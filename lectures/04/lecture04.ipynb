{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1024,\n",
    "        'height': 768,\n",
    "        'scroll': True,\n",
    "})\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Day 4: ZTF Summer School\n",
    "\n",
    "### Michael Coughlin <cough052@umn.edu>\n",
    "\n",
    "\n",
    "with contributions totally ripped off from Gautham Narayan (UIUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Machine Learning ?\n",
    "\n",
    "* The umbrella term \"machine learning\" describes methods for *automated data analysis*, developed by computer scientists and statisticians in response to the appearance of ever larger datasets.\n",
    "\n",
    "* What is actually being learned? With ML, you specify a notion of how to measure the distance between observations, and it learns the correlation structure and builds a model, $M$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The goal of automation has led to an emphasis on non-parametric models (that adapt to dataset size and complexity), and a very uniform terminology that enables multiple models to be implemented and compared on an equal footing.\n",
    "\n",
    "* Machine learning can be divided into two types: *supervised* and *unsupervised.* (this is for future classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised Learning\n",
    "\n",
    "* Supervised learning is also known as *predictive* learning. Given *inputs* $X$, the goal is to construct a machine that can accurately predict a set of *outputs* $y$, usually so that _decisions_ can be made. \n",
    "\n",
    "\n",
    "* The \"supervision\" refers to the education of the machine, via a *training set* $D$ of input-output pairs that we provide. Prediction accuracy is then tested on *validation* and *test* sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Supervised Learning\n",
    "\n",
    "* At the heart of the prediction machine is a *model* $M$ that can be *trained* to give accurate predictions.\n",
    "\n",
    "* Supervised learning is about making predictions by characterizing ${\\rm Pr}(y_k|x_k,D,M)$.\n",
    "\n",
    "* The outputs $y$ are said to be *response variables* - predictions of $y$ will be generated by our model. \n",
    "\n",
    "* The variables $y$ can be either *categorical* (\"labels\") or *nominal* (real numbers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* When the $y$ are numerical, the problem is a *regression* (\"how should we interpolate between these numerical values?\").\n",
    "\n",
    "<img src=\"figures/house_price_features.png\">\n",
    "\n",
    "<img src=\"figures/house_price_features_corr.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"figures/ml_map.png\"></img>\n",
    "\n",
    "> The [`scikit-learn` algorithm cheatsheet](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html), as provided with the package documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Representations\n",
    "\n",
    "* Each input $x$ is said to have $P$ *features* (or *attributes*), and represents a *sample* (assumed to have been drawn from a sampling distribution). Each sample input $x$ is associated with an output $y$.\n",
    "\n",
    "\n",
    "* Our $N$ input *samples* are packaged into an $N \\times P$ *design matrix* $X$ (with $N$ rows and $P$ columns). We've used this term before in the context of regression and you saw an example of building one with the HBM on Cepheids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"figures/ml_data_representation.svg\" width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Typically a supervised learning model is \"trained\" on a subset of the data, and then its ability to make predictions about new data \"tested\" on the remainder.\n",
    "\n",
    "* Training involves \"fitting\" the model to the data, optimizing its parameters to minimize some \"loss function\" (or equivalently, maximize some defined \"score\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"figures/ml_supervised_workflow.svg\" width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"figures/ml_train_test_split_matrix.svg\" width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimizing Model Prediction Accuracy\n",
    "\n",
    "* In supervised machine learning the goal is to make the most accurate predictions we can - which means neither over-fitting nor under-fitting the data \n",
    "\n",
    "* The \"mean squared error\" between the model predictions and the truth is a useful metric: minimizing MSE corresponds to minimizing the \"empirical risk,\" defined as the mean value loss function averaged over the available data samples, where the loss function is quadratic\n",
    "\n",
    "<img src=\"figures/overfitting_underfitting_cartoon.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision Tree Methods\n",
    "\n",
    "The hierarchical application of decision boundaries lead to decision trees\n",
    "\n",
    "Tree structure:\n",
    "\n",
    "- top node contains the entire data set\n",
    "- at each branch the data are subdivided into **two** child nodes (this is the decision)\n",
    "- split is based on a predefined decision boundary (usually axis aligned)\n",
    "- splitting repeats, recursively, until we reach a predefined stopping criteria\n",
    "\n",
    "\n",
    "Application of the tree to classification is simple (a series of binary decisions). \n",
    "\n",
    "The fraction of points from the training set classified as one class or the other defines the class associated with the decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In-class warm-up: Look at the table below and pick the feature that is best to split on first\n",
    "\n",
    "#### Remember that you only get to make a binary split (i.e. mild or not mild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=14</i>\n",
       "<table id=\"table140240401910032\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>outlook</th><th>temperature</th><th>humidity</th><th>windy</th><th>play</th></tr></thead>\n",
       "<thead><tr><th>str8</th><th>str4</th><th>str6</th><th>str5</th><th>str3</th></tr></thead>\n",
       "<tr><td>sunny</td><td>hot</td><td>high</td><td>FALSE</td><td>no</td></tr>\n",
       "<tr><td>sunny</td><td>hot</td><td>high</td><td>TRUE</td><td>no</td></tr>\n",
       "<tr><td>overcast</td><td>hot</td><td>high</td><td>FALSE</td><td>yes</td></tr>\n",
       "<tr><td>rainy</td><td>mild</td><td>high</td><td>FALSE</td><td>yes</td></tr>\n",
       "<tr><td>rainy</td><td>cool</td><td>normal</td><td>FALSE</td><td>yes</td></tr>\n",
       "<tr><td>rainy</td><td>cool</td><td>normal</td><td>TRUE</td><td>no</td></tr>\n",
       "<tr><td>overcast</td><td>cool</td><td>normal</td><td>TRUE</td><td>yes</td></tr>\n",
       "<tr><td>sunny</td><td>mild</td><td>high</td><td>FALSE</td><td>no</td></tr>\n",
       "<tr><td>sunny</td><td>cool</td><td>normal</td><td>FALSE</td><td>yes</td></tr>\n",
       "<tr><td>rainy</td><td>mild</td><td>normal</td><td>FALSE</td><td>yes</td></tr>\n",
       "<tr><td>sunny</td><td>mild</td><td>normal</td><td>TRUE</td><td>yes</td></tr>\n",
       "<tr><td>overcast</td><td>mild</td><td>high</td><td>TRUE</td><td>yes</td></tr>\n",
       "<tr><td>overcast</td><td>hot</td><td>normal</td><td>FALSE</td><td>yes</td></tr>\n",
       "<tr><td>rainy</td><td>mild</td><td>high</td><td>TRUE</td><td>no</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=14>\n",
       "outlook  temperature humidity windy play\n",
       "  str8       str4      str6    str5 str3\n",
       "-------- ----------- -------- ----- ----\n",
       "   sunny         hot     high FALSE   no\n",
       "   sunny         hot     high  TRUE   no\n",
       "overcast         hot     high FALSE  yes\n",
       "   rainy        mild     high FALSE  yes\n",
       "   rainy        cool   normal FALSE  yes\n",
       "   rainy        cool   normal  TRUE   no\n",
       "overcast        cool   normal  TRUE  yes\n",
       "   sunny        mild     high FALSE   no\n",
       "   sunny        cool   normal FALSE  yes\n",
       "   rainy        mild   normal FALSE  yes\n",
       "   sunny        mild   normal  TRUE  yes\n",
       "overcast        mild     high  TRUE  yes\n",
       "overcast         hot   normal FALSE  yes\n",
       "   rainy        mild     high  TRUE   no"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS\n",
    "import astropy.table as at\n",
    "import graphviz \n",
    "weather = at.Table.read('data/weather_nominal.csv', format='ascii')\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Implementing a Single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook  temperature  humidity  windy  play\n",
       "0       2.0          1.0       0.0    0.0   0.0\n",
       "1       2.0          1.0       0.0    1.0   0.0\n",
       "2       0.0          1.0       0.0    0.0   1.0\n",
       "3       1.0          2.0       0.0    0.0   1.0\n",
       "4       1.0          0.0       1.0    0.0   1.0\n",
       "5       1.0          0.0       1.0    1.0   0.0\n",
       "6       0.0          0.0       1.0    1.0   1.0\n",
       "7       2.0          2.0       0.0    0.0   0.0\n",
       "8       2.0          0.0       1.0    0.0   1.0\n",
       "9       1.0          2.0       1.0    0.0   1.0\n",
       "10      2.0          2.0       1.0    1.0   1.0\n",
       "11      0.0          2.0       0.0    1.0   1.0\n",
       "12      0.0          1.0       1.0    0.0   1.0\n",
       "13      1.0          2.0       0.0    1.0   0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# convert the labels to numerical data\n",
    "cols = []\n",
    "new_weather = weather.copy()\n",
    "for i, feature in enumerate(weather.colnames):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    new_weather[feature] = le.fit_transform(weather[feature])*1.\n",
    "new_weather = new_weather.to_pandas()\n",
    "new_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"287pt\" height=\"269pt\"\n",
       " viewBox=\"0.00 0.00 287.00 269.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 265)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-265 283,-265 283,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"155,-261 55,-261 55,-193 155,-193 155,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"105\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\">outlook &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"105\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\">entropy = 0.94</text>\n",
       "<text text-anchor=\"middle\" x=\"105\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 14</text>\n",
       "<text text-anchor=\"middle\" x=\"105\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [9, 5]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"92,-149.5 0,-149.5 0,-96.5 92,-96.5 92,-149.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-134.3\" font-family=\"Times,serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-119.3\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 4</text>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-104.3\" font-family=\"Times,serif\" font-size=\"14.00\">value = [4, 0]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M85.84,-192.88C79.42,-181.78 72.24,-169.37 65.77,-158.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"68.8,-156.42 60.76,-149.52 62.74,-159.93 68.8,-156.42\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.31\" y=\"-169.97\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"217.5,-157 110.5,-157 110.5,-89 217.5,-89 217.5,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"164\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">humidity &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"164\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">entropy = 1.0</text>\n",
       "<text text-anchor=\"middle\" x=\"164\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 10</text>\n",
       "<text text-anchor=\"middle\" x=\"164\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [5, 5]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M124.16,-192.88C129.1,-184.33 134.49,-175.01 139.66,-166.07\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"142.76,-167.71 144.74,-157.3 136.7,-164.2 142.76,-167.71\"/>\n",
       "<text text-anchor=\"middle\" x=\"151.19\" y=\"-177.75\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"155,-53 49,-53 49,0 155,0 155,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"102\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">entropy = 0.722</text>\n",
       "<text text-anchor=\"middle\" x=\"102\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 5</text>\n",
       "<text text-anchor=\"middle\" x=\"102\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [1, 4]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M142.32,-88.95C136.55,-80.17 130.32,-70.66 124.51,-61.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"127.3,-59.68 118.89,-53.24 121.44,-63.52 127.3,-59.68\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"279,-53 173,-53 173,0 279,0 279,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"226\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">entropy = 0.722</text>\n",
       "<text text-anchor=\"middle\" x=\"226\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 5</text>\n",
       "<text text-anchor=\"middle\" x=\"226\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [4, 1]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M185.68,-88.95C191.45,-80.17 197.68,-70.66 203.49,-61.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206.56,-63.52 209.11,-53.24 200.7,-59.68 206.56,-63.52\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f8c4356c9d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the training features and target\n",
    "X_train = new_weather[weather.colnames[0:4]]\n",
    "Y_train = 1.-new_weather['play']\n",
    "\n",
    "# TWO LINES OF CODE TO IMPLEMENT A DECISION TREE\n",
    "\n",
    "# build the decision tree\n",
    "clf = DecisionTreeClassifier(max_depth = 2, criterion='entropy')\n",
    "\n",
    "# Step 3: Train the model on the data\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Plot the Tree\n",
    "dot_data = tree.export_graphviz(clf, feature_names= weather.colnames[0:4], out_file=None) \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Decision trees are simple to interpret (a set of questions).\n",
    "\n",
    "[This structure is called a Dendrogram](https://en.wikipedia.org/wiki/Dendrogram)\n",
    "\n",
    "<img src=\"figures/tree_components.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Remember the bias-variance tradeoff?\n",
    "<img src=\"figures/overfitting_underfitting_cartoon.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# There's not a lot you can do with a tree structure:\n",
    "<img src=\"figures/tree_depth.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Limiting Model Complexity\n",
    "<img src=\"figures/tree_limit.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pruning - getting rid of leaves that don't have large information/gini gain\n",
    "<img src=\"figures/tree_pruning.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression with Trees: When the target variable is nominal \n",
    "\n",
    "<img src=\"figures/tree_regression.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## But you say \n",
    "\n",
    "### AH BUT ENTROPY AND GINI IMPURITY ARE DEFINED AS MARGINALS OVER CATEGORICAL VARIABLES, WOE IS ME HOW COULD THESE DISTANCE METRICS EVER POSSIBLY WORK FOR VARIABLES THAT ARE CONTINUOUS \n",
    "\n",
    "(Well ok maybe you don't say exactly that...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"figures/tree_regression_metric.png\">\n",
    "\n",
    "Hello old friends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The big issues with trees\n",
    "\n",
    "* Variance - different trees lead to different results\n",
    "    - intuitively if you have just two continuous variables, then calculating the split for every node even with a depth = 2 tree is of order $\\infty^2$\n",
    "    \n",
    "You can view each tree as a single path that you can take do get the desired outcome.\n",
    "\n",
    "There are many possible paths, so we do the thing we always do and marginalize over them.\n",
    "\n",
    "In other words, go from a single decision tree to a many decision trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Two common ensemble methods that use decision trees:\n",
    "\n",
    "1. Random Forests\n",
    "    - Trees run in parallel, independent of each other\n",
    "    - Each tree uses a random subset of the observations and features (**bagging**)\n",
    "        - the number of features selected per split level is typically limited to the square root of the total number of features\n",
    "    - Class predicted by majority vote - what class do most trees think an observation belongs to or average in the case of regression\n",
    "\n",
    "\n",
    "\n",
    "2. Gradient Boosted Trees\n",
    "    - Trees run in series \n",
    "    - Each tree uses different weights for the features, updating the weights from the previous tree\n",
    "    - The last tree makes the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-class warm-up: using Random Forests for regression using SDSS galaxies with known redshifts (the target) and magnitudes as features - i.e. a photo-z estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from astroML.datasets import fetch_sdss_specgals\n",
    "from astroML.decorators import pickle_results\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Fetch and prepare the data\n",
    "data = fetch_sdss_specgals()\n",
    "\n",
    "# put magnitudes in a matrix\n",
    "mag = np.vstack([data['modelMag_%s' % f] for f in 'ugriz']).T\n",
    "z = data['z']\n",
    "\n",
    "# train on ~60,000 points\n",
    "mag_train = mag[::10]\n",
    "z_train = z[::10]\n",
    "\n",
    "# test on ~6,000 distinct points\n",
    "mag_test = mag[1::100]\n",
    "z_test = z[1::100]\n",
    "\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Compute the results\n",
    "#  This is a long computation, so we'll save the results to a pickle.\n",
    "@pickle_results('photoz_forest.pkl')\n",
    "def compute_photoz_forest(depth):\n",
    "    rms_test = np.zeros(len(depth))\n",
    "    rms_train = np.zeros(len(depth))\n",
    "    i_best = 0\n",
    "    z_fit_best = None\n",
    "\n",
    "    for i, d in enumerate(depth):\n",
    "        # YOUR CODE HERE\n",
    "        #clf = RandomForestRegressor(...\n",
    "        #clf.fit(...\n",
    "\n",
    "        z_fit_train = clf.predict(mag_train)\n",
    "        z_fit = clf.predict(mag_test)\n",
    "        rms_train[i] = np.mean(np.sqrt((z_fit_train - z_train) ** 2))\n",
    "        rms_test[i] = np.mean(np.sqrt((z_fit - z_test) ** 2))\n",
    "\n",
    "        if rms_test[i] <= rms_test[i_best]:\n",
    "            i_best = i\n",
    "            z_fit_best = z_fit\n",
    "\n",
    "    return rms_test, rms_train, i_best, z_fit_best\n",
    "\n",
    "\n",
    "depth = np.arange(1, 20)\n",
    "rms_test, rms_train, i_best, z_fit_best = compute_photoz_forest(depth)\n",
    "best_depth = depth[i_best]\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Plot the results\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "fig.subplots_adjust(wspace=0.25,\n",
    "                    left=0.1, right=0.95,\n",
    "                    bottom=0.15, top=0.9)\n",
    "\n",
    "# left panel: plot cross-validation results\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(depth, rms_test, '-k', label='cross-validation')\n",
    "ax.plot(depth, rms_train, '--k', label='training set')\n",
    "ax.legend(loc=1, prop=dict(size=13))\n",
    "\n",
    "ax.set_xlabel('depth of tree')\n",
    "ax.set_ylabel('rms error')\n",
    "\n",
    "ax.set_xlim(0, 21)\n",
    "ax.set_ylim(0.009,  0.04)\n",
    "ax.yaxis.set_major_locator(plt.MultipleLocator(0.01))\n",
    "\n",
    "# right panel: plot best fit\n",
    "ax = fig.add_subplot(122)\n",
    "ax.scatter(z_test, z_fit_best, s=1, lw=0, c='k')\n",
    "ax.plot([-0.1, 0.4], [-0.1, 0.4], ':k')\n",
    "ax.text(0.03, 0.97, \"depth = %i\\nrms = %.3f\" % (best_depth, rms_test[i_best]),\n",
    "        ha='left', va='top', transform=ax.transAxes)\n",
    "\n",
    "ax.set_xlabel(r'$\\rm z_{true}$', fontsize=16)\n",
    "ax.set_ylabel(r'$\\rm z_{fit}$', fontsize=16)\n",
    "\n",
    "ax.set_xlim(-0.02, 0.4001)\n",
    "ax.set_ylim(-0.02, 0.4001)\n",
    "ax.xaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
    "ax.yaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-class exercise: using Gradient Boosting for regression on the same data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from astroML.datasets import fetch_sdss_specgals\n",
    "from astroML.decorators import pickle_results\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Fetch and prepare the data\n",
    "data = fetch_sdss_specgals()\n",
    "\n",
    "# put magnitudes in a matrix\n",
    "mag = np.vstack([data['modelMag_%s' % f] for f in 'ugriz']).T\n",
    "z = data['z']\n",
    "\n",
    "# train on ~60,000 points\n",
    "mag_train = mag[::10]\n",
    "z_train = z[::10]\n",
    "\n",
    "# test on ~6,000 distinct points\n",
    "mag_test = mag[1::100]\n",
    "z_test = z[1::100]\n",
    "\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Compute the results\n",
    "#  This is a long computation, so we'll save the results to a pickle.\n",
    "@pickle_results('photoz_boosting.pkl')\n",
    "def compute_photoz_forest(N_boosts):\n",
    "    rms_test = np.zeros(len(N_boosts))\n",
    "    rms_train = np.zeros(len(N_boosts))\n",
    "    i_best = 0\n",
    "    z_fit_best = None\n",
    "\n",
    "    for i, Nb in enumerate(N_boosts):\n",
    "        # YOUR CODE HERE\n",
    "        #clf = GradientBoostingRegressor(...\n",
    "        #clf.fit(...\n",
    "\n",
    "        z_fit_train = clf.predict(mag_train)\n",
    "        z_fit = clf.predict(mag_test)\n",
    "        rms_train[i] = np.mean(np.sqrt((z_fit_train - z_train) ** 2))\n",
    "        rms_test[i] = np.mean(np.sqrt((z_fit - z_test) ** 2))\n",
    "\n",
    "        if rms_test[i] <= rms_test[i_best]:\n",
    "            i_best = i\n",
    "            z_fit_best = z_fit\n",
    "\n",
    "    return rms_test, rms_train, i_best, z_fit_best\n",
    "\n",
    "N_boosts = (10, 100, 200, 300, 400, 500)\n",
    "rms_test, rms_train, i_best, z_fit_best = compute_photoz_forest(N_boosts)\n",
    "best_N = N_boosts[i_best]\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Plot the results\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "fig.subplots_adjust(wspace=0.25,\n",
    "                    left=0.1, right=0.95,\n",
    "                    bottom=0.15, top=0.9)\n",
    "\n",
    "# left panel: plot cross-validation results\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(N_boosts, rms_test, '-k', label='cross-validation')\n",
    "ax.plot(N_boosts, rms_train, '--k', label='training set')\n",
    "ax.legend(loc=1, prop=dict(size=13))\n",
    "\n",
    "ax.set_xlabel('number of boosts')\n",
    "ax.set_ylabel('rms error')\n",
    "ax.set_xlim(0, 510)\n",
    "ax.set_ylim(0.009,  0.032)\n",
    "ax.yaxis.set_major_locator(plt.MultipleLocator(0.01))\n",
    "\n",
    "ax.text(0.03, 0.03, \"Tree depth: 3\",\n",
    "        ha='left', va='bottom', transform=ax.transAxes)\n",
    "\n",
    "# right panel: plot best fit\n",
    "ax = fig.add_subplot(122)\n",
    "ax.scatter(z_test, z_fit_best, s=1, lw=0, c='k')\n",
    "ax.plot([-0.1, 0.4], [-0.1, 0.4], ':k')\n",
    "ax.text(0.03, 0.97, \"N = %i\\nrms = %.3f\" % (best_N, rms_test[i_best]),\n",
    "        ha='left', va='top', transform=ax.transAxes)\n",
    "\n",
    "ax.set_xlabel(r'$\\rm z_{true}$', fontsize=16)\n",
    "ax.set_ylabel(r'$\\rm z_{fit}$', fontsize=16)\n",
    "\n",
    "ax.set_xlim(-0.02, 0.4001)\n",
    "ax.set_ylim(-0.02, 0.4001)\n",
    "ax.xaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
    "ax.yaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What intuition am I supposed to take from the clustering methods?\n",
    "\n",
    "Structure exists on nearly all scales in the universe. Matter clumps under its own gravity into planets, stars, galaxies, clusters, and superclusters. Beyond even these in scale are the filaments and voids. The largest of these filaments is known as the Sloan Great Wall. This giant string of galaxies is 1.4 billion light years across making it the largest known structure in the universe. \n",
    "\n",
    "The study of such properties will help astronomers to test cosmological models that predict galactic structure formation. The models generally fall short in creating the size, morphology and distribution of the formations we see, which arise from density fluctuations initially present during the Big Bang. As such, understanding the structures they formed will help astronomers to understand these perturbations in greater detail and, in turn, what physics would be necessary to achieve them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Density-based clustering\n",
    "\n",
    "- Rather than a linkage based approach that which considers $k$ neighbors to each point (regardless of distance modulo some overall distance threshold), these approaches look at how closely packed points are - i.e. the **local density**\n",
    "\n",
    "- Points that are in low-density regions are marked as **outliers**\n",
    "    - effectively demand that each point have at least MinPts neighbors within some distance, epsilon\n",
    "\n",
    "\n",
    "Implementation:\n",
    "    - Pick a random point in the data that hasn't been checked yet\n",
    "    - Given some epsilon, find if there are at least MinPts within epsilon of point\n",
    "        - if yes\n",
    "            - start a cluster\n",
    "        - else\n",
    "            - mark as noise (may be later marked as member of a different cluster)\n",
    "        - mark any points within epsilon of cluster points as also part of the cluster\n",
    "        - grow cluster until there are no other points that can be added\n",
    "    - repeat until all points visited          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Common implementations: DBSCAN and OPTICS (both in `sklearn.cluster`)\n",
    "    - OPTICS handles clusters with different densities better but is significantly slower\n",
    "- not completely deterministic - depends on order points are visited, but still **agglomerative** (compare vs decision trees that splits the data up into smaller groups - **divisive** \n",
    "- still don't need to specify a number of clusters or cluster centers/widths - i.e. clusters can have arbitrary shapes rather than say a GMM\n",
    "    - can be fiddly and needs some fine-tuning of epsilon **LOOK AT YOUR DATA**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ## Uses in Astrophysics \n",
    " \n",
    " <img src=\"figures/gamma_DBSCAN.jpg\">\n",
    " \n",
    " Finding clusters in Fermi-LAT $\\gamma$ ray data: https://www.aanda.org/articles/aa/abs/2013/01/aa20133-12/aa20133-12.html\n",
    " \n",
    " \n",
    "Gamma-ray astronomers could feasibly name all their photons, so finding clusters this way is really looking for overdensities on a map that is otherwise white noise - because number counts are so low, detections are very significant, but this is a way to automate over large area\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The opposite problem also works - the background is high and the clusters are barely variation on the background:\n",
    "\n",
    "<img src=\"figures/GAIA_DR2_clusters.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And of course, you don't have to do this in RA, Dec space at all - here in 15 dimensional PCA on spectra space:\n",
    "\n",
    "<img src=\"figures/Clustering_chem_abundances.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In-class warm-up\n",
    "\n",
    "There's some noisy real color-magnitude data for stars in `colormag.csv`\n",
    "\n",
    "1. preprocess the data (i.e. scale the magnitudes and colors in some way that makes your results insensitive to the scale of the values\n",
    "\n",
    "2. use k-means, GMMs, hierarchical clustering and DBSCAN to cluster the dataset into similar groups. You can pick the sizes of clusters/initial estimates for parameters however you like\n",
    "\n",
    "3. in each case, the clustering instance that you create will have a `.labels_` attribute - use this to color the points in a scatter plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## YOUR SOLUTION HERE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "X = pd.read_csv('data/colormag.csv', names=['color', 'mag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "z = StandardScaler()\n",
    "Xt = z.fit_transform(X)\n",
    "\n",
    "plt.scatter(Xt[:,0], Xt[:,1])\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('Color', fontsize='xx-large')\n",
    "ax.set_ylabel('Mag', fontsize='xx-large');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Anomaly Detection\n",
    "\n",
    "ML algorithms suffer in terms of their performance when outliers are not taken care of. \n",
    "\n",
    "Bad ideas include \n",
    "- dropping them from your sample\n",
    "- leaving them in, using ML methods, and then ignoring the impact of the outliers\n",
    "\n",
    "\n",
    "Imagine if a bank did either of these for fradulent credit card transactions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One efficient way of performing outlier detection in high-dimensional datasets is to use random forests\n",
    "\n",
    "Isolation forests ‘isolate’ observations by constructing decesion trees:\n",
    "- randomly selecting a feature and then \n",
    "- randomly selecting a split value between the maximum and minimum values of the selected feature\n",
    "\n",
    "Number of splittings required to isolate a sample = path length from the root node to the terminating node\n",
    "\n",
    "Path length, averaged over a forest of such random trees, is a measure of normality and our decision function.\n",
    "\n",
    "Random partitioning produces noticeable shorter paths for anomalies. \n",
    "\n",
    "When a forest of random trees collectively produce shorter path lengths for particular samples, they are highly likely to be anomalies - i.e. **linkage-based**\n",
    "\n",
    "<img src=\"figures/IsolationForest1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Random forest are **supervised** so why are they showing up here in **unsupervised learning**?\n",
    "- there's only two labels (outlier/not outlier)\n",
    "- but you still have to condition the algorithm on a training set (even if it doesn't have labels) \n",
    "\n",
    "\n",
    "## Local Outlier Fraction:\n",
    "\n",
    "LOF uses density-based outlier detection to identify local outliers\n",
    "- points that are outliers with respect to their local neighborhood, rather than with respect to the global distribution. \n",
    "\n",
    "A point is labeled as an outlier if the density around that point is significantly different from the density around its neighbors.\n",
    "  \n",
    "The higher the LOF value for an observation, the more anomalous the observation.\n",
    "\n",
    "Useful because can identify a point that’s an outlier relative to a nearby cluster of points (a local outlier) even if that whole region is an outlying region in the global space of data points.\n",
    "    - Application SNIa have subclasses that are odd, and even amongst those sub-classes there are real oddballs - these are good to identify because they tell us the most about the physics of the explosion.\n",
    "\n",
    "\n",
    "<img src=\"figures/LOF.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary of methods\n",
    "\n",
    "|Method          |Accuracy|Interpretability|Simplicity|Speed|\n",
    "|----------------|--------|----------------|----------|-----|\n",
    "|K-nearest Neighbor| H | H | H | M |\n",
    "|Kernel Density Estimation| H | H | H | H |\n",
    "|Hierarchical Clustering| H | L | L | L |\n",
    "||||||\n",
    "|K-Means| L | M | H | M |\n",
    "|Max-radius minimization| L | M | M | M |\n",
    "|Mean shift| M | H | H | M |\n",
    "|Gaussian Mixture Models| H | M | M | M |\n",
    "|Extreme Deconvolution| H | H | M | M |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Unsupervised ML \"wisdom\"\n",
    "\n",
    "\n",
    "* Do you have labels that you trust?\n",
    "    - Why are you using unsupervised methods at all then\n",
    "* Do you have an a priori reason for there to be $k$ separate groups?\n",
    "    - k-Means/GMM\n",
    "* Are your observations really noise and wiping out structure?\n",
    "    - Extreme deconvolution\n",
    "\n",
    "* Do you really need clusters or are you trying to get a sense of the underlying density distribution\n",
    "    - KDEs\n",
    "* Do you need clustering but your clusters are defined by an overdensity against a background\n",
    "    - DBSCAN/OPTICS\n",
    "* Does your sample have some natural hierarchy\n",
    "    - Hierarchical clustering\n",
    "    \n",
    "* Do you care about the stuff that isn't part of some underlying distribution model\n",
    "    - IsolationForest/LOF\n",
    "\n",
    "There is no one right answer.\n",
    "\n",
    "You are looking for structure in your data with unsupervised methods, so the right answer is to **look at your data** - i.e. try a few different things and refine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In class-exercise\n",
    "\n",
    "Train an isolation forest and LOF on a random subset of the color-mag data. \n",
    "\n",
    "(For isolation forest, you can use `sklearn.model_selection.train_test_split` to split it into a training set and test set)\n",
    "\n",
    "and as before train the algoritin \n",
    "\n",
    "```\n",
    "clf = IsolationForest(max_samples=100, random_state=rng)\n",
    "clf.fit(X_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "```\n",
    "\n",
    "or with `sklearn.neighbors.LocalOutlierFactor`\n",
    "\n",
    "```\n",
    "clf = LocalOutlierFactor(n_neighbors=2)\n",
    "clf.fit_predict(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest = train_test_split(Xt, test_size=0.3)\n",
    "## YOUR CODE HERE\n",
    "#clf = IsolationForest(...\n",
    "#clf.fit(Xtrain)\n",
    "\n",
    "y_pred_train = clf.predict(Xtrain)\n",
    "y_pred_test = clf.predict(Xtest)\n",
    "\n",
    "#outliers are -1, inliers are 1\n",
    "y_pred_train[y_pred_train == -1] += 1\n",
    "y_pred_test[y_pred_test == -1] += 1\n",
    "\n",
    "color_train = [f'C{i}' for i in y_pred_train]\n",
    "plt.scatter(Xtrain[:,0], Xtrain[:,1], color=color_train, marker='.', label='Training set')\n",
    "color_test = [f'C{i}' for i in y_pred_test]\n",
    "plt.scatter(Xtest[:,0], Xtest[:,1], color=color_test, marker='s', label='Test set')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.legend(fontsize='x-large', loc='lower left')\n",
    "\n",
    "ax.set_xlabel('Color', fontsize='xx-large')\n",
    "ax.set_ylabel('Mag', fontsize='xx-large')\n",
    "ax.set_title('Isolation Forest', fontsize='xx-large');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "#clf = LocalOutlierFactor(...\n",
    "#labels = clf.fit_predict(...\n",
    "\n",
    "\n",
    "#outliers are -1, inliers are 1\n",
    "labels[labels == -1] += 1\n",
    "\n",
    "\n",
    "color = [f'C{i}' for i in labels]\n",
    "plt.scatter(Xt[:,0], Xt[:,1], color=color, marker='o')\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.set_xlabel('Color', fontsize='xx-large')\n",
    "ax.set_ylabel('Mag', fontsize='xx-large')\n",
    "ax.set_title('Local Outlier Fraction', fontsize='xx-large');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"figures/classification_workflow.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Individual classifiers are often **weak** (prone to bias/overfitting) so we use **ensembles of classifiers**\n",
    "- bagging (train classifiers in parallel, ensemble votes on output) \n",
    "- boosting (train classifiers in series, each one learning from the mistakes of the previous one, last classifier votes)\n",
    "\n",
    "(e.g. decision tree vs random forest)\n",
    "\n",
    "#### The stats viewpoint\n",
    "- Rather than rely solely on the structure in the data as in unsupervised learning, we're introducing extra information (**priors**) to help improve our ability to model unlabelled data (**prediction**) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Performance Measures/Scores (often, also called metrics, just to be confusing):\n",
    "\n",
    "\n",
    "The first question that we need to address is how we score our results - i.e. how good are our predictions\n",
    "\n",
    "In the simplest case, there are 2 types of errors:\n",
    "* a [False Positive](https://en.wikipedia.org/wiki/False_positives_and_false_negatives#False_positive_error), where we have assigned a *true* class label when it is really false. \n",
    "\n",
    "This is called a \"Type-1 error\".\n",
    "\n",
    "* a [False Negative](https://en.wikipedia.org/wiki/False_positives_and_false_negatives#False_positive_error), where we have assigned a *false* class label when it is really true. \n",
    "\n",
    "This is called a \"Type-II error\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "All 4 [possibilities](https://en.wikipedia.org/wiki/Sensitivity_and_specificity) for each pair of classes:\n",
    "- True Positive = **correctly identified**  (apple identified as apple)\n",
    "- True Negative = **correctly rejected**  (orange rejected as orange)\n",
    "- False Positive = **incorrectly identified**  (orange identified as apple)\n",
    "- False Negative = **incorrectly rejected**  (apple rejected as orange)\n",
    "\n",
    "In the case where there are only two classes (i.e. binary classification), these are clearly related, but in the multi-class case, these numbers tell you a more complex story:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Confusion Matrix\n",
    "\n",
    "Summarizes the \"confusion\" for the classifier. \n",
    "\n",
    "- For a perfect classifier all of the power will be along the diagonal, while confusion is represented by off-diagonal signal. \n",
    "\n",
    "Like almost everything else we have encountered during this exercise, `scikit-learn` makes it easy to compute a confusion matrix. This can be accomplished with the following: \n",
    "\n",
    "```\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "```\n",
    "\n",
    "\n",
    "Here's an example from the <a href=\"https://www.kaggle.com/c/PLAsTiCC-2018\">Photometric LSST Astronomical Time-Series Classificiation Challenge (PLaSTiCC)</a> from the winning entry by then grad student, Kyle Boone:\n",
    "<img src=\"figures/KyleBoone_CM.png\" width=\"70%\">\n",
    "\n",
    "\n",
    "You can read about Kyle's winning entry here: https://arxiv.org/abs/1907.04690 (note that you've seen many of the classes in this CM during this semester, either on homework or in-class exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Based on TP/FP/TN/FN, we usually define either of the following pairs of terms:  \n",
    "\n",
    ">$ {\\rm completeness} = \\frac{\\rm true\\ positives}{\\rm true\\ positives + false\\ negatives}$\n",
    "\n",
    ">$  {\\rm contamination} = \\frac{\\rm false\\ positives}{\\rm true\\ positives + false\\ positives} = {\\rm false\\ discovery\\ rate}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "or\n",
    "\n",
    "> $ {\\rm true\\ positive\\ rate} = \\frac{\\rm true\\ positives} {\\rm true\\ positives + false\\ negatives}\n",
    "$\n",
    "\n",
    "> $  {\\rm false\\ positive\\ rate} = \\frac{\\rm false\\ positives} {\\rm true\\ negatives + false\\ positives} = {\\rm Type1\\ error}\n",
    "$\n",
    "\n",
    "where **completeness** = **true positive rate** and this is also called **sensitivity** or **recall**\n",
    "\n",
    "\n",
    "Which set is used is largely arbitrary and dependent on field/sub-field, but they're largely giving you similar information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Similarly \n",
    " \n",
    ">$ {\\rm efficiency} = 1 - {\\rm contamination} = {\\rm precision}. $\n",
    "\n",
    "Scikit-Learn also reports the **F1 score** which is the harmonic mean (i.e. reciprocal of arithmetic mean of reciprocals) of precision and sensitivity (efficiency and completeness).\n",
    "\n",
    "Depending on your goals, you may want to maximize the completeness or the efficiency, or a combination of both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classifier performance can also be viewed as a tradeoff \n",
    "\n",
    "You might want to minimize voter fraud (contamination), but if doing so reduced voter participation (completeness) by a larger amount, then that wouldn't be such a good thing.  \n",
    "\n",
    "So you need to decide what balance you want to strike.\n",
    "\n",
    "**Note that this tradeoff is different from the bias/variance tradeoff.** \n",
    "You can still infer bias results from a sample without much contamination!\n",
    "\n",
    "If your labels were positives = detected, and negatives = below detection threshold, you can make the analogy to HW8, where you looked at completeness and efficiency for a simulated survey - what fraction of sources you recovered, and how efficient you were at discriminating sources from background noise excursion. \n",
    "\n",
    "You had a hard cut in number of counts (a threshold) so you had a sample that was not contaminated, but if you only used the detected objects for inference you'd still get a biased value for population parameters (exponent of the power law)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparing the performance of classifiers\n",
    "\n",
    "So, \"best\" performance is a bit of a subjective topic. \n",
    "- We trade contamination as a function of completeness and this is science dependent.\n",
    "\n",
    "This is true even for just a single classifier, if we get a score (or probability) for an object being a certain class. Then we don't have a sharp decision boundary but rather a threshold that we can vary.\n",
    "\n",
    "This choice of threshold impacts the TPR/FPR so we want to characterize how it impacts classification. The way that we will do this is with a [**Receiver Operating Characteristic (ROC)**](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) curve.  \n",
    "\n",
    "A ROC curve simply plots the true-positive vs. the false-positive rate as a function of threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ROC curves \n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td width=\"500px\">\n",
    "            <img src=\"figures/roc_schematic.jpg\">\n",
    "        </td>\n",
    "        <td width=\"500px\">\n",
    "            <img src=\"figures/roc_plasticc.jpg\">\n",
    "        </td>\n",
    "     </tr>\n",
    "</table>\n",
    "\n",
    "Annoyingly, they're only well defined for binary classification, so if you have a multi-class problem, then you have to:\n",
    "\n",
    "- plot 1 ROC curve per class\n",
    "- **micro-averaging**: Reduce multi-class problem to correctly classififed/not-correctly classified regardless of class\n",
    "- **macro-averaging**: plot average ROC curve across all classes (what's on the right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## AUC\n",
    "\n",
    "Generally speaking, you want to chose a classifier that maximizes the **area under the curve.**\n",
    "- very literally the area under the ROC curve\n",
    "- classifiers with a higher AUC are better (more true positives, less false positives)\n",
    "\n",
    "## Precision-Recall curves\n",
    "\n",
    "You can also plot completeness/contamination or precision/recall.\n",
    "\n",
    "One concern about precision-recall curves is that they are sensitive to the relative sample sizes.\n",
    "- If there are many more background events than source events small false positive results can dominate a signal. \n",
    "- For these cases we can plot efficiency (1 - contamination) vs. completeness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"figures/PRC_turbo_3_downsampled_thresh_lines.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Actually computing performance scores:\n",
    "\n",
    "- [sklearn.metrics.roc_curve(y_test, y_prob)](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)\n",
    "- [sklearn.metrics.precision_recall_curve(y_test, y_prob)](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html)\n",
    "- astroML.utils.completeness_contamination(y_pred, y_test)\n",
    "\n",
    "**Note** \n",
    "- [`sklearn.metrics` algorithms](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) take `y_test`, which are classes, and `y_prob`, which are not class predictions, but rather probabilities\n",
    "- the AstroML algorithm wants `y_pred` (which we get by converting `y_prob` into discrete predictions as a function of the probability).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Different Supervised Learning methods:\n",
    "\n",
    "\n",
    "With Unsupervised Learning, there were a few different approaches-\n",
    "- centroid-based (k-means/median)\n",
    "- distribution-based (GMMs/Extreme Deconvolution)\n",
    "- linkage/connectivity-based (hierarchical clustering/isolation forests)\n",
    "- density-based (KDEs/DBSCAN/Optics)\n",
    "\n",
    "We can divide these methods into two groups-\n",
    "\n",
    "## Generative vs. Discriminative Classification\n",
    "\n",
    "As an example, if you are trying to determine whether a galaxy is at redshift 0.2 or redshift 2, you could either \n",
    "- learn how galaxies are distributed over all redshifts and given this model, you can evaluate the likelihood ratio of the data at both redshifts\n",
    "- OR, you can learn what key features discriminate between galaxies at z=0.2 and z=2\n",
    "\n",
    "For example, in the figure below, to classify a new object with $x=1$, it would suffice to know that either \n",
    "1) model 1 is a better fit than model 2\n",
    "or \n",
    "2) $x=1.4$ is a good discriminator between the two populations \n",
    "\n",
    "![Ivezic, Figure 9.1](http://www.astroml.org/_images/fig_bayes_DB_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we find ourselves asking which category is most likely to generate the observed result, then we are using using **density estimation** for classification \n",
    "- this is referred to as **generative classification**.  \n",
    "- we have a full model of the density for each class or we have a model which describes how data could be generated from each class\n",
    "- both distribution-based (where you assume a form the density) and density-based (where you directly estimate the density from the data) approaches are here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we don't care about the full distribution, then we are doing something more like clustering\n",
    "- we don't need to map the distribution, we just need to define boundaries.  \n",
    "- Classification that finds the **decision boundary** that separates classes is called **discriminative classification**\n",
    "- centroid-based and linkage-based methods come under this class\n",
    "- For high-dimensional data, this may be a better choice\n",
    "    - usual reason - curse of dimensionality\n",
    "    \n",
    "You've already seen **decision trees** and **random forests** as examples of discriminative classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Ivezic, Figure 9.1](http://www.astroml.org/_images/fig_bayes_DB_1.png)\n",
    "\n",
    "In reality, we usually do both. \n",
    "\n",
    "We first do discriminative classification using a decision boundary based-method, and then we do generative classification using density estimation for the class of interest (in order to determine a probability of group membership)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generative Classification\n",
    "\n",
    "We can use Bayes' theorem to relate the labels to the features in an $N\\times D$ data set $X$.  \n",
    "\n",
    "The $j$th feature of the $i$th sample is $x_{ij}$ and there are $k$ classes giving discrete labels $y_k$.  \n",
    "Then we have:\n",
    "\n",
    "$$p(y_k|x_i) = \\frac{p(x_i|y_k)p(y_k)}{\\sum_i p(x_i|y_k)p(y_k)}$$\n",
    "\n",
    "where $x_i$ is a vector with $j$ components.\n",
    "\n",
    "$p(y=y_k)$ is the probability of any point having class $k$ (equivalent to the prior probability of the class $k$). \n",
    "\n",
    "In generative classifiers we model class-conditional densities $p_k(x) = p(x|y=y_k)$ and our goal is to estimate the $p_k$'s. \n",
    "\n",
    "Before we get into the generative classification algortithms, we'll first discuss 3 general concepts:\n",
    "- Discriminant Functions\n",
    "- Bayes Classifiers\n",
    "- Decision Boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Discriminant Function\n",
    "\n",
    "We can relate classification to density estimation and regression.\n",
    "\n",
    "$\\hat{y} = f(y|x)$ represents the best guess of $y$ given $x$. \n",
    "\n",
    "Classification can be thought of as the analog of regression where $y$ is a discrete *category* rather than a continuous variable, for example $y=\\{0,1\\}$.\n",
    "\n",
    "(Alternately regression is just classification with very many classes distrbuted on a real number line).\n",
    "\n",
    "In classification we refer to $f(y|x)$ as the [**discriminant function**](https://en.wikipedia.org/wiki/Discriminant_function_analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For a simple 2-class example, if you want the best guess of the label y:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "g(x) = f(y|x) & = &  \\int y \\, p(y|x) \\, dy \\\\\n",
    "%    & = & \\int y p(y|x) \\, dy \\\\\n",
    "       & = & 1 \\cdot p(y=1 | x) + 0 \\cdot p(y=0 | x) = p(y=1 | x).\n",
    "%     & = & p(y=1 | x)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "From Bayes rule (yet again):\n",
    "\n",
    "$$g(x) = \\frac{p(x|y=1) \\, p(y=1)}{p(x|y=1) \\, p(y=1)  + p(x|y=0) \\, p(y=0)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayes Classifier\n",
    "\n",
    "If the discriminant function gives a binary prediction, we call it a **Bayes classifier**, formulated as\n",
    "\n",
    "\n",
    "$$\\begin{eqnarray} \\widehat{y} & = & \\left\\{ \\begin{array}{cl}       \t           1 & \\mbox{if $g(x) > 1/2$}, \\\\       \t           0 & \\mbox{otherwise,}       \t           \\end{array}     \t   \\right. \\\\     & = & \\left\\{\n",
    "\\begin{array}{cl}               1 & \\mbox{if $p(y=1|x) > p(y=0|x)$}, \\\\               0 & \\mbox{otherwise.}               \\end{array}       \\right.\\end{eqnarray}$$\n",
    "\n",
    "**i.e. the best guess class is the most likely** (duh)\n",
    "\n",
    "This can be generalized to any number of classes, $k$, and not just two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Decision Boundary\n",
    "\n",
    "The **decision boundary** is just the set of $x$ values at which each class is equally likely:\n",
    "\n",
    "$$\n",
    "p(x|y=1)p(y=1)  =  p(x|y=0)p(y=0);\n",
    "$$\n",
    "\n",
    "$$g_1(x) = g_2(x) \\; {\\rm or}\\; g(x) = 1/2$$\n",
    "\n",
    "So same figure as earlier - we're just assigning classifications according to which pdf is higher at every given $x$.\n",
    "\n",
    "![Ivezic, Figure 9.1](http://www.astroml.org/_images/fig_bayes_DB_1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simplest Classifier: Naive Bayes\n",
    "\n",
    "In practice classification can be very complicated as the data are generally multi-dimensional (that is we don't just have $x$, we have $x_{j=0},x_1,x_2,x_3...x_n$, so we want $p(x_0,x_1,x_2,x_3...x_n|y)$.\n",
    "\n",
    "However, if we **assume** that all attributes are conditionally independent (which is not always true, but is often close enough), then this simplifies to\n",
    "\n",
    "$$ p(x_1,x_2|y_k) = p(x_1|y)p(x_2|y_k)$$\n",
    "  \n",
    "which can be written as\n",
    "\n",
    "$$ p({x_{j=0},x_1,x_2,\\ldots,x_N}|y_k) = \\prod_j p(x_j|y_k).$$\n",
    "\n",
    "From Bayes' rule and conditional independence we get\n",
    "\n",
    "$$\n",
    "  p(y_k | {x_0,x_1,\\ldots,x_N}) =\n",
    "  \\frac{\\prod_j p(x_j|y_k) p(y_k)}\n",
    "       {\\sum_l \\prod_j p(x_j|y_l) p(y_l)}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We calculate the most likely value of $y$ by maximizing over $y_k$:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\arg \\max_{y_k} \\frac{\\prod_j p(x_j|y_k) p(y_k)}\n",
    "        {\\sum_l \\prod_j p(x_j|y_l) p(y_l)},\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "From there the process is just estimating densities: $p(x|y=y_k)$ and $p(y=y_k)$ are learned from a set of training data, where\n",
    "- $p(y=y_k)$ is just the frequency of the class $k$ in the training set\n",
    "- $p(x|y=y_k)$ is just the density (probability) of an object with class $k$ having the attributes $x$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gaussian Naive Bayes\n",
    "\n",
    "\n",
    "Of course, to get $p(x|y=y_k)$ you can use all of the density estimation methods from last week. \n",
    "\n",
    "The parametric model is to assert that we have a bunch of 1-D Gaussians i.e. $p(x_i|y=y_k)$ is a normal distributions, with means $\\mu_{ik}$ and widths $\\sigma_{ik}$. \n",
    "\n",
    "The naive Bayes estimator is then\n",
    "\n",
    "$$\\hat{y} = \\arg\\max_{y_k}\\left[\\ln p(y=y_k) - \\frac{1}{2}\\sum_{i=1}^N\\left(2\\pi(\\sigma_{ik})^2 + \\frac{(x_i - \\mu_{ik})^2}{(\\sigma_{ik})^2} \\right) \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The \"naive\" refers to the fact that we are assuming that all of the variable are independent. You can of course compute the covariance matrix to estimate the degree to which this is bullshit.\n",
    "\n",
    "But then you can use dimensionality reduction like PCA to help \"whiten\" the features and construct independent variables.\n",
    "\n",
    "Generally, naieve Bayes by itself is a bad idea because of the covariances, but PCA might also be a bad idea because it's a linear transformation and the covariance may not be linear.\n",
    "\n",
    "If instead, we relax that assumption and allow for covariances then:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Linear Discriminant Analysis\n",
    "\n",
    "In [Linear Discriminant Analysis (LDA)](https://en.wikipedia.org/wiki/Linear_discriminant_analysis) we assume that the class distributions have identical covariances for all $k$ classes (all classes are a set of shifted Gaussians). \n",
    "\n",
    "The class-dependent covariances that would normally give rise to a quadratic dependence on\n",
    "$X$ cancel out if they are assumed to be constant. \n",
    "\n",
    "The Bayes classifier is, therefore, linear with respect to $X$, and  discriminant boundary between classes is the line that minimizes the overlap between Gaussians.\n",
    "\n",
    "Basically, we're projecting N-dimensional data onto k new axes and finding what the optimal decision boundary is for each. Therefore LDA is also used for dimensionality reduction, but the new features may still be correlated.\n",
    "\n",
    "<img src=\"figures/lda.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Relaxing the requirement that the covariances of the Gaussians are constant, the discriminant function becomes quadratic in $X$.\n",
    "\n",
    "This is sometimes known as [Quadratic Discriminant Analysis (QDA)](https://en.wikipedia.org/wiki/Quadratic_classifier#Quadratic_discriminant_analysis).\n",
    "\n",
    "[`LDA`](http://scikit-learn.org/0.16/modules/generated/sklearn.lda.LDA.html) and [`QDA`](http://scikit-learn.org/0.16/modules/generated/sklearn.qda.QDA.html#sklearn.qda.QDA) are implemented in Scikit-Learn as follows and an example using the same data as above is given below.\n",
    "\n",
    "<img src=\"figures/lda_vs_qda.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-Nearest Neighbor Classifier\n",
    "\n",
    "These approaches are using a model for the population density. We can, just as in unsupervised learning, use linkage instead (or local density):\n",
    "\n",
    "[$k$-nearest-neighbors](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) ($k$NN) is simple and can be used for clasification and regression. \n",
    "\n",
    "The output is determined by examining the $k$ nearest neighbors in the training set, where $k$ is a user defined number. \n",
    "\n",
    "Typically, though not always, distances between sources are Euclidean, and the final classification is assigned to whichever class has a plurality within the $k$ nearest neighbors (in the case of regression, the average of the $k$ neighbors is the output from the model). \n",
    "\n",
    "The number of neighbors, $k$, regulates the complexity of the classification, where a larger $K$ decreases the variance in the classification but leads to an increase in the bias.  \n",
    "\n",
    "The distance measure is usually N-D Euclidean.  However, if the attributes have very different properties, then normalization, weighting, etc. may be needed.\n",
    "\n",
    "<img src=\"figures/knn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In-class exercise: Putting together the full supervised-learning workflow\n",
    "\n",
    "Data comes from [this paper.](https://ui.adsabs.harvard.edu/abs/2010ApJS..186..427N/abstract) where Preethi Nair (LSU) heroically visually classified 14,000 galaxies.\n",
    "\n",
    "Her T-Type morphology is much more fine-grained but it can be mapped to broad galaxy morphology.\n",
    "\n",
    "T-Type:\n",
    "- Ellipticals: -6 to -4  \n",
    "- Spirals: -3 to 7  \n",
    "- Irregular things: 7 and up\n",
    "\n",
    "So the morphology column in the file is just a letter: \n",
    "- Spiral: S \n",
    "- Elliptical: E \n",
    "- Other: N\n",
    "\n",
    "And that in turn, can be binarized as Ellipticals =1, Not Ellipticals = 0\n",
    "\n",
    "\n",
    "\n",
    "## 1. Clean the Data:\n",
    "\n",
    "Only learn on well defined morphologies, aka elliptical or spirals.\n",
    "\n",
    "## 2. Preprocess:\n",
    "\n",
    "The dataset incorporates lots of features, but there's also columns that give away the answer\n",
    "\n",
    "Therefore only use these:\n",
    "```\n",
    "feature_names = ['zs', 'g_mag', 'r_mag', 'sigma', 'M_L', 'SFRT', 'b_a', 'log_M_']\n",
    "```\n",
    "\n",
    "Normalize the features (you can try `MinMaxScaler` instead of the `StandardScaler`).\n",
    "Then split the data into a training and testing set (\n",
    "\n",
    "You may also want to encode the labels:\n",
    "\n",
    "```\n",
    "# encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y)\n",
    "```\n",
    "\n",
    "## 3. Build models\n",
    "\n",
    "You already know how to use the Random Forest. Now try LDA and kNN.\n",
    "\n",
    "\n",
    "## 4. Evaluate performance\n",
    "\n",
    "Since we made this a two class problem, plot the confusion matrix and the ROC curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import astropy.table as at\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.neighbors import KNeighborsClassifier as kNN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=14034</i>\n",
       "<table id=\"table140372240280848\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>SDSS</th><th>zs</th><th>g_mag</th><th>r_mag</th><th>Rp</th><th>log_M_</th><th>Age</th><th>SFRT</th><th>SFRM</th><th>mug</th><th>M_L</th><th>b_a</th><th>sigma</th><th>e_sigma</th><th>TT</th><th>RA</th><th>DEC</th><th>Morphology</th><th>Morphology_i</th></tr></thead>\n",
       "<thead><tr><th></th><th></th><th>mag</th><th>mag</th><th>kpc</th><th>[solMass]</th><th>Gyr</th><th>solMass / yr</th><th>1 / yr</th><th>mag / arcsec2</th><th>Sun</th><th></th><th>km / s</th><th>km / s</th><th></th><th>deg</th><th>deg</th><th></th><th></th></tr></thead>\n",
       "<thead><tr><th>str20</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>int32</th><th>float32</th><th>float32</th><th>str1</th><th>int64</th></tr></thead>\n",
       "<tr><td>J155341.74-003422.84</td><td>0.078</td><td>15.82</td><td>15.058</td><td>18.669</td><td>11.083</td><td>4.459</td><td>1.014</td><td>-9.958</td><td>22.631</td><td>0.194</td><td>0.794</td><td>143.68</td><td>7.89</td><td>3</td><td>238.42392</td><td>-0.573011</td><td>S</td><td>0</td></tr>\n",
       "<tr><td>J155146.83-000618.62</td><td>0.055</td><td>15.512</td><td>14.606</td><td>12.185</td><td>11.245</td><td>7.111</td><td>0.896</td><td>-10.94</td><td>22.439</td><td>0.329</td><td>0.954</td><td>204.81</td><td>5.36</td><td>-5</td><td>237.94511</td><td>-0.105172</td><td>E</td><td>1</td></tr>\n",
       "<tr><td>J154453.22+002415.48</td><td>0.034</td><td>15.631</td><td>14.838</td><td>6.12</td><td>10.405</td><td>4.287</td><td>-0.012</td><td>-10.835</td><td>22.47</td><td>0.094</td><td>0.848</td><td>129.97</td><td>5.46</td><td>-2</td><td>236.22176</td><td>0.4043</td><td>S</td><td>0</td></tr>\n",
       "<tr><td>J154711.32+002424.81</td><td>0.033</td><td>15.716</td><td>15.158</td><td>11.094</td><td>10.156</td><td>1.901</td><td>1.109</td><td>-9.926</td><td>22.631</td><td>0.045</td><td>0.854</td><td>45.25</td><td>12.27</td><td>4</td><td>236.79716</td><td>0.406892</td><td>S</td><td>0</td></tr>\n",
       "<tr><td>J154514.39+004619.89</td><td>0.013</td><td>15.341</td><td>14.956</td><td>6.917</td><td>9.173</td><td>1.891</td><td>-1.738</td><td>-10.288</td><td>22.533</td><td>-0.077</td><td>0.329</td><td>89.32</td><td>14.59</td><td>5</td><td>236.30997</td><td>0.772192</td><td>S</td><td>0</td></tr>\n",
       "<tr><td>J155255.43+004304.87</td><td>0.033</td><td>15.86</td><td>15.084</td><td>3.46</td><td>10.484</td><td>6.842</td><td>0.437</td><td>-11.138</td><td>22.129</td><td>0.265</td><td>0.76</td><td>188.82</td><td>5.21</td><td>-5</td><td>238.23096</td><td>0.718019</td><td>E</td><td>1</td></tr>\n",
       "<tr><td>J155357.40+004117.11</td><td>0.039</td><td>15.784</td><td>15.147</td><td>6.882</td><td>10.627</td><td>2.004</td><td>0.461</td><td>-9.978</td><td>22.174</td><td>0.273</td><td>0.486</td><td>102.61</td><td>7.84</td><td>1</td><td>238.48917</td><td>0.688086</td><td>S</td><td>0</td></tr>\n",
       "<tr><td>J110122.00-010824.89</td><td>0.074</td><td>15.588</td><td>14.628</td><td>17.776</td><td>11.442</td><td>7.491</td><td>0.176</td><td>-11.327</td><td>22.463</td><td>0.28</td><td>0.755</td><td>285.78</td><td>6.63</td><td>-5</td><td>165.34167</td><td>-1.140247</td><td>E</td><td>1</td></tr>\n",
       "<tr><td>J112000.06-010711.96</td><td>0.025</td><td>15.97</td><td>15.892</td><td>3.131</td><td>9.119</td><td>0.503</td><td>0.171</td><td>-9.034</td><td>21.056</td><td>-0.389</td><td>0.562</td><td>40.34</td><td>17.84</td><td>0</td><td>170.00024</td><td>-1.119989</td><td>S</td><td>0</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>J131146.22+143413.48</td><td>0.027</td><td>15.764</td><td>15.034</td><td>2.47</td><td>10.287</td><td>0.0</td><td>-2.031</td><td>-11.864</td><td>22.124</td><td>0.0</td><td>0.825</td><td>128.75</td><td>3.1</td><td>0</td><td>197.94258</td><td>14.570411</td><td>S</td><td>0</td></tr>\n",
       "<tr><td>J131952.50+142325.08</td><td>0.071</td><td>15.674</td><td>15.274</td><td>11.607</td><td>10.743</td><td>1.855</td><td>0.168</td><td>-9.735</td><td>21.747</td><td>-0.03</td><td>0.877</td><td>62.97</td><td>7.55</td><td>4</td><td>199.96875</td><td>14.3903</td><td>S</td><td>0</td></tr>\n",
       "<tr><td>J132155.38+141957.80</td><td>0.024</td><td>15.225</td><td>14.618</td><td>9.272</td><td>10.026</td><td>2.727</td><td>-1.103</td><td>-9.869</td><td>22.737</td><td>0.052</td><td>0.488</td><td>28.01</td><td>42.59</td><td>5</td><td>200.48074</td><td>14.332722</td><td>S</td><td>0</td></tr>\n",
       "<tr><td>J130800.20+150102.07</td><td>0.064</td><td>15.961</td><td>15.366</td><td>18.042</td><td>10.898</td><td>3.222</td><td>0.277</td><td>-9.676</td><td>22.683</td><td>0.237</td><td>0.668</td><td>82.3</td><td>8.66</td><td>4</td><td>197.00082</td><td>15.017242</td><td>S</td><td>0</td></tr>\n",
       "<tr><td>J131901.87+144727.65</td><td>0.023</td><td>15.105</td><td>14.551</td><td>5.941</td><td>10.1</td><td>2.118</td><td>-0.672</td><td>-9.698</td><td>22.164</td><td>0.047</td><td>0.52</td><td>55.85</td><td>7.56</td><td>5</td><td>199.7578</td><td>14.791014</td><td>S</td><td>0</td></tr>\n",
       "<tr><td>J124719.07+154235.64</td><td>0.069</td><td>15.786</td><td>14.906</td><td>16.597</td><td>11.258</td><td>7.986</td><td>-0.217</td><td>-10.721</td><td>22.535</td><td>0.305</td><td>0.565</td><td>195.68</td><td>6.66</td><td>2</td><td>191.82945</td><td>15.7099</td><td>S</td><td>0</td></tr>\n",
       "<tr><td>J130510.16+152606.67</td><td>0.053</td><td>15.318</td><td>14.598</td><td>10.95</td><td>10.935</td><td>4.255</td><td>-0.052</td><td>-10.182</td><td>22.354</td><td>0.187</td><td>0.707</td><td>121.74</td><td>5.39</td><td>2</td><td>196.29233</td><td>15.435186</td><td>S</td><td>0</td></tr>\n",
       "<tr><td>J131525.21+152522.23</td><td>0.027</td><td>15.255</td><td>14.349</td><td>5.514</td><td>10.742</td><td>0.0</td><td>-1.075</td><td>-11.132</td><td>22.265</td><td>0.0</td><td>0.349</td><td>243.68</td><td>4.62</td><td>1</td><td>198.85504</td><td>15.422842</td><td>S</td><td>0</td></tr>\n",
       "<tr><td>J132045.57+151532.75</td><td>0.023</td><td>15.724</td><td>14.936</td><td>5.177</td><td>10.25</td><td>4.399</td><td>-0.534</td><td>-9.987</td><td>22.781</td><td>0.337</td><td>0.609</td><td>65.21</td><td>5.18</td><td>0</td><td>200.18987</td><td>15.259097</td><td>S</td><td>0</td></tr>\n",
       "<tr><td>J132135.96+151917.80</td><td>0.023</td><td>15.471</td><td>14.805</td><td>3.879</td><td>10.313</td><td>5.76</td><td>-0.848</td><td>-10.41</td><td>22.171</td><td>0.301</td><td>0.45</td><td>120.39</td><td>3.95</td><td>3</td><td>200.39983</td><td>15.321611</td><td>S</td><td>0</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=14034>\n",
       "        SDSS            zs    g_mag  ...    DEC    Morphology Morphology_i\n",
       "                               mag   ...    deg                           \n",
       "       str20         float32 float32 ...  float32     str1       int64    \n",
       "-------------------- ------- ------- ... --------- ---------- ------------\n",
       "J155341.74-003422.84   0.078   15.82 ... -0.573011          S            0\n",
       "J155146.83-000618.62   0.055  15.512 ... -0.105172          E            1\n",
       "J154453.22+002415.48   0.034  15.631 ...    0.4043          S            0\n",
       "J154711.32+002424.81   0.033  15.716 ...  0.406892          S            0\n",
       "J154514.39+004619.89   0.013  15.341 ...  0.772192          S            0\n",
       "J155255.43+004304.87   0.033   15.86 ...  0.718019          E            1\n",
       "J155357.40+004117.11   0.039  15.784 ...  0.688086          S            0\n",
       "J110122.00-010824.89   0.074  15.588 ... -1.140247          E            1\n",
       "J112000.06-010711.96   0.025   15.97 ... -1.119989          S            0\n",
       "                 ...     ...     ... ...       ...        ...          ...\n",
       "J131146.22+143413.48   0.027  15.764 ... 14.570411          S            0\n",
       "J131952.50+142325.08   0.071  15.674 ...   14.3903          S            0\n",
       "J132155.38+141957.80   0.024  15.225 ... 14.332722          S            0\n",
       "J130800.20+150102.07   0.064  15.961 ... 15.017242          S            0\n",
       "J131901.87+144727.65   0.023  15.105 ... 14.791014          S            0\n",
       "J124719.07+154235.64   0.069  15.786 ...   15.7099          S            0\n",
       "J130510.16+152606.67   0.053  15.318 ... 15.435186          S            0\n",
       "J131525.21+152522.23   0.027  15.255 ... 15.422842          S            0\n",
       "J132045.57+151532.75   0.023  15.724 ... 15.259097          S            0\n",
       "J132135.96+151917.80   0.023  15.471 ... 15.321611          S            0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = at.Table.read('data/SDSS_morphology.fit')\n",
    "data.convert_bytestring_to_unicode()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data[data['Morphology'] != 'N']\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(np.array(data_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['zs', 'g_mag', 'r_mag', 'sigma', 'M_L', 'SFRT', 'b_a', 'log_M_']\n",
    "X = df[feature_names]\n",
    "y = df['Morphology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode labels - or we could just morphology_i\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=15)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## YOUR CODE HERE\n",
    "\n",
    "#knn = kNN(...\n",
    "#knn.fit(...\n",
    "\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))\n",
    "\n",
    "## YOUR CODE HERE\n",
    "#rf = RandomForestClassifier(...\n",
    "#rf.fit(....\n",
    "\n",
    "print('Accuracy of RF classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))\n",
    "print('Accuracy of RF classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))\n",
    "\n",
    "## YOUR CODE HERE\n",
    "#lda = LDA(...\n",
    "#lda.fit(...\n",
    "print('Accuracy of LDA classifier on training set: {:.2f}'\n",
    "     .format(lda.score(X_train, y_train)))\n",
    "print('Accuracy of LDA classifier on test set: {:.2f}'\n",
    "     .format(lda.score(X_test, y_test)))\n",
    "\n",
    "## YOUR CODE HERE\n",
    "#knn2 = kNN(...\n",
    "#knn2.fit(...\n",
    "\n",
    "print('Accuracy of KNN classifier on training set w/ 30 neighbors: {:.2f}'\n",
    "     .format(knn2.score(X_train, y_train)))\n",
    "print('Accuracy of KNN classifier on test set w/ 30 neighbors: {:.2f}'\n",
    "     .format(knn2.score(X_test, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_knn = knn.predict_proba(X_test)[:,1]\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test, y_score_knn)\n",
    "\n",
    "y_score_rf = rf.predict_proba(X_test)[:,1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_score_rf)\n",
    "\n",
    "y_score_lda = lda.predict_proba(X_test)[:,1]\n",
    "fpr_lda, tpr_lda, _ = roc_curve(y_test, y_score_lda)\n",
    "\n",
    "y_score_knn2 = knn2.predict_proba(X_test)[:,1]\n",
    "fpr_knn2, tpr_knn2, _ = roc_curve(y_test, y_score_knn2)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_knn, tpr_knn, color='C0', lw=lw, label='kNN w/ 3 neighbors')\n",
    "plt.plot(fpr_rf, tpr_rf, color='C1', lw=lw, label='RF (deliberately crap)')\n",
    "plt.plot(fpr_lda, tpr_lda, color='C2', lw=lw, label='LDA')\n",
    "plt.plot(fpr_knn2, tpr_knn2, color='C3', lw=lw, label='kNN w/ 30 neighbors')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='k', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(10, 10), nrows=2, ncols=2)\n",
    "\n",
    "plot_confusion_matrix(knn, X_test, y_test, normalize='true', cmap='Blues', ax=axs[0][0])\n",
    "ax = axs[0][0]\n",
    "ax.set_title('kNN w/ 3 Neighbors')\n",
    "\n",
    "plot_confusion_matrix(knn2, X_test, y_test, normalize='true', cmap='Blues', ax=axs[0][1])\n",
    "ax = axs[0][1]\n",
    "ax.set_title('kNN w/ 30 Neighbors')\n",
    "\n",
    "plot_confusion_matrix(lda, X_test, y_test, normalize='true', cmap='Blues', ax=axs[1][0])\n",
    "ax = axs[1][0]\n",
    "ax.set_title('LDA')\n",
    "\n",
    "plot_confusion_matrix(rf, X_test, y_test, normalize='true', cmap='Blues', ax=axs[1][1])\n",
    "ax = axs[1][1]\n",
    "ax.set_title('RF');\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('kNN w/ 3 neighbors\\n', classification_report(y_test, knn.predict(X_test)))\n",
    "\n",
    "print('kNN w/ 30 neighbors\\n', classification_report(y_test, knn2.predict(X_test)))\n",
    "\n",
    "print('LDA', classification_report(y_test, lda.predict(X_test)))\n",
    "\n",
    "print('Deliberately Crap RF', classification_report(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Appendix: Extreme Deconvolution\n",
    "\n",
    "Real data come with uncertainties\n",
    "\n",
    "Extreme Deconvolution is parametric density estimation on a *noisy* d-dimensional dataset\n",
    "- Straightforward generalization of Gaussian Mixture Models conceptually but much slower\n",
    "    \n",
    "\n",
    "You have some real obsevations $\\mathbf{x}_i$ in d-dimensions *with zero-mean Gaussian noise* $\\epsilon_i$ with known per-datapoint covariance $S_i$ to a projection $R_i$ of a true value $\\mathbf{v}_i$\n",
    "\n",
    "\n",
    "## $$\n",
    "\\mathbf{x}_{i}=R_{i} \\mathbf{v}_{i}+\\epsilon_{i}, \\quad \\epsilon_{i} \\sim \\mathcal{N}\\left(\\mathbf{0}, S_{i}\\right)\n",
    "$$\n",
    "\n",
    "We assume that $\\mathbf{v}_i$ can be modelled by a mixture of Gaussians with K components (i.e. a GMM):\n",
    "\n",
    "## $$\n",
    "p\\left(\\mathbf{v}_{i} | \\theta\\right)=\\sum_{j}^{K} \\alpha_{j} \\mathcal{N}\\left(\\mathbf{v} | \\mathbf{\\mu}_{j}, \\Sigma_{j}\\right)$$\n",
    "\n",
    "with the components mean the mean, covariance and mixture coefficients of each Gaussian being the parameters that we solve for as before:\n",
    "\n",
    "## $$\\theta=\\left\\{\\alpha_{j}, \\mathbf{\\mu}_{j}, \\Sigma_{j}\\right\\}_{j=1}^{K}\n",
    "$$\n",
    "\n",
    "\n",
    "Just as before the likelihood is easy:\n",
    "## $$\n",
    "\\mathcal{L}(\\theta)=\\sum_{i}^{N} \\log \\sum_{j}^{K} \\alpha_{j} \\mathcal{N}\\left(\\mathbf{x}_{i} | R_{i} \\mathbf{\\mu}_{j}, C_{i j}\\right)$$\n",
    "\n",
    "#### BUT NOW THE COVARIANCE MATRIX INCLUDES THE ERRORS IN THE OBSERVATIONS\n",
    "\n",
    "## $$ C_{i j}=R_{i} \\Sigma_{j} R_{i}^{T}+S_{i}\n",
    "$$\n",
    "\n",
    "Now instead of estimating the covariance of just the $k$ GMM components, you now have the the $n \\times n$ covariance matrix of the observations.\n",
    "\n",
    "This is unfortunate because the covariance matrix appears as the inverse in the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from astroML.density_estimation import XDGMM\n",
    "from astroML.crossmatch import crossmatch\n",
    "from astroML.datasets import fetch_sdss_S82standards, fetch_imaging_sample\n",
    "from astroML.plotting.tools import draw_ellipse\n",
    "from astroML.utils.decorators import pickle_results\n",
    "from astroML.stats import sigmaG\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# This function adjusts matplotlib settings for a uniform feel in the textbook.\n",
    "# Note that with usetex=True, fonts are rendered with LaTeX.  This may\n",
    "# result in an error if LaTeX is not installed on your system.  In that case,\n",
    "# you can set usetex to False.\n",
    "if \"setup_text_plots\" not in globals():\n",
    "    from astroML.plotting import setup_text_plots\n",
    "setup_text_plots(fontsize=8, usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# define u-g-r-i-z extinction from Berry et al, arXiv 1111.4985\n",
    "# multiply extinction by A_r\n",
    "extinction_vector = np.array([1.810, 1.400, 1.0, 0.759, 0.561])\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Fetch and process the noisy imaging data\n",
    "data_noisy = fetch_imaging_sample()\n",
    "\n",
    "# select only stars\n",
    "data_noisy = data_noisy[np.where(data_noisy['type'] == 6)[0]]\n",
    "\n",
    "# Get the extinction-corrected magnitudes for each band\n",
    "X = np.vstack([data_noisy[f + 'RawPSF'] for f in 'ugriz'])\n",
    "Xerr = np.vstack([data_noisy[f + 'psfErr'] for f in 'ugriz'])\n",
    "\n",
    "# extinction terms from Berry et al, arXiv 1111.4985\n",
    "X -= (extinction_vector * data_noisy['rExtSFD'][:, None]).flatten().T\n",
    "\n",
    "X = X.T\n",
    "Xerr = Xerr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------\n",
    "# Fetch and process the stacked imaging data\n",
    "data_stacked = fetch_sdss_S82standards()\n",
    "\n",
    "# cut to RA, DEC range of imaging sample\n",
    "RA = data_stacked['RA']\n",
    "DEC = data_stacked['DEC']\n",
    "data_stacked = data_stacked[(RA > 0) & (RA < 10) &\n",
    "                            (DEC > -1) & (DEC < 1)]\n",
    "\n",
    "# get stacked magnitudes for each band\n",
    "Y = np.vstack([data_stacked['mmu_' + f] for f in 'ugriz']).T\n",
    "Yerr = np.vstack([data_stacked['msig_' + f] for f in 'ugriz']).T\n",
    "\n",
    "# extinction terms from Berry et al, arXiv 1111.4985\n",
    "Y -= (extinction_vector * data_stacked['A_r'][:, None]).squeeze()\n",
    "\n",
    "# quality cuts\n",
    "g = Y[:, 1]\n",
    "mask = ((Yerr.max(1) < 0.05) &\n",
    "        (g < 20))\n",
    "data_stacked = data_stacked[mask]\n",
    "Y = Y[mask]\n",
    "Yerr = Yerr[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of noisy points:   (82003, 2)\n",
      "number of stacked points: (13377, 2)\n",
      "(82003, 5) (13377, 5)\n",
      "size after crossmatch: (12313, 5)\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------\n",
    "# cross-match\n",
    "#  the imaging sample contains both standard and variable stars.  We'll\n",
    "#  perform a cross-match with the standard star catalog and choose objects\n",
    "#  which are common to both.\n",
    "Xlocs = np.hstack((data_noisy['ra'][:, np.newaxis],\n",
    "                   data_noisy['dec'][:, np.newaxis])).squeeze()\n",
    "Ylocs = np.hstack((data_stacked['RA'][:, np.newaxis],\n",
    "                   data_stacked['DEC'][:, np.newaxis]))\n",
    "\n",
    "print(\"number of noisy points:  \", Xlocs.shape)\n",
    "print(\"number of stacked points:\", Ylocs.shape)\n",
    "\n",
    "# find all points within 0.9 arcsec.  This cutoff was selected\n",
    "# by plotting a histogram of the log(distances).\n",
    "dist, ind = crossmatch(Xlocs, Ylocs, max_distance=0.9 / 3600)\n",
    "\n",
    "noisy_mask = np.where(~np.isinf(dist))[0]\n",
    "stacked_mask = ind[noisy_mask]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# select the data\n",
    "data_noisy = data_noisy[noisy_mask]\n",
    "X = X[noisy_mask,:]\n",
    "Xerr = Xerr[noisy_mask,:]\n",
    "\n",
    "data_stacked = data_stacked[stacked_mask]\n",
    "Y = Y[stacked_mask]\n",
    "Yerr = Yerr[stacked_mask]\n",
    "\n",
    "# double-check that our cross-match succeeded\n",
    "assert X.shape == Y.shape\n",
    "print(\"size after crossmatch:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------\n",
    "# perform extreme deconvolution on the noisy sample\n",
    "\n",
    "# first define mixing matrix W\n",
    "W = np.array([[0, 1, 0, 0, 0],    # g magnitude\n",
    "              [1, -1, 0, 0, 0],   # u-g color\n",
    "              [0, 1, -1, 0, 0],   # g-r color\n",
    "              [0, 0, 1, -1, 0],   # r-i color\n",
    "              [0, 0, 0, 1, -1]])  # i-z color\n",
    "\n",
    "X = np.dot(X, W.T)\n",
    "Y = np.dot(Y, W.T)\n",
    "\n",
    "# compute error covariance from mixing matrix\n",
    "Xcov = np.zeros(Xerr.shape + Xerr.shape[-1:])\n",
    "Xcov[:, range(Xerr.shape[1]), range(Xerr.shape[1])] = Xerr ** 2\n",
    "\n",
    "# each covariance C = WCW^T\n",
    "# best way to do this is with a tensor dot-product\n",
    "Xcov = np.tensordot(np.dot(Xcov, W.T), W, (-2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@pickle_results: computing results and saving to 'XD_stellar.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mcoughlin/opt/anaconda3/envs/ast8581/lib/python3.7/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: log(L) = 32868\n",
      "    (45 sec)\n",
      "2: log(L) = 33422\n",
      "    (33 sec)\n",
      "3: log(L) = 33742\n",
      "    (22 sec)\n",
      "4: log(L) = 33967\n",
      "    (21 sec)\n",
      "5: log(L) = 34155\n",
      "    (20 sec)\n",
      "6: log(L) = 34307\n",
      "    (22 sec)\n",
      "7: log(L) = 34418\n",
      "    (28 sec)\n",
      "8: log(L) = 34507\n",
      "    (23 sec)\n",
      "9: log(L) = 34583\n",
      "    (21 sec)\n",
      "10: log(L) = 34648\n",
      "    (25 sec)\n",
      "11: log(L) = 34707\n",
      "    (22 sec)\n",
      "12: log(L) = 34762\n",
      "    (28 sec)\n",
      "13: log(L) = 34818\n",
      "    (25 sec)\n",
      "14: log(L) = 34884\n",
      "    (40 sec)\n",
      "15: log(L) = 34943\n",
      "    (37 sec)\n",
      "16: log(L) = 34988\n",
      "    (42 sec)\n",
      "17: log(L) = 35028\n",
      "    (30 sec)\n",
      "18: log(L) = 35066\n",
      "    (22 sec)\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------\n",
    "# This is a long calculation: save results to file\n",
    "@pickle_results(\"XD_stellar.pkl\")\n",
    "def compute_XD(n_clusters=12, rseed=0, max_iter=100, verbose=True):\n",
    "    np.random.seed(rseed)\n",
    "    clf = XDGMM(n_clusters, max_iter=max_iter, tol=1E-5, verbose=verbose)\n",
    "    clf.fit(X, Xcov)\n",
    "    return clf\n",
    "\n",
    "\n",
    "clf = compute_XD(12)\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Fit and sample from the underlying distribution\n",
    "np.random.seed(42)\n",
    "X_sample = clf.sample(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoMAAAINCAYAAABF1HUmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAB9vUlEQVR4nO3921NbV9ov+n+HppDEWZwEBmMw7hwcSDcvUvq97Krd5OK9XeUkN+9tk1rmggra5ez+C7Kd+kGKC1jb9O26Scf79weseNWqVK1V6+02ECcBJ3FibGNsziAJobM09gXMmSkhCQE6Tn0/VSrD1IE5E/P4mWOM5xlCSgkiIiIiqk6mUp8AEREREZUOk0EiIiKiKsZkkIiIiKiKMRkkIiIiqmJMBomIiIiqGJNBIiIioipmLvUJZNPe3i77+/vP9Z6dnR10dHQU5oTKVDVeM1Cd112N1wyU53UvLi7uSilPndR541Y5Xlsx8LqrRzVeM1Ce150pbpV1Mtjf34+FhYVzvcflcp37PZWuGq8ZqM7rrsZrBsrzuoUQL9IdP2/cKsdrKwZed/WoxmsGyvO6M8UtThMTERERVTEmg0RERERVzHDJ4NjYWKlPoeiq8ZqB6rzuarxmwNjXbeRry4bXXT2q8ZqByrpuUc57E7tcLllu8+1ERAAghFiUUrpSjzNuEVG5yhS3DDcySERERES5YzJIREREVMWYDBIRERFVMSaDRERERFWMyWAOPB4PHjx4ULDXExHlw9LSEpaWlgz784ioMAybDHo8HszPz+PBgwf4+OOPteOrq6vn/iy73Y6vvvrq0q/P5zkRkfGkixFLS0uYn5/P6f0DAwP48ssvs75maWkJN27cwIMHD3D//n188MEH8Hg8FzrfXH4eEZW/st6O7jL+/ve/48MPP4TdbteSrdXVVdy/fx937tzhORFR2UkXI0ZGRjAyMpK3nzEyMoKBgQGMjo7C4/FgdHQUq6uref0ZRFRZDJsMulwu/PnPf8ZHH32kNX5cWlrCw4cPtWmNhYUFeDwejI2N4cGDB/jyyy/x8ccfY2lpCXfu3MHq6ioePHiAgYEB7O/va5+R+r6vv/4aAPDpp5+eev1lz0n97A8++EB7PRNHImNKFyMePHiApaUlbRQuXYzyeDyw2+348MMPAUA7DgCjo6MYGBhI+jn7+/u4f/8+vvzyS3z11VcYGRnRvv/oo4/w8OFD3L17V7tZHRgYgN1ux8DAAO7fvw+73Q6Xy4WBgQEsLS1p58jYRFSZDDtNPDIygv/+3/87BgYGtERqZGQE7733nnan3draCuA42I6OjqK1tRWjo6N4+vQpAODu3bv48MMPtefUz0h9n91ux71799K+/rLnpH720tISvv76a4yOjhb2PxwRlUy6GOFyubC3t5c2Ri0tLcHlOu4fq48Nn376qZaspVuG0trailu3buGjjz4CcJw8jo6O4r333sOtW7fQ1taG+/fv49NPP8WdO3dw69YtLcbdunULY2NjWoKpjjKq50RElcewyeD8/Dzsdjtu3bqFjz/+GB6PR0u0VldX8emnn2JgYCBpasRut5/5uene19bWVrBzUj9bfc9nn32W088iosqTLkbopcYoNdlTp35TnxsdHdWSxXRu3boFADkVgXg8Huzv72sxSz2XXOImEZU3w04TA8D9+/cBHE+JqAFrb28Pq6uruHHjBlZXV7G/v4/FxUWYzWYsLS1hdXUVCwsLWnL297//HQMDA9qx1Pf5/X48fPgQHo8n7etTA/R5zkn/2ffv38fIyAjef//9ov33I6LiS40RDx480OJSaoyy2+348ssvMTAwgNbWVuzv72N1dRV3797F/Py8liTqEzb1M9Tp5S+//BJ//etfAQAPHz7EgwcPsLe3hzt37mBkZATz8/NobW3VblY/++wzbTZjdXX11DmlxjwiKn/cm5iI6ALKYW/izz//HGNjY7Db7fj4449x7969C3+WWsnMdX9ExpUpbhl6ZJCIyMjUWQgAcDqdl/qsBw8e4OHDh/k4LSKqMEwGiYgqlLrmL1+flc/PI6LKYdgCEiIiIiI6G5NBIiIioirGZJCIiIioijEZJCIiIqpiTAaJiIiIqhiTQSIiIqIqVpRkUAhhF0KMCiHupBwfEEIsCiHuCSHYtp6IiIioyIqSDEopPQBWAaTbxPfPUsqPpZSnd1MnIiIiKjG32w2bzQa3213qUymIcpgm/lAIMSaEGCn1iRARERGlmp2dRTgcxtzcXKlPpSBKmgxKKVellPNSynkAH5fyXIiIiIjSGR8fh81mw+3bt0t9KgVR0mTwZETQfvJta+rzOzs7cLlc2mN+fr64J0hEpDM/P6/FIwDt6V7DuEVkPFNTUwgGg5iamir1qZxbLnFLSCmLcjJCiDEAH+C3EcBbAO4DGDh5PEhdN+hyuaS6CTsRGYfb7cbs7CzGx8crMrgCgBBiUUrpSj3OuEVE5SpT3CpaMngRDKpExmSz2RAOh2Gz2RAMBkt9OhfCZJCIKk2muFUOBSREVGWMvv6GiKiSmEt9AkRUfaampip2epiIyGg4MkhEBWX0/lxERJWOySARFZTR+3MREVU6JoNEVFBcH0hEVN64ZpCICorrA4mIyhtHBomIiIjOYOT1z0wGiYiIiM5g5PXPTAaJiIiIzmDk9c9cM0hERER0BiOvf+bIIBEREVEVYzJIREREVMWYDBIRERFVMSaDRFQURm7LQETGU00xi8kgERWFkdsyEJHx5BKzjJIwMhkkoqIwclsGIjKeXGKWUW5ymQwSUVFMTU0hGAymbc1glLtrIipv54k12WKWyig3uUwGiejSUgPseZM7o9xdE1F5SxdrLnMzmkvCWAmYDBLRpaUG2EzJXaagOzQ0BAAYHBwszgkTUVVKN5Knxqvp6emqnZ1gMkhEl5YaYNMFXLfbjenp6bRJ4vLyMgBgZWWleCdNRFUn3Uje+Pi49vXc3FxVLlthMkhEl+J2uzE7O4vbt29rATZdwJ2dndW+Tl1fY5R1N0RUeaampjA5OanFoJmZGYTDYczMzGR9n5GSRiGlLPU5ZORyueTCwkKpT4OIsrDZbAiHw7DZbAgGgxlf53a7MTc3l5Q0VjIhxKKU0pV6nHGLqLKZzWbE43EoioJYLJbxdbnGvnKSKW5xZJCILiXXUT2jLLQmImObmJiAzWbDxMRE1tcZaUaDI4NEVBTqdPLQ0BCWl5cxPj5e0YkhRwaJqNJwZJCISkqt2FtcXMxpPQ4RUSnp1wQaaX1gOkwGiago1CkVIUSpT4WI6Ez6FllG74XKZJCIikJdM/jJJ5/ktB6HiKiU9GsCx8fHoSgKotFo1tHBSh1BZDJIREV1ViFJpQZTIjIGNQYB0GLV1NSUVmWcrTl1pY4gMhkkorJSqcGUiCrDWTecmWJQanPqdCq1wpjJIBGdqZijddyajogK6awbzkwJXWpz6nQqtYUWk0EiOlOuo3X5SBq5NR0RFYrb7UYsFoOiKOdK6NJNHRsJk0EiOlO2qQ99AphL0uh2u2E2m2E2m9MmjZU6zUJE5W92dhbxeBw1NTXnSuiMvnyFySARnSnb1Ic+SGZK5FITxng8jng8njawVuo0CxGVv7NuNtP1FnS5XGeOJlY67kBCRJdy1p7Dbrcb09PTAJC0ETxwvO1TpSZ93IGEyHj0+w1LKREOh7XnztqruBJkiltMBomooNTgCgAOhwNer7fit6IDmAwSGZH+5hY4rhoOhUIAACEEEolEKU/v0rgdHRGVhL4dw/b2tqHX3RBRZdMvU1G/VhQFAGAynU6ZjNIXlckgERWcoihQFAVOp5PFIURU9vRJ3sTERMZdk4xSWMJkkIgKSl+9t7CwkLY4xCh310RUmVJjkD7Jy9ZqZmhoyBA3uEwGiaigUqv30lXrzczMGOLumogqU+oI31lVx+rrV1ZWDNH9gMkgEV1atpG91LtqfdBVvwZgiLtrIqpMqcnfWS2ujNYPlckgEV3aedbN6IOo+vXExIQh7q6JqDJlmwrW3+QadScSJoNEdGnnvUtWW1qxwTQRlat0N7lGKRhJxWSQiC7tPEndWcGUxSREVGqZ9jA22vSwiskgERVUanKX68Jso915E1Hl0HdBAKDtp/7NN98g22YdlXozW5RkUAhhF0KMCiHupDl+RwhxSwgxUoxzIaLiUpO76elpuN1ubRTxm2++gRACJpMpKXAa9c6biCqHPg7p91NfXFxMulnN1pKmkhQlGZRSegCsAmhLeWoMwLyU8j6Aj4pxLkRUXPodSGZmZrQ77MXFRQDH6wf1gZPrCImo1PRxaHx8PGPj/PO2pClXpZ4mfu8kUQSAgVKeCBHln9vtxuzsrBZAAWh32EIIAMf7fVZa4CQiY9OP+E1NTWFiYgJmsxkAkqaJz9uSplyJbHPfef1BQgwA+FhK+anu2FcA/iKl9AghvpZSvq9/T19fn+zo6NC+Hxsbw9jYWFHOl4guz2azIRwOw2azIRgMwu12Y2ZmBgAwPDyM5eVljI+PV0zgnJ+fx/z8PABgcXHxhZSyP/U1jFtElU+NXQAwOTmZ1BNVfT4YDJbq9M4ll7gFKWVRHjge+bubcuwOgIGTr79KfY/T6ZREVP4mJyel1WqVk5OTp47bbDbpdDpPPW+1WiUAqShK2veWOwALMk2sY9wiKn+ZYpb+eQASgLTZbEnfA6i4eKXKFLeKOU08CmBECDFw8rgDYB7ALSHEGIDPinguRJRH+nUzqdMrwWAQy8vLpxZdRyIRAEAikajIBddEVLnOKvSYmprC5OQkFEVBNBoFAO17RVGKeapFUbRkUEo5L6V8X0q5evL4XErpOflzXkq5VKxzIaL8Sq28Sw2yqetqZmdntXU3JpPp1ILrSm3PQESV4axCD3W9M3C8zlmNZ+qaZ318M0S8SjdcWC4PTrcQVR51ajjdNIo6NeN0OqWiKFJRlLSvU6eQbTZbMU75QsBpYiLD0i9jUeOZegwp08SVEK9UmeJWqauJichgslXTqaOGKysriMViiMViaV9Xqe0ZiMgY0u2brh6bnJxMilvq8cHBwYodIWQySER5o06XuFyutEEx1ySvUtszEFHlSZ3mVaeIb9++nRSDMsWlTGujK0nRWstchMvlkgsLC6U+DSLKkb4dAwAoigKz2VxR7WNyJYRYlFK6Uo8zbhFVFjVuqfEqFoshHo8nrYNWm+errbEmJiZOxTS32425ublTSWQ5yRS3ODJIRHmjjvypTabVSuGZmZkzRw2JiEpBjVsAtJtZddp3enpaG+3Tb0uXbvSvkmc0mAwSUd6owXBhYQHBYBAm028hRl0veNbenkRExaTGrYmJCa1tzO3bt7G8vKy95vbt20nb0hltPTOTQSIqGH1wHRoags1mg8PhAAAMDg4CqNyN3YnIWKampmA2m7WRP33ypz6fWvhmlJtZJoNElFepTacTiQTi8TiWlpYQDAbh9XoBACsrKwBYOUxE5UNNANVG02pyODMzkzbpM8rNLJNBIsqr1OCoFqlJKeFyuRAOhyGESNrYXV2kXel310RU2dKNDurXE6YmfUa5mWUySER5lRocnU6n9ufi4iKA48RQv8jaKHfXRFT59DFMv54wXdJXyUUjekwGiSivUoPjwsICpJRYWFjQEkMhRNIooFHuronIGPRt9zL1HTQSJoNEdGnZFlHrn1tYWIDVaoWUMmkU0Ch311SZjFIEQBen/zugzlTMzMzAbDZr7WUyrRs0AjadJqJLU5u22mw2BIPBpOfU9TeKoiAWi1VEY9ZcsOm0cWT7+0vVQd94WpVIJJJGCBVF0ZpRV+rfEzadpoLj3XX1Os80L0cBqdxwmUJ1c7vdiMViWiIYj8dRU1OT1Cd1cnIy7bpBw/y7J6Us24fT6ZRUOaxWqwQgbTZbqU+FSmByclJarVY5OTl56rjNZpOTk5MZX1OJACxIxi2iiqf/t0uNV06nUyqKIhVFSfo6NXZV2r97meIWRwYpb3h3Xd0yVQTrRwL1r3G73TCbzTCbzUkbxBviLpuIKka66uHl5WVthFD9Ot02dEb5d49rBokoL7KtBVQXZQ8NDWFlZQWDg4NamxkA2hqcSlq7xTWDRMalj2cAMDMzA+B4V6VKXuKSKW4xGSSigktN8tTvgeNF2WqAraTiEiaDRNVJvbkdHx8v+ziVigUkRFQyqVMp6veTk5OIxWIAoHX5Z3EJEZUz/XIXl8sFIQRcrlP5VUVhMkhEeZVuLWBqBXHqFnTcgYSIii2XNcrp4pn+5lZd7qJf9lKR0lWVlMuDVXlElUFfJaxW1wGQiqJox1MridNV8FVSlTFYTUxU0bJVAk9OTkpFUbRYlul1TqdTApCV8nufKW6VPOHL9qiU/7hE1S41sVMURQohkgKpPqCqr0nXqqFSMBkkqmyZbkInJydPxS19rKrkFlmZ4hYLSIjoUtxut1ZpNzw8jOXlZYyPj2tTv6kmJye15yqhajgTFpAQGVOmArfU5ysxfrGAhIgKYnZ2Nqkfl7qHZywWgxBCeyiKgsnJSQBAJBIBAAwODrK3IBGVVGoMGh8fh6IoUBQFw8PD2tpmtVhE3bau0nsL6nFkkIguRd8O5ptvvsHi4iKEEJBSpr1z1t9122w2SCkr8i6bI4NElc/tdmN6ehoAtKKQmZkZxOPxrO+rtHil4sggERWEvlJ4eXkZwPFaZCEEbt++faoaT3/Xffv2bcN08CeiyqAfCZydndWOn5UICiG0P40WrzgySER5o7/LBo6TQrPZnBRcHQ4Htre34XQ6Ucm/3xwZJKpM+jV/t2/fxtzcHAYHB7G8vIxIJILUvEgIAZPJVPG7jwAcGSSiAlLvtAHA6XRqx81mMxKJRNJrt7e3ARigLxcRVaTUvYjVfoHhcBgmk0mLZSqr1Yrh4WFMT09XfHPpTDgySESXlm27OXX9YCqODBJROdDHK4fDAa/XC5PJlHFNYDnnTWe58MigEGI45fsmIUR//k6NiCpduu3m1HWBJlNymFGripkwEVGh5dKtYHx8XPt6e3sb4XBY679ntVqTXutwOAp2rqWUyzSxAAAhxP8jhPgvAP4K4FZBz4qIyp6+MAT4bU9hdVF2W1sb4vH4qcXYNTU1Fb/uhogqg36rS31iqP96amoKk5OTsNlscDqdp25s9Xw+Xykuo/DSdaJO9wDwLwCaTx7Xc33fZR7s5E9UvvTbzum3adIfT/eoxK796YA7kBCVPf0uI2ps0m8zZ7PZTm0pl7rDiD5+Vfrvd6a4lXMBiZTyWyml9+TxLC+ZKBFVrNQWMaqhoaGM73E6nRwVJKKCSh31U9f+xWIxKIqS9Fq1eAT4rahNHU2cnp6G2+1Omhp+9OiRIZvks5qYiM5FXzk8MTEBAJiZmdGC46NHj069RwjBdYJEVBT6qWH9MXWnpImJCdhsNkxOTqa9OdVPDU9PT+Pf//3ftWlkAKc+2xDSDRdmewD4P877nos+Kn04lsiI1KkWm82WNH2iThULITJu8G4k4DQxUVnSTw1nOqafClaniYUQSc/rY5j62nSfXUkyxa2LJIP/6bzvueiDQZWo/OiDYWrSpwbV1IeaKKauxalkTAaJKsvk5KRUFEUqiqLdtAohkm5g9esLnU7nqfWFlS5T3Dp3n0EhxH+SUv7/LzoSeR7s10VUntSK4Wy9uIDjNjI1NTVac9fUfoSVjH0GiSpL6m5I6ej7our3TgeQcVq5knAHEiLKG3VNTjAYTFqQrbZlUP+cmJjQWs4Ap/sREhEVkrrG2eVyJSWCaoxK7RuoHyDT751uhEQwm4skgyLvZ0FEZSldw1a3241YLKZ9H4/HoSgKnE4nlpeXcfv2bSwsLGgjf/r3q5V9Rg6qRFQ+1BtX/faXajFbMBiE1+vVjtfW1kKI4xRH7XxQLTHr3MmglPL/LcSJEFHppSZ/6aryZmZm0k61qHt7fvHFF9pnpHs/EVG+ZLphVY+pI3vqSKB+hM/tdiMSiWjvk1LCYrEAAFZWVop7ISXGvYmJSJO6ps/tdmNubk6b1k1NBDPtO6xyOp1YWVnR1gwaCdcMEhWfepM5Pj6etA4ZOB7x++abb7RRwHRrkzs7O7G9vQ3gdPyanJwEgKSYp/9ZRpApbhWlKviiD1blEeXXWdW82dompNtZRF9pl+5hxCpiFVhNTFR0+tZWUia3gEltd5WurVW2eHXWzzKCTHEr52liIcT/KYRoOn8eSkTl4qxpW323fpPJBCEEXK7jm0h1xxG94eHhU5+hrh/UF4pwupiILktdr6zf9Ui/r/Dt27fhdDq118fjcXzxxRcwm80wmUzaPuoqdX0gcLxeUP86/RRzVRS8pcsQ0z1QxP6C6oN32ET5lWvD1NRRQFWmPoJIadh60Z9bScCRQaKiOmukTt8fMFucwskew6m9UvUPI40G6mWKW+dJBv9vAP/l5HGuxBCAHcAdALcAjOiODwBYBHAPwEDq+xhUiUpDHyRra2uzBlcAhkrycsVkkKiwUpeX6G8q9Q2k1e/TxaZMsUsIkfSZaoNpIYRhd02SMg/TxAC+BvB/SSn/M4Bn53gfAIwBmJdS3gfwUcpzf5ZSfiylXD3nZxJRHukr8L755hvteDAYTGrLkMro/beIqPjcbjemp6dPLS85zmd+22s4Ho9jZmYG09PT2mvU6V9FUfCnP/0JiqJAURStQET9HHWv4WAwiIWFBcRiMSQSCcRiseqLaekyxHw/AHyV4esBHCeKY9CNGKoP3mET5Ue6Ao7UO2t1CiZdUUi6u2sj3z3nAhwZJCoY/VKV1JE/dXRQv6WcPlbpRxD1z1mtVulwOJLeY9Tp4Ewyxa2iJYMA7Cdff53hNfdSj127dk06nU7tce/evcL9FyIyGH0CmK0CTx9cbTbbqWRQCJG2krga3bt3T4tHAJ7LNLGMcYvo4tR4pSZt6s1VanKoP6ZP+BRFSbrxTXcTq/4co61jziSXuFWsZPAOTtYEpowMjumSxK9S38c7bKKLSXcXrV8Po0/4hBDS6XRqAVR9bWoQTU0Qqx1HBonyL/XGU03e1NkJ/e+XekyfDKbGqHTPVUMCmEmmuFWUptNCCPtJ4ucBsHDy5y0A93E8VTwA4IFMWTfI5q1EF5PaiDW1Oau+2aqiKDCbzWmfS6UoCmpqagzZRPq82HSaKL/cbjdmZmYAAIlE4jhJEQIWiwWxWEzb+tJsNmNoaEhby6woStpdkVKbUKvSNaOuFpni1kX2Jj43KaVHSvm5lHJeSrkkpVw9+X5VSvng5DgLSIjyJN3m6uPj49rz+mRPXTCd7jk9RVEwMTFRFft0ElHxqUUhNTU1+OSTT2Cz2WAymbQbVZvNhng8fmqv4YmJCa3XoMPh0I7Pzc1heXlZ+z61/yn9pijJIBEVV+rm6uoWTumYTCbtjltRlKRGrIqiaEllVVbYEVFepO4hnO57fUNpNYZNTEzAZrNpN6KpnE6nFtuCwSC2traSmlDrb4wXFhZ4M5tJurnjcnlw7Q1RfqRbaI2U9TWplcbVsrj6osA1g1SlLrK9ZGoRm757gdVqPVURrF/DrP9ZqZ0NjLhlXCFlilslT/iyPRhUiZLpA6O+236mwKm+R991X8r0+wzT+TAZpGqjxhe1wCzXBEzfxkqNV2q18Hke6ntTb2JTb1yNuBd6vjAZJNKpxGChrxBW76b1gVJfJaxW4EkpT1UOp/saVV5hdxFMBqna6Efzcp05SO1skO5GNFNMyvRQf77+RjjdeXK08LRMcYtrBqkqzc7OnupsX0ip62PO+xq1G7+euhZGXeOnduNXv1Y3XE8kEtp7jmPBMZPJBEVRtO+L9d+CiMpfunikxpx0hWSZ4pd+rfLg4CAikQgAoLa2FgCSCj5MJhOcTqd2XF3HrB7Tu337NpaXl9PGcfU8WShyDukyxHJ58A6bCqXYa+JyuVPN9prUu2n9eZ813aLebTscjqSO/fpRRK4PPD9wZJBKoFizGucdXcv0en2sTTcqqPY/TY1XqXEutSm+vlE+Y1fuMsUtjgxSVUqtti20THeq+rvpbHez4+Pjp/bXtNlscLlc2N7ezvqzTabjX/Pt7W1IebwfZyKROFWlxwo7ovJXyFmNbPHI5XJBCAGX61SLOgCnY5z6WQC0+KLGMX3HglRSN3uhv8bU6mJ9xTFjVx6kyxDL5cE7bDK6bHffmaro9KN6qQ/1c1Ir89T1NbyLzh9wZJBKoJCjYeniUboRvWznlroFprqWWY1bqdXA6fY9V9+XaU0gXVymuFXyhC/bg0GVjEaf0KnVv+kWQqcWi0gpMwZL/TF1a7l0CSLlF5NBqkTZppnTJZqpbamy/f3WJ43qzWe2rS1TY5V+yYu+2IQxLH+YDBKViD74pkvSUqvtpDy9RjDT3bPT6cwabBVF4V11gTAZpEp03gRL3xZGv3d5utiij1P6+Jatv2lqTNQnpOn2I6bLYTJIVCL64KsfGVRHA/XJnHpn7HA4siZ52RJFTgcXB5NBqkS5TjOrN7H60Tp9+yr1e/2Iof45/e9BtnYy2ZawcGQw/zLFLRaQEBXY0NAQgOO2CiopJRYXF5P23HQ6nVoxyPb2Ntra2nL6/JWVFa1FjKIo3HKJqIqd1cYq16ILtVBFX6Cmb18FHO9rfpxfAIuLi0nPraysaOfS3Nyc9mcIIRAMBjPGLLaIKR4mg0R5ki4Iu1wubUP1R48eJW2urkokEhgcHDz13FlVwvpN1/WVwURUvS5bbazGMfUmNhuTyZSxMjgajWJmZiYpodT3NQWATz75JOvns1q4iNINF5bLg9MtVK7SLcJO3WszdY1grtO+mR7qNAzXAZYHcJqYSihTIUimaeDUrSxTt4dLXbZis9ly6mGqfl6m5/WfI4TQppX1uyRR8WSKWyVP+LI9GFSpXGVqwWCz2ZKCnX6NYG1t7bmTPzZVLV9MBilfLtJI+qJNoXN9nGdruEzJoJrwpe4nzJhWOkwGibJIvVPW98VK7YKfutev2Wy+1IhfagA+7ybwVBpMBilfsvX3y5Q0ZavqTfcZZ43yXfSRbp/02trapIQvXassKg0mg0RZnHXXrJ/mKFRAlTK3AE/lgckg5Yu+36j6+5+67Vq6xFAft/TPZWpFla/RQP1D3y81240s28SUByaDRFnok7BC3UGfFVClZCuFSsJkkPItdTpVHWXLNKqWGqvUOHLROJTu56e7MU53w3rWjSxjW3nIFLdYTUxVw+12w2w2w2w2w+VyJVX+Tk1NYXh4GPF4/Mwq3osSQmh7C8vjpAHAcVWwWi3HVgpE1Uu/B7m6p3gwGNSej8fjMJvNEEJACHEqVk1PT8Ptdmfd+1eNO+mora4AYGRkRNsHXc/n82FiYgJmsznp+OzsLOLxOGpqatJW/2aLbWe1w6EiSJchlsuDd9iUD6nr/PQP/V1quucv8sjUVT8V75QrGzgySAWkTr1eZKYi23TveQpD1Crj1MbQ2QroLrK8hbGweDLFLY4MkiG5XC4IIeByuTAzM5PUDBX4rUff4OAgzGazdheeD1arFZOTk7DZbJicnMzYJ4ujgETVIXXkK9NImDp7YTKZ8MUXXyAajaK3txeKomQd7Ut1/G/++Z8DAIfDAZvNBuB4pHBlZeVUY+h0sesyPQEZC8tAugyxXB68w6aLyGXxdD7WBWb6OSz8qA7gyGDVOG/rl9TXp9uSUn3o19gVqkAtl4f+Z+uLQhjPjCVT3BLyjLuEUnK5XHJhYaHUp0EVRL/jR6EpipI04qje2bJbfnUQQixKKV2pxxm3jMdmsyEcDsNmsyWt4cv19W63GzMzMwBwapZCVVtbm9Nn55vT6cTCwgLcbjemp6cBIOfrpMqTKW5xmpgqjjrF4nK5tIIQt9sNt9tdtEQQSA7q2aaDiaiynXcaU78fucvlwvT09Kl9fVOVKvlSb1ympqa05S2crq0+HBmkiqK/ey0GIUTSGhshBBKJhHbnDxwngkwCqw9HBquT2+3G7OwsxsfHAUD7Wh8D9CODoVAo7eekxpZi0c9oOBwOeL3eU+dPxsWRQap46h12sQgh8Mknn0BKqd0xqxurqyMFTASJqsvs7CzC4TDm5uaSvtbPWMRiMSiKgsHBwYyfU+xEUG1rNTExocUur9ernT9VuXQLCcvlwYXY1U1dhO10OouysFrf/Z+LpuksYAFJVdHHI7WwQr9zSKHj03nimHp++r3R08U0FolUn0xxiyODVBbStVqYmZlBOBzG4uJiUe6iV1ZWEIvFEIvFONpHVCWytXnRH9fHo8HBQczOzgIAbt++XdS1yunoG9r/6U9/0uLlwsICrFYrpJRpR/8u0w6GjIVrBqnkilkBDByvk9nZ2TmVYHLKl86DawaNIVOlsHpcURSYzWZEIpFTMaMc1v0JIWCxWLR1f+kqmefm5tjpgABwzSCVqWImgupwuNfrhZRSWzfDtX9E1Utf+asfDVSPJxIJhMPhtElfMRNBdeTPZrNhYmJC+9pkMiWt+0utfOboH+WCySAVnbo7iBCiYImgOm2icjgc2tf6YMlASVS99O2oVlZWtKngL774QjteLrNnExMTAIBoNKr1LAwGg5iYmICiKIhGo3C73YxpdCGcJqaCUtswxONxxGKxgv88IQRMJhMmJiYYDKmgOE1cmdSYNDQ0VPK1frlQuxrop4CB5MbQ522KTdWL08RUEl988QXC4XBBE0FFUbSp3kQiwQIQItKo+/2azWatPZVaCFLObDYbpJRIJBJaPBsfH4eiKFAUJakxNPf2pctiMkiXpl9n43a7YTKZtGngQow8O51O2Gw27c+JiQlOixARgPRVwOruH+WUACqKAqfTCeA4pqlrANW4li6xm5qaStvxgFPDdFmcJqZLM5vNWbdZugx12retrQ3b29vaPppEpcZp4vKUujvQF198od2Ulmr/33TUKmVO71IxcZqYCsLlchUsEdRP+25tbUFKyUSQiLJqbm7Wvk7trVfqhGtycjKpIpjTu1QumAxSTtSpl87OTgghUFdXl/dqYCGE9rXT6eSUBxHlRD81vL29rR2/ffs2TKby+GdOURRMTU2dmtIt59k5qh7l8VtCZU9tuaAG2ovcYdfW1p46piaATqcTiURC6wXIEUAiypV+j2C1jZT6ZyKRyPlzzGZz0k1pPqhtrtTWMHr68yYqJSaDlJa+As/tdp8roGai3wdRnSr55JNPmPwRUVaZtoxT6adb9/b2AAB7e3tJ6wVzEYvFYLFYTh3PNUHU9zMFjkcDLRZLxlZXnCamcsECEkrrskUh6p3wzMwMEokEe/+R4bCApHjO00dPjV2p3QwcDkfSFHImqa9zOp1YXl5O+/PVHZTUn6UmdmpTaACIx+MsEKGywQISKrja2lqtB5aa+MViMfb+I6JLSR1ByzRSqH6frq1VLomg+rrJyUlYrVZMTk5iYWEh4wjewsICpJT45JNPknY1Utu/TExMcOSPKgJHBiktt9uN6enpM1+nT/yIqglHBksn3UjhWTFLneo1mUwYHh7Go0ePMs5+KIrCET0yJI4MUlqZ7rCnpqYwOTmZtL+vSu2ML6XkiB8RFV26kbrZ2VntazXxE0LAZrNpI4VSSsTj8ayJoIojelRNmAxWOX01W2piqE53qF3yHQ4HAyQRFU22m9XUHTfUBHFyclKbtv3kk08QDAa19jJqcpiJurUldzWiqqOv8CzUA4AdwB0AtwCMnHVcfTidTkn543Q6JQCp/+86OTkpbTabnJyclFarVQKQNputhGdJVBkALMg08Y5xK3/yFZP0cS71ewDaQ32eyKgyxa1iJYN3ANhPvr571nH1waCaX/qgB0A6HI6k51MDJhFlxmSw8IoRk9LdJBMZVaa4VZQCEiHEV1LKD3L9WtXX1yc7Ojq078fGxjA2Nlbw8zUqtQ2CXjH+/xMZxfz8PObn5wEAi4uLL6SU/amvYdwqPLfbjdnZWYyPj3Mql+gMucStoiWDAP4ipfQIIb6WUr6f7biKVXnnk2uArKurQzAYRG1tLQKBQBHPkMg4WE18cZdN5s7Td5CIflPqauKHAFpPvvbkcJwuINetjdTdRDgqSESlcJFt2PTFJENDQwCAwcHBQp0iUVUpVjI4D+CWEGIMwGdCiAEhxJ3U40U6F8PKdWsjboFERKV0kRikTyCXl5cBACsrK4U6RaKqwqbTBsU1NUSFxWni4nK73Zibm9MSSPVrxjei3GWKW0wGDYpraogKi8lgafGGl+j8Sr1mkAostTkrp4KJqFxlaiZ9HhdZd0hE6TEZNIjUwJiuQz8RUTlIl8idN0HkDS9R/jAZNAhW1xFRqWRK5DIdz7S38HlG+njDS5Q/XDNoEFwjSFRcXDP4m0zx5zxxSV8gwgSPqDC4ZtAA0t1lq8eGhoY4ZUJEJZFpyvY8U7kc6SMqHY4MVgi3243p6WkASLrL5oggUWlwZDD/WCFMVFgcGaxws7Oz2tf6u2wuoiYio0hdN5iPqmMiOhuTwTJxVtBTk77JycmkO2ZOrRCRUaTe3LJ9DFFxcJq4THC6l6iycJq48FhUQpRfnCYuc5zuJSJKxpkPouIwl/oE6NjU1BQDHhERERUdRwaJiOhSxRos9CCqbFwzSER0AUZbM3iZdctc80xUGbhmkIiIMrrMumWueSaqbBwZJCK6AKONDBKR8XFkkIiIiIhOYTJIREREVMWYDOYBK+mIiIioUjEZzANumURERESVislgHrCSjoiIiCoVdyDJA+4eQkRERJWKI4NEREREVYzJIBEREVEVYzJIREREVMWYDBIRERFVMSaDRERERFWMySARERFRFWMySERERFTFmAwSERERVTEmg0RERERVjMkgERERURVjMkhERERUxZgMEhEREVUxJoNEREREVYzJIBEREVEVYzJIREREVMWYDBIRERFVMSaDRERERFWMySARERFRFWMySERERFTFmAwSERERVTEmg0RERERVjMkgERERURUrSjIohLALIe4IIW4JIUZ0xweEEItCiHtCiIFinAsRERER/cZcpJ8zBmBeSukRQtwFsKR77s9SSk+RzoOIiIiIdIo1TfyeLuFLHQH8UAgxph8xVO3s7MDlcmmP+fn5gp8oEVEm8/PzWjwC0J7uNYxbRFROcolbQkpZ8BMRQnwF4C8nI4NfSynfT/Oae1LKj/XHXC6XXFhYKPj5ERGdlxBiUUrpSj3OuEVE5SpT3MrrNLEQ4lbKIY+U8gGAhwBaAXhOHurrxwD8/WTUsDWf50JEREREZ8trMiilvJ/hqXkAY0IID4DPTopFbgG4D8B18v2n+TwXIiIiIjpbUQpITkb+Pk85rH6/WoxzICIiIqLT2GeQiIiIqIoxGSQiIiKqYoZLBquxjUM1XjNQndddjdcMGPu6jXxt2fC6q0c1XjNQWdfNZNAAqvGageq87mq8ZsDY123ka8uG1109qvGagcq6bsMlg0RERESUu6I0nb4oIcQOgBfnfFs7gN0CnE45q8ZrBqrzuqvxmoHyvO4+KWVH6sELxK1yvLZi4HVXj2q8ZqA8rzt93CrnZJCIiIiICovTxERERERVjMkgERERURVjMkhERERUxYqyHd1Ftbe3y/7+/nO9Z2dnBx0dp9ZGGlo1XjNQndddjdcMlOd1Ly4u7qZbiH3euFWO11YMvO7qUY3XDJTndWeKW2WdDPb392NhYeFc73G5XOd+T6WrxmsGqvO6q/GagfK8biFE2orh88atcry2YuB1V49qvGagPK87U9ziNDERERFRFWMySERERFTFDJcMjo2NlfoUiq4arxmozuuuxmsGjH3dRr62bHjd1aMarxmorOsu66bTLpdLltt8OxERAAghFqWUrtTjjFtEVK4yxS3DjQwSERERUe6YDBIRERFVMSaDRERERFWMySARERFRFWMyaGBLS0tYWloq9WkQEeWMcYuo+AybDC4tLeHGjRt48OAB7t+/jw8++AAejyfta1dXV4t2Hp9//nnBflaqgYEBfPnllxmfV697aWkJ8/PzxTotIsqAcYtxi6gUDJsMjoyMYGBgAKOjoxgdHcXf/va3tMFzdXUV9+/fL8p53Lp1C7du3cLHH39csJ+XK/11j4yMVFQ/JCKjYtzKjnGLqDDKem/iy9rf38f9+/fx5Zdf4quvvsLIyAju37+Pe/fu4d69e7h79y7ef/99PHz4EEtLS1hdXcXXX38NAPj000/x4MEDAMDo6CiWlpbw5Zdf4uOPP8bXX3+N999/H19//TXu3r2L1dXVpNcODAxkPKeBgQEsLCyceg8A3L9/H3a7HS6XC3a7Hffv38fAwADsdjs8Ho/285eWlnDnzh3Mz89jcXER9+7dw8cff4z//J//M/7bf/tv2ntcLpf2uaurqxgbG8Nf/vIXfPXVV1haWtKue39/H0tLS7h169aZP5OICotxi3GLqOiklGX7cDqd8jJGR0ellFJ+9dVXUkopnz59KqWU8t69e/Lu3bvaMfXrg4MDeefOHSmllLdu3ZKLi4vy66+/ll9//bU8ODiQY2Nj2nPq5ywuLp56babzUI2MjJx6z9jYmHZ+BwcH2s9Qf57+56t/6s9FPY/U99y5cyfputT3prvuXH8mEUkJYEEybjFuEVWQTHHLsNPEerdu3QIAbVHywMAAnj59CgBobW0F8Ns6lLa2Nu196jSJeqdqt9uT3qOX+tpMVldXtdfo37O/v699rvpzVOqaodTjAPDee+9hfn4eIyMjad+T+r79/f2ka8i07ijbzySiwmPc+u19jFtEhWXYaWJ1+uTBgwfatMFf//pXzM/Pw+Px4OOPP8b777+Pr776Cnt7e1hdXdWmIDweD+7evasFq4GBAe351dVVbbpkcXERAE69Vh+IUs9jdXUV9+7dw+rqatJ77t69i88++wzvvfceRkZGtM9sbW3Fp59+ioWFhVM/f2BgAGNjY/jss8+SzkP/Hn3QfPDggXYdIyMj2nWrj1x/JhEVBuMW4xZRKXBvYiKiC+DexERUabg3MRFRhSlkzz328yMiFZPBS2JAJaJCOavnnt55+w6e57Oz/Tz2+yOqfEwGL0kNqAyIRFQqhe47mO3nsd8fUeUzbAFJsY2MjJyqjCMiOg81yVL77amFD+l67qn9/paWljAwMKD137Pb7ad6Dap9CO/du5fxZ6pFJKOjo6fOAwAWFhbg8XgwNjZ24X5/+nNm/z+i8mHYZPD+/fsZG7HqpzdGR0eTgtyDBw8yNmlVG8F+9NFHePjwIe7evav9vAcPHmhBOTUA6qvy7HY776KJKK27d+/i008/xcDAQFKbldHRUXz22Wew2+1ae5WlpSXs7e3ho48+gt1ux+rqKkZGRvDBBx/gr3/9K/b397G6uorR0dFT8Urv008/xVdffQUA+OCDDzA6OnrqPNTP93g8ePDgAUZGRrSf5/F48PXXX5/6nL/97W/4+uuvMTo6qh3XnzMRlQ/DThOPjo7Cbrfj3r17+PTTT7W7bLVFgRqkRkZGtOD64MEDjI6OorW1VUsaR0dHcePGDS1xfO+993Dr1i20tbUlTcu4XC7s7e0lvV/tCba0tKTdXatd+4mIUmXq25eu5566Rdxnn312qv9eav9AfR/CbNQENPU81MRQnf24aL8//TkTUfkw7MggcLoRq3oXq069qAFOvbNODWDpmrTmIjUAqkmo2puLiCid1L59ai89lb7nnjpC9/7778Nut2v991L7B+r7EOpjk9qDL7VPX7rzuHHjBlZXV7G/v4/FxUWMjo5eqN/f/fv3tXMmovJh2D6D6pTu3/72N22vTzU4ql+rQba1tVULcv/2b/+G2dlZ3Lt3Dx988AG++uor3L17F06nEx9++CH+8pe/aFPId+/exYMHD7Q9NtU/7969m/R+IDnx5NpCosrHPoNEVGkyxa2iJINCCDsAF4ARKeXnuuMDAL4CsADgrpQyac6h3IKqx+PB/Pz8uRc+f/755xgbG4PdbteSRiKqbEwGiajSZIpbRZkmllJ6hBCrANLNDfxZSukpxnlc1oMHD/Dw4cNzv29gYADqPw5OpzPfp0VERER0YeWwZvBDIQQALEgpy7p7861bt7TN48/7PiIiIqJyVNJk8GRaeB4AhBD3AHxcyvMhIiIiqjYlbS0jhBg7WU8IAKdKd3d2duByubQHd/ggolKan5/X4hGA9nSvYdwionKSS9wqWjWxEGIMwAf4bfTvFoD7AAZOHg/KvYCEiEjFAhIiqjQlLSABACnlPE6mhE+oVcXn212diIiIiPLGsDuQEBEREdHZmAwSERERVTEmg0RERERZRCIRHB0doZx3bbsMJoNEVFJutxs2mw1ut7vUp0JEdMra2hr++c9/4rvvvsOjR48QiURKfUp5x2SQiEpqdnYW4XAYc3NzpT4VIqIkL168wPr6Ovr6+tDf3w+TyYQff/wRiUSi1KeWV0wGiaikxsfHYbPZcPv27VKfChGR5ujoCOvr6+jt7YWiKACAjo4OhEIh7OzslPjs8ovJIBGV1NTUFILBIKampkp9KkREmmfPnqG5uVlLBFVtbW1YX18v0VkVBpNBIioqrhEkonLn9Xrh8/nQ0tJy6rm6ujpEIhF4vd4SnFlhMBkkorzLlvBxjSARlbu1tTXY7XYIIdI+39jYiM3NzSKfVeEwGSSivMuW8HGNIBGVM3XUr7m5OeNrGhsbsb+/X8SzKiwmg0SUd9kSPq4RJKJytre3B6vVmnFUEABqamogpUQwGCzimRUOk0EiyjsmfERUqba2trKOCqosFgsODw+LcEaFx2SQiIiICEAwGITf70dDQ8OZr62trYXH4yn8SRUBk0EiIiIiAB6PB7W1tTm9tr6+HgcHBwU+o+JgMkhEREQEYH9/H3V1dTm91mKxIBKJIB6PF/isCo/JIBEREVW9RCKBg4ODnKaIVTU1NYYoImEySEQFwebSRFRJjo6OYDabT+04ko2iKAiFQgU8q+JgMkhEBcHm0kRUSQ4PD1FTU3Ou95jNZiaDRESZsLk0EVWSg4ODnNcLqiwWC6eJiYgyYa9BIqokPp8P9fX153qP1WplMkhERERU6cLhMOLxOMxm87nexzWDRESXxCITIioHwWDw3OsFgeNq4mg0WoAzKi4mg0RUcJmSPhaZEFE5CAQCF0oGTSYTEokEEolEAc6qeJgMElHBZUr6WGRCROXA5/PBZrNd6L0mkwmxWCzPZ1RcTAaJqOAyJX1TU1O4ffs2ZmdnOVVMRCXj9/svlQxW+lQxk0EiKrhslcXqqOHMzAzXDxJR0cXjcW3NYDwez/pIxwgjg+crmyEiygO3243Z2VmMj49jfHwcc3NziEaj2lQy29EQUb5EIhGEw2FEo1HtEQ6HEYlEEIlE4PV68fPPP2N/fx9SSu19Qoikz5FSQggBi8UCi8UCq9UKi8WC/f19bG9vw2KxwGaznXpfJWAySEQFpSZ+Q0NDWF5exvj4OGZmZhCPxzEzM4NYLIapqSm43W7Mzc1x/SARnZuUEuFwGKFQCKFQCH6/H36/H0dHR5BSoqamBiaTCSaTCYqiwGw2w2w2o76+HkIIXLt2DV1dXWf+nEQigVgspj38fj+8Xi9evHiBnZ0dCCHQ3NwMu92OxsZG1NfXw2Qq/0lYoc+Cy43L5ZILCwulPg0iugSbzYZwOKx9ryiKNt2iKErFTq8IIRallK7U44xbRIWVSCQQCARwdHQEr9eLw8NDBAIBmEwmLcmzWq2w2WywWq1n7jW8t7eHnZ0dtLW1Xeh8dnd30dnZidbWVsRiMRwdHSEQCCAajSIWi6GlpQVXrlxBS0tLyUcNM8UtjgwSUUGp08CDg4NYWVlJSgyHh4dhs9kwPj7OqWEiSisSicDv98Pn88Hj8cDv90NRFNTU1MBms8Fut6Ozs/PCI3ChUOjczab1hBDa9LLZbEZzczOam5sBHCeuPp8PT548AQBcvXoVHR0dsFqtF/55hcCRQSIqKrPZjHg8rt2tq19X2gghRwaJCiMcDsPn8+Hg4AAHBweIRqPaGr36+nrYbLa8Tr2urq5CUZRz70us2tvbQ3t7O9rb27O+LhQKwePxIBAIoL29Hf39/ReuYL6oTHGr/CeyiaiiqQ2nXS4XzGYzEokEFEXBxMREqU+NiMpAIpGA1+vF8+fPsbCwgIcPH+L58+eIRCJwOBwYGBjQRtTq6uryvgYvHA7nbWQwG5vNhq6uLvT39yMajWJxcRGbm5s5vbfQOE1MRAWlto5ZXFzUjtXU1GjTwvqiEX2VMaeNiYwrGAzC5/NhZ2cHHo9Hm/JtaWlBbW1tUc8lHA5faPcRlRDiXDuQmEwmtLW1oaGhAc+fP8fOzg7eeOONoo8SJp1TyX4yEVUFteG00+mEoihQFEVL/lL7D3J7OiJjSiQS8Hg8ePr0Kf7xj39gaWkJL1++hNlsRn9/P3p7e9HR0VH0RFBdnnKZwo7zJoMqq9WKa9euQQiBxcVF7OzsXPgcLovJIBEVhDo9DByPAiwsLGBiYiLrdAy3pyMyDjUB/PXXX/Ef//Ef+Pnnn3F0dASHw4Hr16+ju7sbTU1NJW29Eo1Gz6w2PstlK4RbW1tx5coVPHnyBNvb25f6rItiAQkRFYTaUkbt6TU+Pq6N/AGA0+nU+g5W4pQwC0iITlOrZ3d3d7G9va0VZjQ1NV1qKrZQfD4f1tfX0dHRcanPsNls6OnpudS5hMNhvH79Gjdv3kRra+ulPisTFpAQUVGNj49rPQXVqd/x8XHt+cXFRU4JExmAOgL4yy+/aCOAwWAQPT096O3tRVtbW1kmgsBx25p8jExeZJo4ldVqRVdXF3788Uf4/f5Lf955MBkkooKYmppKmhK+ffs2pqamTk3JDA4OFvvUiCgPDg8P8fTpU/zHf/wHfvrpJ4RCIVy9erXsE0C9yxaPAMcFIfmaZa2trUV7ezseP36clwQzV0wGiahg1DWAk5OT2lTwxMQEbDablhSurKyU8hSJ6BwikQhev36NhYUF/PDDDzg6OkJPTw+uXbuGtra2S7VoKYXLtpVR5TNxa2xsBICirh9kMkhEBZNaLaySUmJ4eBiKoiAajcLtdpfoDInoLIlEAgcHB3j8+DH++c9/4vXr17Db7ejv70d7e3tFjABmEovFLl1AUgjt7e14/vy5tnVnoTEZJKKCUquK3W433G43pqenEQ6HsbKyou1GMjMzo72GiMpDIBDA8+fP8c9//hNPnjyBlBL9/f3o7u6+8G4d5SYWi116zaCUMu8V0ersyebmZl4/NxNWExNRQalVxTabDVJKrZpYURQMDw9jZWUF0WgU8XgcNpsNwWCwxGecG1YTkxHF43Hs7+/j1atXODo6Qn19Pex2OywWS6lPrSB++OEHdHR0XGp00OfzwWq14urVq3k8s+Mp7M3NTfzxj3/M2+glq4mJCkw/Aka/UdcNDg4OIhaLaT254vE4VlZWEAwGtXWE7C9IVBrhcBgvXrzAP/7xDzx79gx1dXW4fv06HA6HYRNBID/TxOoWm/lmtVohhMDR0VHePzsVk0GiPOHuGclSm04vLy8jHo8nVd2plcSZ1hYSUWH5fD789NNPePjwIfb29tDd3Y2rV6+ioaGh1KdWcPkq+ijENLHKYrHg8PCwIJ+tV5RkUAhhF0KMCiHupDl+RwhxSwgxUoxzISoU7p6RPDqqJsfqesChoSFtWzoVK4mJii8ej2NnZwdLS0tYXl5GLBZDf38/urq6DD0KmCoej+cliStkMlhXVwePx1OQz9YrSjIopfQAWAXQlvLUGIB5KeV9AB8V41yICoWjW8mjo0NDQwCO777VghF1W7rJycmqT5yJik2dCv7nP/+JZ8+eoaGhAf39/WhtbS3plnClEo/HL72VHFD4ZNDr9eatj2Empf6//95JoggAA6U8ESK6PP3o6PLyMoDjhqypiR8TZ6Li8fv9SVPBV65cqZqp4GwSiUTZJ4Nmszmp8K5QSp0MQghhP/nSnuVlRFQB9EmemhgODw9DSolvvvmGBTZEReTz+bC8vIzvvvsO0Wi0KqeCs8nXyCCAvH1Ops8u9G4kpU4GHwJQd2P2pD65s7MDl8ulPebn54t6ckR0cWpiuLy8jHA4rO1FPDMzc6ryulIqsefn57V4BKA93WsYt6iUpJQ4ODjAd999h+XlZQgh0N/fj7a2tqqcCs4mXyN6iUSirP/b5hK3itZnUAgxBuADAB+fHLoFYB7H6wY9ABaklEv697BfF1Hlc7vdmJubQzgchpQSiqLAbDZrvQeDwWBSL0L2GSQ6Pykl9vf38eLFC4TDYdjtdjQ3N5f6tMqax+PB69ev0dHRcanP2drawvXr11FfX5+nM0v2/PlzDA8P56XRd8n7DEop56WU70spV08en0spPSd/zqcmgkRkDOoI4SeffAKbzYaJiQmtuKSpqSmp0pgFJUTnk0gksLW1hYWFBfz6669oaGhAX18fE8EcSCnLfs2gqpDT0ABQWTtKE1HFUdvMDA0NaRVxjx49AvDbRuxqpTER5SYej2Nrawtra2swmUxobW01zBZxxZKvdXiFajpdTEwGiaig1HYzi4uLAJDUlFsIAavVyhFBohypI4EvXryAyWSCw+HQmrvT+VRCNTFwfJ5mc2HTNSaDRFRQQ0NDWFxchMPhgM/n0xK/ubk53L59m+1liHIgpcTOzg6ePXsGIQSTwDzIVxKnroUuhEgkgpqaGtTU1BTk81VMBomoINxuN2ZmZhCPxwEAe3t7AICZmRlMTExwWpgoB2phyOrqKhKJBNrb21FbW1vq0zKEfLSWURPKQq3pC4VCRekHWb610ERU0fSJIHA81RGPxxGPx7l/M1EODg4O8O233+LJkyew2+3o7e1lIphH+WgJE4/HC7peMBQKFaUYiCODRFQU+qDLNYJEmXm9Xjx//hxHR0doa2tDV1dXqU/JkPLRWq/QyWAkEilYyxo9jgwSUd7om0dPTEzAZrPB6XRqLWVisRhisRjXCRKl4ff7sby8jOXlZVgsFvT396OxsbHUp2VY+ZjajcfjsFqteTib9KLRaFFGgzkySER5o1YOz8zMwGw2Y2hoCMvLyxgfH2cCSJRBOBzG2toatre30dzcjP7+/oL3laPj2YrLtpcpZLIWDAZhsViKUijEkUEiyht1P2IASVvQTU9PJ201VynbzxEVUjwex/r6OhYWFnB0dIS+vj60trYyESySfPx3jsViBUvWvF4vrly5UpDPTsVkkIjyRt1tRJ0idjgc2nNzc3Nwu90wm82Ynp5GOBxmIQlVJSkldnd3sbCwgI2NDVy9ehUOh6Os97c1IpPJdOl1g/F4vGBtX4LBINra2gry2an4N4+I8k5NCr1er3bs9u3bmJ2dTaowZiEJVZvDw0N89913+OWXX9De3o6enp6C95Cj9IQQl04GE4lEQf7/HR0doba2tmjV40wGiahg1D2IHQ6HtiWdoihQFAWTk5Np1xFyCpmMKBwO4+eff8b3338Pi8WCvr4+tokpsXwVkBQiGfR6vUWtImcySEQFs7y8DOB4D+JwOIyVlRXEYjFMTExgdnY2bcKnFqFwCpmMIB6PY21tDQsLCwiFQujr64Pdbi/1aRGOk8HLFJBIKSGEyPtWcVLKok4RA0wGiaiA1IIStb3M7du34Xa7s64ZVN/DKWSqdHt7e1hYWMDW1hauXr2Kjo4OrgssI5f9fxGNRmGxWPJ0Nr/xer2w2+0FbVmTSuSj6WKhuFwuubCwUOrTIKI8stlsCIfDAIDJyUkAx6OBldZ+RgixKKV0pR5n3KJgMIinT5/i8PAQDoeD08Fl6uDgAJubm2hvb7/Q+4+OjpBIJDAwMJDX83r+/DkGBwcLsvNIprjFWxQiKqrx8XFt3SDAaWEyDnVKeHFxEQBw7do1JoJl7KJrBuPxOHZ2dvDLL7/g+fPnCIVCeTsnr9eL+vr6omxBp8dkkIgu5ayCj9Tnp6amYDabtT2KOS1MRnBwcIClpSVsbW3h2rVr7BdYAS5STezz+fDs2TMEAgHU1dWhtrYWgUAgb+fk8XjQ19eXt8/LFZNBIrqUs0b20j2vVhk3NTVhdnZWSwRZRUyVJhKJ4KeffsLjx49ht9vR09OT94ICKozz9BlUG4Sru8Q0NzdDCAGTyZS3vYl9Ph9qa2tLUmDEZJCILuWskb10z6dWGc/NzXG6mCqKlBKbm5talXB/fz/q6+tLfVp0Doqi5JQMRiIRrK2tIZFIoL29XWslE4vFIIRAQ0NDXs7n4OCgJKOCAJNBIroktcF0tuKPaDSKmZkZbdQvXZUxp4upUgQCAXz//fd4/vw5urq64HA4OCVcgRRFObO1TCAQwNraGqxWK5qamrTjiUQCR0dHaG1tzcvI4OHhIWw2G1paWi79WRfBamIiKih99bDNZkMwGCzxGeUHq4mrTyKRwKtXr/DixQvY7Xa0traW+pToEmKxGJaXl9HT05P2+cPDQ2xsbMBut59qIRMKhfDixQv86U9/QmNj46XOQ0qpVRAXeoqY1cREVBL66mF11E8tKnG5XFwnSBXh6OgI3333HV6/fq0ViFBlyzZN7PF4sLm5idbW1rS9BL1eL5qbmy+dCALA7u4u2traStqMnMkgEeWdvoJ4amrq1K4j6vrAxcVFhMNhzMzMMCmksiSlxPr6Or799ltYLBb09vayQMQg1N1D9PulA8eJ4M7ODlpaWjL+v/b5fOjv77/0OYTDYRwdHeW9V+F5MRkkorxLLQbR7zoyMzOjVRPrsXiEyk0gENBGA3t7e0u2nosKJzUZVBPB1tbWjIng4eEhLBZLXkaHt7a2cP369YLsZHIeTAaJKO/0xSBqIqinVhMDgNPpxMTEBItHqGxIKfHq1SssLS2hpqYGV69e1SpIyVhqamq0ZPDw8FAbEcxUFBKLxRAKhdDc3AybzXapn+3xeGCz2dDV1XWpz8kHjnUTUd5NTU1p1cX6/T8VRcHw8DAePXoERVEwMTGhva6StqIj4woGg3jy5AlCoRB6e3uZBBqc1WpFJBJBPB7H5uZm1qlh4Hh62G63Q0p5qSrieDyO/f19DA8Pl0UlOkcGiSiv9MUhqR3+1eq9eDyOmpoaJoBUNqSUeP36NZaWlqAoChPBKmGz2eDz+fD69WvY7fasieDR0REURYHFYklqM3MR29vb6OnpyVuPwsviyCAR5YVaGBKLxRCPx7X9WVVOpxNutxuxWCypspio1MLhMH766ScEg0H09PSUfP0WFU80GsX6+joGBgayJv+xWAyBQAB9fX3wer1oa2u78M/0+/2IxWLo7e298GfkG0cGiSgv1KIRAFpDab0//elPmJ6e1tbncFSQysH+/j6WlpZgMplw7do1JoJVJBAI4OXLl6ivrz/z/7vH44HD4YDFYkE0GkVdXd2FfmYsFsPOzg5u3rxZVlXpZyaDQojhlO+bhBD9hTohIqpMatHIxMQEgsEg/vSnP2lrYZxOJ2ZnZ7XXntX1n6jQ4vE4nj59ih9//BEOh+NSIz1UeSKRCJ4+fQqHw3Hm2j+fz4e6ujo0NzcjGo1CURRYrdYL/dyNjQ309vZeepo533JJSwUACCH+HwASgAfAHoD/X+FOi4gqjb5oBDgeKVTXCz569AjDw8Pa1LG+qISo2AKBAH788UckEgn09fXx72OVUW8E6urq0NDQALPZjFgslnakLhwOIxKJaLuUBINBNDc3X+jn7u/vw2azldX0sOrM3wAp5bcnX94D8H8B+L8B/L+FPCkiqlxqAYm+l2A8HsfKygomJye10UOiUtjc3MS3336L2tpa9PT0MBGsMurWb0IIbXSurq4OoVDo1GsTiQR8Ph+6u7u10cNQKHShUb1gMAifz4e33nqrLKqHU+U8Ya1LCgHAW4BzISID0O8uoq8mHhwcxOzsLMbHx7lekIouFovh119/xf7+Prq7uy88zUeV7dWrVwiFQnA4HNqx+vp6HBwcnHqt1+tFS0uLtj4wkUggFoudews6tW3NzZs3L92bsFB4S0RE56bfbi71eCwW075XE0GHw6FtPcddRqjYfD4fFhcXtWpQJoLVaW9vD/v7++jo6Eg6Xltbi0gkknTM7/fDZDKhvb096VhLS8u5R5M3NjbQ3d1d1vtZnzsZFEL8H4U4ESKqDPqt5ebm5rR+gnV1dVq1cOo0yPb2tva12lImU0JJlC9SSrx8+RLff/89Wlpa0NXVVZZTdFR4R0dHePnyJTo6Ok79HbDZbJBSap0OwuEwQqGQtk5QFQwGz70l4d7eHqxWK/r6+i53AQV2kZFBe75Pgogqh74qeHBwUCsKCQaD2nEppTYNI4SA0+mEzWbD5OSkNkWcun8xUT7FYjH89NNPWF9fx7Vr18qmuS8VXzQaxbNnz7LuN1xfX49gMIhYLAav14uenp6k18ZiMUgpz/X3yOfzIRAI4ObNm2W/NrV8mtwQUUUYGhrSEsClpaWMr/P5fEm7j6QaHx/H3Nwcm09T3gUCATx+/BiKouDatWscDaxiasFIbW0tamtrM77Obrdja2tLW0+Y+lqv14v29vac/y4Fg0Hs7e1heHi4InpXlneqSkRlZ3l5Wfs6W7I3ODiY9XOmpqYQDAZZTEJ5tbe3h2+//RZ1dXXo7OxkIljlNjc3EYlEzqwAbmxsxN7eHmpra2G325Oei8ViiEajp9YaZhKNRrGxsYGbN2+ivr7+oqdeVBdJBvmbRVSlUgtEsllcXExaD8g1glRI6gjQjz/+iK6urlP/oFP1OTw8xPb2dlIRSCbqyF+6UbyDgwN0dXXltGNIIpHAq1evMDAwUNYFI6nOnQxKKdljkKgKqYUj8XgciqLAZrOd2blfvx4w3RpBJoiUD9FoFCsrK9ja2kJfX1/W6UCqDrFYDC9evEBra+uZ6/X8fj+i0SiGh4cRj8eTeg76fD4AyHmHmtevX8PhcKC7u/viJ18CnCYmopzoC0cmJiZw+/ZtbVs5h8ORtPWc2lxavx5Q3a5Of4xFJHRZfr8f3377LWKxGHp7e8+8QaHq8PLlS1gsljP7+oVCIRweHmJgYAC1tbW4fv069vb24PF4sLu7i1AohN/97nc5FYBsbW2htrYWAwMD+bqMohHZ1vyUmsvlkgsLC6U+DaKq5na78cUXX0BKCSEERkZG8OjRI60NA3BcMXyR/YbdbrdWRFJpaweFEItSSlfqccat4tne3saTJ0/Q3t5ednu9Uuns7e3h9evX6OrqAnA8chwKhRAOhxEIBAAAVqsVTU1N2N/fx+9+97ukKmG1+MNsNqOtrQ01NTVn/syDgwMEg0H84Q9/yOn1pZIpbuU8MiiE+D+FEPxtI7qASp4O1e8xLKXE4uJiUiKoHgfOf50sIqGLUNcH/vrrr+jp6WEiSJpQKIS1tTVYrVasr69jeXkZjx8/xsuXL7G/v6/FqvX1dTx79gwDAwOn2sXU1tbi6tWr6Orqyimx8/l8ODw8xODgYFkngtmcZ5p4VUrpK9iZEBlYJU+Hjo+Ppz0uhNB6CTqdTgCVfZ1UGeLxOH7++Wdsbm6it7eXu4kQgOPCjYODA/yv//W/sL6+jtevXyMSicDhcKCvrw/d3d1wOBxobm6G2WyG1+vFzZs3L30j4ff7cXBwgHfffbei16qeJxn8oxDiv5w8/tN5fogQwi6EuCOEuCWEGNEdHxBCLAoh7gkhKm+SnShH6dbLlavzjO55vV5MTk5CnRatpOukyhOJRLC8vIzDw0OuDyRIKXF4eIgXL15gaWkJ3333HRKJBH73u9+hp6cHra2tp6qDj46O8NNPP2FkZCRpf+KLCAQC2NnZwdDQUMW0kMkk5zWDQog/A1iQUnqFEP8ipfw25x8ixB0A81JKjxDirpTy05PjAwD2pZSedO/j2hui4nC73ZidncX4+Lg2uqcmddPT01nfa7PZknYfqRZcM1hcgUAAKysrsFqtObUKIeOKRqPY29vD5uYmEokE6uvrUVdXh5cvX6KlpSVjCxi/348nT57A5XLhxo0blzqHYDCIjY0NvPvuu2hubr7UZxVTpriV8w4kUsr/rvs650TwxHtSys9Pvk4dAfzwpApxQUqZeTsDIiqYmZkZxONxTE9Pw+l0YmVlBbdv306qIAaSN3QfHh7WXkdUSF6vF48fP0ZzczP7B1axo6MjbG1tac2h29ratGrh169fw2azZUwE9/b28PLlSzidzksngqFQCBsbGxgcHKyoRDCbom1HJ4Swn4wA2tVjUspVAPMnz98D8LH+PTs7O3C5fktgx8bGMDY2VozTJTI8/Wig3uLiIpxOp5Yg6gWDway7jhjd/Pw85ufn1W/TDk8xbuWXWjHc1dWFurq6Up8OFVk8HofH48Hm5iaCwSAaGxtPLREIBoM4OjpKu0NINBrF1tYW/H4/3nvvPfT391/qfMLhMF6/fo2bN2+ipaXlUp9VLLnEraK0ljmZJr4vpVwVQnwlpfzg5PgYgL+fTB9rx1Wcbil/+oSCFaHlL910sBDiXAmeoiiYmJi49P/vSv+7w2niwltbW8PLly/R3d3NQpEqEwqFsLu7i83NTdTU1KC5uTnjurwXL17AYrGk3U94f38fNTU1eOutty7dCDoSiWB9fR1vvvnmpdcblkqmuFWsZNAOYAyAB8DCyZ+3ANzH8bTxAIAHJyOFGgbV8mez2bT1ZdW4bqzSmM1mxONxCCG0Jqqpo38qRVGyPpfrtnSZVPrfHSaDhZNIJPDrr79ib28PPT09OW0DRsbg8/mwubkJn8+Huro62O32rO1a/H4/Njc3k9aRRiIR7OzswGQywWq1YmBgIOd9hTOJRqNYX1/HjRs3tP6FlejSfQYvQ0rpkVJ+LqWcl1IuSSlXT75flVI+ODm+evYnUblh9Wj5yaUaWEqJeDyOeDye8Q43FotpLWMAaDuM5Av/7lA68XgcP/30EzweD65du8ZEsApIKXFwcICVlRX88ssvMJlMuHbtGjo6Os7s27e7u6v1CZRSYn9/H5ubm7Db7WhsbMSbb7556UQwHA5jfX0dAwMDFZ0IZsMdSIgMRh39U0fvXC4XFhcXUVtbm3YELtMIoJTy1OhdJe8Ykm8cGcy/eDyOx48fIxQKobu7O+83IFRe1N6A6+vrSCQSsNvtpxpAZxOLxbC6ugqHwwG/34/9/X00NjaisbERsVgM169fP9fnpaMWi7zxxhsVOzWsV9KRQSIqLLfbDbPZDJPJpCV26vZwi4uLAHAqEVT/oU2XCKqLs1NH77hjCBVKNBrF8vIyotEoenp6mAgaWCKRwNbWFr7//nusr6+jpaUFV69eTZu4RSIRHB0d4fDwEIeHh0nP+f1+SCnx6tUr+P1+9PX1obGxEQDw1ltvXToRDAaDeP36Nd5++21DJILZcPydyADSVf4CSKpq1cv0D63D4cDe3h6A4wRzamqKiR8VXCQSwcrKCgAYdhqOjm88d3d38erVKyiKktQaBjgehYtGowgGgwgGgwiHwzCZTDCZTIhGo5BS4vr167BarYhGo1hbW0MoFMLvfvc7KIoCv9+Pzs5OOByOSzckDwQC2NzcxODgYMVUDV8GRwaLrJL3qKXylanQQx0VVNlsNlitVkgp01YQb21tadPM3FKOiiEcDuP777+Hoijo7Ows9elQAcTjcWxubuK7777D1tYWHA6HVtnr8Xiwvr6OJ0+eYH19HXt7e4hEIrDZbOjo6IDdbofJZIKiKLh69SrMZjO2t7exsbGBzs5OdHV1IRQKQUqJt956C1euXLl0Iuj3+7G9vY133323KhJBgCODRaffu5UjLnRRbrcbMzMzAICJiYmMr0ttG6NO96bbVUQtFhkfH9fWBRIVUjAYxA8//IC6ujq0traW+nQoz6SU2NnZwfr6OhRFQXNzMxKJBHZ2dhAIBGAymWA2m7XETz9jEYlEcHBwgEQigba2NjQ2NsLn82F3dxcOhwNvvPEGampqEAgEUFNTc2rbuYvy+XzaXsPqlHM14MhgkbGCki5DHVlWp4XVXUPSbZAupUyqolMURbsBURRFewDHI4Zq0QPXBVIxBAIBfP/996ivr2ciaEAHBwf49ttv8eTJE8TjcQQCAWxvb8Pj8cBsNqOjowPt7e2w2+2w2WxaIhgKhbC3t4fDw0O0trbixo0bUBQFr169gslkwtDQEPr6+mCxWCCEQH19fd4SwYODA3i9Xvz+97+vqkQQYDJYdPyHlnKRupxA/f6LL75AOBxOuzNIOtvb29rX6gji7Ows4vE4ampqMDExwZsTKrqjoyN89913aGpqqpppuGqQSCSwubmJb775Bv/jf/wPHBwcwGq1wmKxoKWlJW3yBxxPIx8eHmJnZwehUAgOhwMDAwMQQmBtbQ2RSARvvfUW3njjjbQ3vvmwt7eHo6Mj/P73v8/Y3NrIOE1MVAZSd+PQLycA0k/rnkVRlKT9g9UbEP00MAtEqNjUqeGWlhY0NTWV+nTokiKRiNb4+dmzZwgGg+jo6MDNmzfP7BEZCoUQCASQSCTQ1NQEh8MBi8UCn8+HtbU11NfX46233iroKJ2UEpubmzCZTBgeHs7bKGOlYZ9BojKg9vMDgMnJSfzX//pfsb29DYfDAa/Xqz2XTm1tLaSUiEaj2ojh5OQkk7wCY5/B8wuFQvjuu+/Q2NgIu91e6tOhC5BSIhAIwOfzwePxaF8fHR2hvb0dLS0t2u5G6cRiMRwdHWlFIvregh6PBz6fD42Njeju7i74VG0ikcDr16/R0NCAt95669KFJ5WAfQaJykjqNPD4+Lj23PT0tDa9u729nTURnJycRCAQQDAY1KZ8mQhSOQqHw/jhhx9QX1/PRLDCxGIxeDwevHjxAj/88ANWV1fh8/kQDofh9XphsVhw48YNtLW1pU0EpZTw+/3Y29uDx+NBfX09+vr60Nvbi/r6ehwcHGBtbQ1CCLz99tsFHw0EoLWmaW9vx82bN6siEcyGI4NEJaCOBKZW+56H0+kEfz9KhyODuYtGo/j+++9htVpZLFIhQqEQDg8P4fF44Pf7YbFYYLPZUF9fj3A4jLW1NYTDYdjtdm23o1gsBiEEamtrUVdXh1AohGAwiGg0isbGRjQ3N6Ourg7Abwnm0dERWltbceXKlYKtB0wVDAaxsbGBgYEBrcVNtcgUt7hmkKjIOjs7tdG+8yaC+q3j1Ca9ROUsFotheXkZNTU1TATLmJQSR0dH8Hq9WksXi8WCuro6NDc3azuBLC8vY2trC7W1tWhsbITX64UQQusFeHh4iFAohM7OTtTW1qK1tRUNDQ3ayFsoFILH49Fec/369aTG04V2eHiI3d1dvPPOO/z7qMNkkOiSUos/9Do7O7UpX7PZjFgsduGfI4TA8PAwHj16BACsAKayF4/HtZuW9vb2Ep8NpUokEvD7/fB4PPB4PBBCwGazobm5GbFYDMFgEFtbWwgEAlrLF6vVir6+PthsNm1KOBqNIhAIYHd3FwDwxhtvoL29XSsgkVLC6/Xi8PAQJpMJnZ2daGtrQ01NTVGvd39/H36/H3/4wx8uvVWd0XCamOiS1B071KkSfUPoTDuDnKW2thaRSOTU+xVFgdlsTpt4UnFxmji7eDyOx48fIxqNcou5MhKLxeD3+3FwcACfzwdFUWC1WiGEQCQS0Ub2ampqtIfH44HX60VbW5s2zRuPxxEKhbSHxWJBd3c3HA5HUpKoFpk0NTWhs7MTTU1NJdl3enNzE1JKDA4OFnUkstxkiltMBokuKTUZ1FcGX4SiKFpPwLm5OQwODmqjgcBxELbZbBl7C2aTbRSTzofJYGZSSvz000/w+/3o6ekp9elUvWg0qhVw+P1+mM1mLWE7OjpCIBCA2WzW1gWqyWE4HMbLly8B/Dayq+4fHI1GtR1Eurq6YLfbtZFAdbpZvRFob28vWQIWj8fx+vVr1NfX4+233z6z3Y3RsZqYKE/cbjfMZjPMZjPcbjcmJia0tXxqAD2PyclJbSs4ANquIsDxQueFhQVtcfZlm0Sn9i8kKoQXL17A6/VW3eL8chKNRrG7u4tffvkFKysreP78Ofx+PxKJBPb397VdPiwWC7q6uuBwOJIaQgcCAayursJqtaKxsRF+vx8+nw+xWAyKosBut6O/vx83b95Ee3s7pJTY39/HixcvcHR0hKtXr2JkZARXr14tWSIYDAaxtraGrq4uDA4OVn0imA1HBolOZBs1U6d+003b5joVnK5yOLUiWB1lBHDh0b9s3G53UsNpujiODKa3tbWFX3/9FdeuXav6dh3FFolE4PV6sb+/j0AggHg8jkQigUgkohWEWK1W2Gy2rImRz+fDL7/8gsbGRthsNq0RsxBC6xFZV1eHeDwOn8+HQCCAWCyG9vZ2dHR0lMUOHurWcm+//TYLRXQ4TUx0BnV6V03C9MmhOqJ2UWq1nT5xTJfs6dcbTkxMMGErY0wGT/N6vfjhhx/Q09MDq9Va6tOpCmoCqG6npu5ZHolEtKnfurq6M3fWiMfjCAaD8Hq9WFtbQ3d3N+rq6iClRE1NDVpaWrSii8PDQwSDQUQiEbS2tqKtrQ1NTU1Zm00Xi5QSW1tbkFLi5s2b2hpHOsZpYqIzjI+PQ1EURKNRLSkLh8OYmZlJagp9ESaTSVsHqEo31Ts1NaVNCTMRpEoSDAbx+PFjdHZ2MhEsMP0U8KNHj/Drr79iZ2dHSwZtNhs6Ozu1qd9MiWAsFsPh4SH29vZwcHAAIQSCwSAcDgfq6+vR3NyMK1euoK2tDbFYDJubm3j16hXMZjOuXbuGkZER3LhxA3a7vSwSwVgshrW1NdTW1uIPf/gDE8Fz4AQ6VZ1so2/qyJ1+L2D9Gr7zcjgc2N7exvDwMKampvDNN99gcXERTqeTyR4ZRjQaxcrKCpqamspiitCI1MRtd3cXe3t7WhGH2WxGTU0NGhoaYLFYtKQs0xS92jJGneloaGjQWrxIKdHW1oZgMIiamhpt+ldNDHt6etDQ0FAWiV+qYDCIzc1N9PX1oaenpyQVy5WM08RUddIFicvsBJKOWhGsTi/rp4RZ0WsMnCY+lkgksLKyglgshs7OzlKfjqEkEglt5O7169c4PDzUpn/VSl6TyYREIpGU/EkpIYRAc3MzmpqaEIlEtJ1AAKCxsVF7Xzweh91u15pDCyEQjUYRi8VQU1NTEUUX+/v7ODw8xM2bN7nV4Rm4AwkZmj7BApBx5M/lOvU7AOD8O4HoqaN/qtSiELVgQ6Wv6GUySJVudXUVwWAQV69eLfWpGEIsFsPOzg7W19fx7NkzrRhECKGt/evv74fVaoXZbIaiKKducNW9gNfX19HR0YGamhrU1dWhvr5eW1NYX1+P1tZWLTHUU/sLlrtEIoGNjQ2YzWb8y7/8S1X3D7wsjgySIeiLP6SUp4o9amtrkUgkLlUEko7aW/A8WNFrDBwZBLa3t7XK4XKcOqwEauK2traG58+fY319XYtT6lZwdrsdVqtVGxm8evXqqWngRCKBUCiESCSCQCCASCSiTesmEglIKbXP0m8PV6nUaWF1S7tKv55i4cggGUrqur+hoSEsLi6iqakJOzs7p16fzxYtDocDe3t72s8+r6mpKSaBVPECgQB++eUXdHd3MxE8J3VnjufPn+PZs2daPLHZbGhqakJjYyPq6uq00blIJIKdnR3U1dUlJYKxWExLAOPxOKxWK6LRKIQQ6OnpQX19PVpaWrS1nEZZR6dOC7/99ttoa2sr9ekYApNBqjgulwuLi4va9/riDv10bT45nU6srKxo071c80fVLB6P48cff0RLSwsrh3MUDAaxvb2N9fV1vHz5EkdHRxBCwGKxoL29HXV1dUk9/YDjJNDn8wGA1r8vEonA7/drMxLq+wKBAPb399HW1oY333wTdrsdtbW1JbnWQlErmq1WK0ZGRvh3L4+YDBKAzEUN5VjsoE8EiyF1DaA6Jc01f1StVldXAYCL9c8QCoWwsbGBFy9eYGtrC4lEQmv+3NTUBKvVitraWm37N/37/H4/AKC5uRk1NTWIRCLY3d2FxWLRKojj8TgODg6gKAquXr2K69eva70Ajcbv92NnZwe9vb3o7e01zChnueCaQQJwuuHyWceLye1244svvoCU8lSxRr6pzaGBzE2fueaPgOpdM7izs4MnT56gv7+f/yCnEY1GsbW1hbW1NWxsbCCRSAAArFYr4vE4pJSwWq2oq6tLqtRNJBI4OjpCMBiElBL19fVQFEVr+mwymWAymSCl1GKUxWLB1atX0dHRcWZT6UolpcT29jYikQjefvttNDc3l/qUKhrXDFJW4+Pjp6pesx0vNP2IpJoIAvmZBtYvNB4eHsbKygoGBwe1aeCzEjyu+aNqFQqF8Msvv+DKlStMBHWklNjb28OzZ8+wsbGBcDistXfR7zpUX1+v7f2rUkcBA4EALBaLNlWsKIpWKaxuIad+Zm1tLdrb29HS0mLowolIJIKNjQ3Y7XYMDQ1VRIVzpeLIIJVE6vSzug7Q4XDA6/XmvepXb3JykskcXVq1jQxKKfH9999DURTu9XoiHA7jxYsX+OWXX+DxeLRt4OLxuDa1e3h4iMbGRnR2diIcDiMSiWjHFUXRdghpaGiA1WqFyWRCbW2tti+wuiOREALt7e2w2+1V0ULF4/Fgf38fN27cwJUrV0p9OobBkUEqK2qvvenpaW1XDqA4BSBMBInO7/Xr1wiFQujt7S31qZSUlBIHBwd4/Pgxnj59ilgspk3dWq1WtLa2IhgMYmtrC36/H42NjWhoaEAwGEQsFkMgEMDu7i6EELh27Rq6urq0at/a2lrU1NQgGo0iGAwiGAyitbUVra2tqK2trYrRWLVIpKamBv/yL//CHW2KhMkgFZ3L5Uoa+St0QYiiKDDiSA1RsYRCITx//hw9PT2lPpWSicfjWF1dxXfffYetrS3U1tZqCZq6E0gkEsH29jZ2d3dRW1uLa9euIZFI4ODgAKFQCMBx9e8f//hH9Pb2aqOBam/AQCAA4LhoxOFwaDuCVAuv14u9vT1cu3YNV69eZcuiImIySEXjdrsvvMdvLtQt4Obm5jA4OIhHjx4BuFgvQCL6zdOnT9HU1GTYIoVMpJTwer1YXV3F0tISDg8PUV9fD4vFAq/Xi3g8jrq6Oq1xdCQSQU1NDa5cuQKz2YxoNIqamho4HA50dXXhypUraG5uhpQSgUBA22rOarVq/QCrZQRQTx0NVBQFw8PDhq2ILmdMBqmg1ObQagf8fEvdU5jFHUT5tb+/D6/Xi76+vlKfSlFIKbUk7ccff8T6+jq8Xi/MZjPq6uoQiUQQi8VQV1cHq9Wq9fxrbGxES0sLAGgjhc3Nzejo6EBdXR3i8TjC4bC2FKapqQlXrlxBQ0NDVRdG+Hw+7O7uai1jOBpYGkwGqSDq6uoK0orG4XDg3//935N2HwFO7/9LRJcXj8fxyy+/wOFwGH606ujoCLu7u1hbW4PX68Xm5iai0Sii0WhSc221eMPv9yORSKC5uTlpn2C73Z7UNiYcDiORSKCxsVFrBJ1aUVyN4vE4Njc3YTKZOBpYBpgMUl6o1cHqtnCFYLPZsLW1BQCnRv84GkiUfy9fvoSiKKirqyv1qRREMBjEq1ev8PPPP2N7exuhUAiNjY2IRqMwm81oamqCz+eDoihaUuf3+2Gz2WCz2VBTU4Oamhpt+zi1Gri+vl47pr6OfuPz+bC3t4erV69yNLBMMBmkS9OvBcxXIuhwOODz+bTRPo78ERXX0dER1tfXDTc9HIvFsL6+jp9//hlra2uIx+NaIUc8HteaPfv9fvj9fgSDQYRCIW23kKamJjQ3N8Nutyet87NarbBYLLBYLFU/6peJOhoohMDvf/97NDY2lvqU6ASTQbqwzs7OvLWCSU3+UrfA48gfUXH9+uuvhmpqvLe3h59//hk//fQTotEo6uvr0dfXp+31G41G0dTUpLWAkVLCbrfjxo0b6OrqQnNzMxoaGlBXV8eRrAtQ+waqo4FG+XtlFEwGKWdqMQhwvHPHRRJBtd9fth0/uPcvUWl5vV4cHR2hv7+/1KdyKdFoFC9fvsTKygo2NjZgNpvR2dmprQEMhUJYXV3FwcEB6uvr0dTUhO7ubvT09KCzs1PbF5guTi2asVqtXBtYxpgM0pnUJFC/rdJFpoOdTmdO/f5KtQUeER178eIF7HZ7qU/jwnw+H54+fYrHjx8jFAqhtrYWN27cQENDA2KxGA4PD/Hy5Uv4fD7U19fjvffeQ19fX1W2zykUdYs+v9+P69evo6uri9PnZYzb0dGZ1JG6XOmnfDmyR0Zl1O3ofD4flpeX0dfXV1H/eCcSCXg8Hvz44494+fKlNhXc1NQERVFweHgIv98PIQQSiQRsNhtu3ryJGzduaJXClB9HR0fY2dlBS0sLBgYG+N+3jGSKW1z4QKe43W7YbDa43W4AxyN1uZicnISUEltbWwgGg0wEiSrQ2toampubKyYRDIfD2NjYwD//+U/8z//5PxEIBNDc3Iy6ujqEw2FsbW1ha2sLFosFb7zxBq5fv46RkRH827/9G9555x0mKnkUi8Xw6tUr7O/v4+2338bNmzf537dCcJqYkugrg9V9gxcWFrT9g51OJwBoX1fyCAgRJTs8PITX6y37tYLqjh87Ozvw+Xyoq6vTGkOrO380NDSgtbUVzc3NqK+vx+HhIaLRKLq7u9Ha2loxyW6l2N/fh8fjQW9vL65evcoCkQrDZJCSzM7OJn2vrg1k0kdkfOU+KiilhMfjwebmJmKxGBoaGrT9ki0WC+LxOGpqamCxWLRkxO/3Y3d3F62trdo2cZQ/wWAQW1tbaGxsxMjIiGF7Uhodp4mrlNvt1u6i1elg4HhK2GazweFwADhe/6efMiYiYwoGg/B4PNqWauUkHo9jZ2cHy8vLeP36NRoaGtDV1ZVUmaquD6ytrdWaRKu7iLz55pvo7e1lIphH0WgUr169wu7uLt588028++67TAQrWFEKSIQQdgBjAFYBrEopl7IdV1X6Quxyo+4SMj4+jtnZWa0oxGazZdw6Ti0eyfYaompktAKS9fV1bG9vo6urq9SnoolGo9jd3cX29jZqamrQ3Nx8ZrVvLBaDx+NBPB7H1atXy3qksxIlEgns7u7i6OgI165dQ3d3N6eEK0ipC0jGAMxLKe8D+CiH41QAagI4NzeH8fFxKIoCRVGytnBRRwrZ5oXI2DY2NtDc3Fzq0wBwPEq5traGlZUV+Hw+OBwOdHR0ZE0E1Snk7e1ttLa24p133oHdbmcimEcHBwd48eIF6uvr4XK52DzaQIqVDL4npfScfD2Qw3EqAH1iNzU1hVgshlgslrXqd2pqipXBRAan7sBRW1tb8vNYXV3FkydPEIlEtGKPs6Z3/X4/NjY2YLFY8M4776Czs5O7hORRIBDA8+fPEYvF8Pvf/x5vvPEGq4QNpmgLKIQQ9pPEz57LcQDY2dmBy/XbaObY2BjGxsYKep5GNjU1xaSO6BLm5+cxPz+vftue7jWVGLf29vZKtt5LSgmfz4eNjQ2tN2B3d3dO7w0EAvB6vaitrcUbb7zBNWt5FolEsL29DSkl3nrrLbS1tZX6lOgCcolbxVozeAfAfSnlqhDiKynlB9mOqyp17Q1VL/26TCbexmaUNYNSSvzjH/9AZ2dnUUd7EokE9vf3sbm5CQBobGzMOZkLhULweDywWCzo7u5GY2NjIU+16iQSCezs7CAYDKKvrw9XrlzhSKtBZIpbxS4g8QBYOPnzFoB5/XEWkFClY8FN9TBKMnh4eKjtOFIMsVgMu7u72NnZgclkQnNzc85JaDgchsfjgclkQk9PD5qamrgmMI+klNjf34fX60VnZyf6+vq4PZ/BlLSARErpkVJ+LqWcl1IuSSlXT75POl6Mc6k2qbuJUGGx4IYqzdHRUVH+wY9Go9jY2MDKygoODg7Q3t4Oh8ORUyIYjUaxvb0Nj8eD7u5u3Lx5k1XCeaQmgc+fP0dNTQ1GRkbwxhtvMBGsItybuEJcdPqRI1VEhWGUkUG1WKO1tbUgnx+NRrGzs4Pt7W3YbDY0Nzfn3O9PbRMTi8XQ1dWFtrY2TlfmmcfjgcfjQVNTE/r7+5N6N5LxlLq1DF2Svi3MeXCkioiyOTw8LEgVcSQSwfr6Oh4/fgyfz6clc7kkgolEAnt7e9jZ2UFLSwveeecddHR0MBHMI5/Ph+fPnyMajWJoaAhDQ0NMBKsY27FXiPHxcczNzZ07qWMFMRFlkkgkEAgE8tpoOhwOY3t7W6tQ7urqyjmJk1LC6/Xi6OhI6y1YU1OTt3Oj4zY8e3t7sNlsWi9GIt5mVYhM/f64JpCILioYDMJsNudl7V04HMbLly/x+PFjhEIhXLlyBS0tLTkngl6vF69fv9aSlO7ubiaCeRQIBPDy5UscHh7izTffxPDwMBNB0nBksIK53W5MT08DAObm5jgCSETnoiaDl6EfCayvr0dPT8+5kkufzwe/34+mpia8/fbbsNlslzofSub3+3FwcACTyYSBgQG0t7ez8IZOYTJYwWZnZ7WvuSaQiM5LSnnhxCA1Cezu7r5wEvjmm2+WfPcTo/H5fPB4PKipqcGNGzfQ1tbGJJAy4jRxGcp16lctDpmcnOSoIBEVRTgcxtraGn788UeEQiF0d3efaw9gn8+H169fw2Qy4c0338T169eZCOaJlBIHBwd4/vw5QqEQ3nrrLYyMjHA0kM7E1jJliO1giMqfEVrLbG9vY21tLaft3yKRCLa2trSRwPP2+dOPBHZ1dTEBzCM1CfR6vWhqasK1a9fQ3Nxc6tOiMsTWMmUo0wgg28EQUbmIRqN49eqVVhhy3pFAtTCEI4H5l0gksLu7i2fPnkFRFPzhD3/Au+++y0SQzo0jgyWkjgAqigKz2cz9bIkqiNFHBuPxuNYs2mKxnKsyWEoJn8+Ho6MjNDc3o7OzkwlgHkWjUezv7+Po6AidnZ3o6enJeV9nqm4cGSxD6ggggAs1lCYiugyLxYJ4PJ50LJFIYGdnB48fP8bBwQE6Ojpy3vlDSgmPx4PXr1+jpqYGb731Fvr7+5kI5snR0RHW19fx6tUrtLS0wOVy4Y033mAiSJfGZLCE1N6BExMTsNlsGBwcZM9AIiqahoYGRCIRAMeJ3N7eHlZWVrC9vY22tja0t7fnvGPIwcGB1ifw5s2b6OvrY5uYPEgkEtjf38eLFy/g8/nQ19eHf/3Xf0V/fz//+1LeMBkssnTrBNWkcHl5mSOERFQ0ZrMZNpsNm5ub+PHHH7G5uYmWlhY4HI6cGj7H43Hs7+9jY2MDdXV1eOedd9Db2wur1VqEsze2aDSKra0tPHv2DCaTCe+88w6cTic6OzuhKEqpT48MhslgkWXbY5iFI0RUTAcHB9jY2MAvv/yCxsZGOByOnBK5aDSK3d1dbG5uorGxEYODg7h69SosFksRztrYUqeC33vvPbzzzjssCqGCYtPpIsu2xzD3ESaiYvD5fHj27Jm2B7DH48lpyjEcDsPr9SKRSKCzsxOtra2X3sGEgFgsBq/XC7/fD4vFgr6+PrS3t3MEkIqGv8UF4Ha7MTs7m7Y6mAkfEZXK0dERnj9/Do/Hg5aWFvT39yMWi2FnZweRSCTjyF4gEIDP54OiKOjq6jpXZTGlJ6WE3++H1+tFNBpFZ2cn+vr60NTUVOpToyrE1jIFwKbRRMZXSa1lIpEI1tbWsLm5CbvdjpaWlqQ+gRsbG9jZ2cGVK1eS3qe2h7HZbOjs7ERTUxN3srikcDgMj8eDQCCAhoYGdHd3o7W1laOAVBRsLZMHqcUfbBpNROUskUjg1atXWFhYwOHhIfr7+9Ha2noqoXM4HIjFYgiFQkgkElp7GCEEbty4gTfffPPcO47Qb9SK4JcvX2Jrawutra0YGRnBH/7wB3R0dDARpJLjyOA5pI746b+/fft2xqlhIjKech8Z3N/fx9OnTyGlhMPhOLO449WrV3jy5AlaWlrQ1taGjo4Oti65BHUa2OfzIRwOo62tDVeuXGFSTSXFkcE8SB3x03+vVgnPzMywVyARlczR0RG+//57/Pzzz7Db7WdW+YZCIbx69QrhcBitra3o6upCb28vE8ELkFLi8PAQr169wrNnzxAKhdDb24t//dd/xc2bN8+1jR9RMXFkME/cbjfm5uYQjUYRj8e5XpDI4MptZDAWi+Hly5d49eoV7HY7Wltbs77e7/fj4OAAANDb2wuHw4F4PI5Hjx6hubmZhQw5UkcADw8PEQqF0NTUBIfDgZaWFvZbpLKTKW6xmjhP1CphNSnkekEiKgYpJXZ2drC6uoqamhr09fVlXIMWj8fh8XhweHiIuro6DAwMJG01ZzabMTQ0hO+//x5CCDQ2NhbzUipGugSwt7cXLS0t7LVIFYnJYJ6xdQwRFYvf78fTp08RDAbR0dGRcQ/gUCiEg4MDBINBOBwO9Pf3Z0z06uvr8e677+KHH35ANBo9c4SxWkSjURweHiIQCCASiTABJENhMkhEVGGklFhfX8eLFy/Q0tKCa9eupX2N1+vF4eEhAODq1avo6OjIKXFpaGjA8PAwnjx5gpcvX6Kzs7PqEh519M/v9yMcDsNkMqG1tRVXrlxBU1NTTtv1EVUKJoNERBUkFArh559/RjgcxrVr107tABIOh3FwcIBAIIDm5ma88cYbp/oK5qK2tha///3vsbGxgWfPnqG5udnwo4ThcBiHh4cIBoOIRqNoamrSKoDr6upY/EGGVfXJYLbdQoiIysnW1haePn2KpqYmXL16VTuuHwWUUqK7uxsOh+PSFcFCCHR3d6OlpQVPnjzBixcv0NzcbIj2KFJKhEIhBAIBhEIhRCIRmM1mtLe3o7e3F42Njdxqj6pG1VcTc7cQIrqIYlYTSynx5MkT7O3t4cqVK7BarUgkEjg8PNSmMZubm9HT0wO73V6QreKklDg4OMCrV6/g9XpRX19fUevlYrEYAoEAgsEgIpEIIpEI6urq0NLSgqamJjQ0NLCdDhkeq4kzGB8fZ/UvEZW1X3/9FR6PBz09PTg6OtL2Erbb7ejr64Pdbi94UiaEQGtrK1pbWxEMBrG9vY3Xr1/DZDKhrq4OdXV1sNlsJR8xTCQSCIfD2mhfNBpFNBqFyWTS2r7U19ejoaGBI39EJ6p+ZJCI6CKKNTIopcT//t//G7FYDDU1NWhubobD4YDdbi95MpNIJHBwcACPx6Ptt2uxWGC1WrXksBDnmEgkEIvFEI1GEQ6HtaQvFosBAOrq6lBfX4/6+nrU1tZq50JU7TgySERUgYQQ+OMf/wgAJU/+UplMJrS1taGtrQ3A8VSs2n/v4OAAe3t7iEajUBQFiqLAZDJpXyuKAiEEMg1ISCkRj8cRj8eRSCSQSCQQj8e111ssFthsNtTX12tb59lsNlgslpKPThJVmvKKLEREdEq5JYGZmM1m2O122O129Pb2AjgexVOnatWHumYvHTWRM5lMsFgsMJvNqKmpSfozU1NtIrqYyogwRERUkUwmE6xWK7dmIypj+S85IyIiIqKKwWSQiIiIqIoxGSQiIiKqYkwGiYiIiKoYk0EiIiKiKsZkkIiIiKiKMRkkIiIiqmJMBomIiIiqGJNBIiIioirGZJCIiIioijEZJCIiIqpiTAaJiIiIqlhRkkEhhF0IcUcIcUsIMaI7PiCEWBRC3BNCDBTjXIiIiIjoN+Yi/ZwxAPNSSo8Q4i6AJd1zf5ZSeop0HkRERESkU6xp4vd0CV/qCOCHQogx/YihamdnBy6XS3vMz88X/ESJiDKZn5/X4hGA9nSvYdwionKSS9wSUsqCn4gQ4isAfzkZGfxaSvl+mtfck1J+rD/mcrnkwsJCwc+PiOi8hBCLUkpX6nHGLSIqV5niVl6niYUQt1IOeaSUDwA8BNAKwHPyUF8/BuDvJ6OGrfk8FyIiIiI6W16TQSnl/QxPzQMYE0J4AHx2UixyC8B9AK6T7z/N57kQERER0dmKUkByMvL3ecph9fvVYpwDEREREZ3GPoNEREREVYzJIBEREVEVM1wyWI1tHKrxmoHqvO5qvGbA2Ndt5GvLhtddParxmoHKum4mgwZQjdcMVOd1V+M1A8a+biNfWza87upRjdcMVNZ1Gy4ZJCIiIqLcFaXp9EUJIXYAvDjn29oB7BbgdMpZNV4zUJ3XXY3XDJTndfdJKTtSD14gbpXjtRUDr7t6VOM1A+V53enjVjkng0RERERUWJwmJiIiIqpiTAaJypQQwi6EGBVC3Elz/I4Q4pYQYqRU51coWa57QAixKIS4d7JrERGVmWqMW0aIWUXZgYTyRwhhBzCG451bVqWUS9mOG0GWax4A8BWABQB3pZSG2s1GSukRQqwCeD/lqTEA8yfP3wVgmP/XQNbrBoA/n+xoRBWEcYtxCwaOW0aIWYYZGcx011FJmXmO1F+o+wA+yuG4EWS7tj9LKT82WkA9w3u64GKEv9Pn8aEQYswoIwuMW4xbJTivUqnWuFURMcswySCq5xcv0y+UkX/Rsl1bRfyi5dvJqAMA2LO8zFCklKtSynkp5TyAj0t9PnnCuMW4VTWqLW5VUswyUjJYNb94mX6hjPyLlu7aKukXLc8eAmg9+dpTwvMoqpPfYfvJt63ZXltBGLcYt6pF1cWtSopZhlozKISwnwRWu3rs5K56/uT5e6j8Xz71F8qD5F+oTMeNIO21CSHGAPz95P95Wf+iXcIogBHdVOEtHP99HhNCeAB8VqoTK7B0130fgOvk2KclO7M8Y9xi3DKgaoxbFR2zKq7PoBDiVsohj5TywUkVz30p5aoQ4isp5Qcnr9d+8fTHK5VuUbIHxwuQPdD9oqnHDboQ24Pka76P49GUAQAPDDKdRgbEuMW4BcYtKmMVlwxmwl88Iqo0jFtEVA4MkwwSERER0fkZqYCEiIiIiM6JySARERFRFWMySERERFTFmAwSERERVTFD9Rmk6nbSjmMVwAdSypz7sgkhRnG8p+RDAANSys8LdIpEREkYt6gccGSQDOGkqecNKeWDC7x9AYD9ZEuw+fyeGRFReoxbVC44MkhGMQLg4UnfNo/+iUwNf9VvThr7al8X9CyJiH7DuEVlgX0GyRBOgumHAG4AeHhyt5zre0dwPM2S83uIiC6LcYvKBZNBMhQhxF0An/FOmYgqBeMWlRqnickQToLp1wCeMqASUSVg3KJywZFBIiIioirGamIiIiKiKsZkkIiIiKiKMRkkIiIiqmJMBomIiIiqGJNBIiIioirGZJCIiIioiv1/z3Ak381frvEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#------------------------------------------------------------\n",
    "# plot the results\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "fig.subplots_adjust(left=0.12, right=0.95,\n",
    "                    bottom=0.1, top=0.95,\n",
    "                    wspace=0.02, hspace=0.02)\n",
    "\n",
    "# only plot 1/10 of the stars for clarity\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax1.scatter(Y[::10, 2], Y[::10, 3], s=9, lw=0, c='k')\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax2.scatter(X[::10, 2], X[::10, 3], s=9, lw=0, c='k')\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax3.scatter(X_sample[::10, 2], X_sample[::10, 3], s=9, lw=0, c='k')\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "for i in range(clf.n_components):\n",
    "    draw_ellipse(clf.mu[i, 2:4], clf.V[i, 2:4, 2:4], scales=[2],\n",
    "                 ec='k', fc='gray', alpha=0.2, ax=ax4)\n",
    "\n",
    "titles = [\"Standard Stars\", \"Single Epoch\",\n",
    "          \"Extreme Deconvolution\\n  resampling\",\n",
    "          \"Extreme Deconvolution\\n  cluster locations\"]\n",
    "ax = [ax1, ax2, ax3, ax4]\n",
    "\n",
    "for i in range(4):\n",
    "    ax[i].set_xlim(-0.6, 1.8)\n",
    "    ax[i].set_ylim(-0.6, 1.8)\n",
    "\n",
    "    ax[i].xaxis.set_major_locator(plt.MultipleLocator(0.5))\n",
    "    ax[i].yaxis.set_major_locator(plt.MultipleLocator(0.5))\n",
    "\n",
    "    ax[i].text(0.05, 0.95, titles[i],\n",
    "               ha='left', va='top', transform=ax[i].transAxes)\n",
    "\n",
    "    if i in (0, 1):\n",
    "        ax[i].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "    else:\n",
    "        ax[i].set_xlabel('$g-r$')\n",
    "\n",
    "    if i in (1, 3):\n",
    "        ax[i].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "    else:\n",
    "        ax[i].set_ylabel('$r-i$')\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Second figure: the width of the locus\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "labels = ['single epoch', 'standard stars', 'XD resampled']\n",
    "linestyles = ['solid', 'dashed', 'dotted']\n",
    "for data, label, ls in zip((X, Y, X_sample), labels, linestyles):\n",
    "    g = data[:, 0]\n",
    "    gr = data[:, 2]\n",
    "    ri = data[:, 3]\n",
    "\n",
    "    r = g - gr\n",
    "    i = r - ri\n",
    "\n",
    "    mask = (gr > 0.3) & (gr < 1.0)\n",
    "    g = g[mask]\n",
    "    r = r[mask]\n",
    "    i = i[mask]\n",
    "\n",
    "    w = -0.227 * g + 0.792 * r - 0.567 * i + 0.05\n",
    "\n",
    "    sigma = sigmaG(w)\n",
    "\n",
    "    ax.hist(w, bins=np.linspace(-0.08, 0.08, 100), linestyle=ls,\n",
    "            histtype='step', label=label + '\\n\\t' + r'$\\sigma_G=%.3f$' % sigma,\n",
    "            density=True)\n",
    "\n",
    "ax.legend(loc=2)\n",
    "ax.text(0.95, 0.95, '$w = -0.227g + 0.792r$\\n$ - 0.567i + 0.05$',\n",
    "        transform=ax.transAxes, ha='right', va='top')\n",
    "\n",
    "ax.set_xlim(-0.07, 0.07)\n",
    "ax.set_ylim(0, 55)\n",
    "\n",
    "ax.set_xlabel('$w$')\n",
    "ax.set_ylabel('$N(w)$')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
