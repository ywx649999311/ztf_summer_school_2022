{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Problem 1: Linear least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares formulation\n",
    "\n",
    "\"Linear least squares\" is a method for fitting a model which depends **linearly on its parameters**. Outside astronomy (for example, machine learning), the popular term for linear least-squares is \"linear regression.\"\n",
    "\n",
    "- An important note: You can use linear least squares even when your model **isn't linear with respect to the data**. For example, the model $y(x)=\\beta x^2$ is linear with respect to the parameter $\\beta$, even though it's nonlinear with respect to the data $x$; therefore, we can use linear least squares to fit $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup:** When using linear least squares, you assume that your data can be expressed with the following equation:\n",
    " \\begin{equation}\n",
    "   {\\bf y} = {\\bf X}{\\bf \\beta} + {\\bf \\beta_0} + {\\bf \\epsilon}\n",
    " \\end{equation}\n",
    "\n",
    "where $y_i$ is the $i$th measurement and $\\epsilon_i$ the corresponding noise; here $i$ ranges from 1 to $n$. When fitting your model, you will be given input data $\\bf X$, then fitting parameters $\\bf \\beta$ and $\\beta_0$ to predict measurements $\\bf y$ as accurately as possible.\n",
    "\n",
    "Some jargon:\n",
    "- ${\\bf y}$ is called the \"response\" vector,\n",
    "- $\\beta_0$ is the intercept,\n",
    "- ${\\bf \\beta}$ is the slope, and \n",
    "- ${\\bf X}$ is the \"predictor\" matrix.\n",
    "\n",
    "Each of these parameters has a specific shape.\n",
    "- $\\bf \\beta$ has shape $(m,1)$ where $m$ is the number of parameters in the model.\n",
    "- $\\bf y$ has shape $(n,1)$, where $n$ is the number of dimensions you are trying to predict.\n",
    "- Finally $\\bf X$ is a matrix with dimensions $(n,m)$.\n",
    "\n",
    "These models are designed to have multiple input dimensions and multiple output dimensions. For example, a model could use a galaxy's **magnitude in the i-band, r-band and g-band** to predict its **mass** and its **redshift**. It would then have $m=3$ (three dimensions of input data) and $n=2$ (two dimensions of output data). [*Caution - this is purely for example purposes and would probably be a terrible model.*]\n",
    "\n",
    "A few final notes:\n",
    "\n",
    "- Usually the intercept $\\beta_0$ is included in ${\\bf \\beta}$ (and a column of 1's is appended to $\\bf X$ to match).\n",
    "- When $m>1$ -- i.e. when there are multiple parameters -- this problem is called \"multiple linear regression\". \"Multi-variate (multiple)\" linear regression is when ${\\bf y}$ has more than one column. \n",
    "- Finally, the least squares is optimal only when ${\\bf\\epsilon}$ results from Gaussian processes. That is, the error on any combination of parameters must form a Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting a model:** Least-squares regression refers to finding the best-fit parameters $\\hat \\beta$ minimizing the sum of squared errors between the data and your model's predictions. There's a simple formula for this:\n",
    " \\begin{eqnarray*}\n",
    "  \\bf{\\hat{\\beta}} &=&({\\bf X}^T{\\bf X})^{-1}{\\bf X}^T{\\bf\n",
    "  y}.\n",
    " \\end{eqnarray*}\n",
    "The post-fit value and the corresponding residuals are given by\n",
    " \\begin{eqnarray*}\n",
    "  \\hat{\\bf y} = {\\bf X}\\hat{\\bf\\beta},\\qquad {\\bf e} = {\\bf y} -\n",
    "  {\\hat{\\bf y}}.\n",
    " \\end{eqnarray*}\n",
    "Linear algebra assures you that the resulting sum of the squares\n",
    "of the residuals, ${\\bf e}{\\bf e}^T$, is the smallest value\n",
    "possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The problem**: Improving telescope pointing\n",
    "\n",
    "Recall that astronomers use two coordinates to identify objects on the sky.\n",
    "- **Right ascension** (RA) is parallel to the direction of Earth's rotation, and it is a polar angle (similar to latitude on Earth).\n",
    "- **Declination** is perpendicular to right ascension, and is the azimuthal angle (similar to longitude).\n",
    "\n",
    "We will be using a linear least squares method to create and fit a model of \"pointing error\" (error in aligning to a requested set of angles) on a particular telescope, the Palomar 48-inch Oschin telescope (or P48 for short). Each night, P48 is given a long list of requested observation locations in terms of right ascension and declination. It then rotates on its two axes to find that location: These axes are called the **hour angle (HA)** and **declination (DEC)** axes.\n",
    "- Hour angle corresponds to right ascension. However, the **right ascension of a target is constant**, while the **hour angle needed to observe it changes depending on the time of day** due to the rotation of the Earth.\n",
    "\n",
    "A telescope's pointing performance measures how accurately it is able to align itself to a requested hour angle $h$ and declination angle $\\delta$. These errors are expressed $\\Delta h$ and $\\Delta \\delta$ (or \"raoff\" and \"decoff\").\n",
    "\n",
    "For this analysis, we will use a basic pointing model which accounts for a few things (explained in more detail in the appendix):\n",
    "\n",
    "1. Non-alignment of the axis of the fork of the telescope and the Earth's rotation\n",
    "2. Deviation from orthogonality between the axes of the astronomical \"latitude\" and \"longitude\" (\"hour angle\" and \"declination\") motors\n",
    "3. Lack of parallelism between the optical and mechanical axes of the telescope (\"collimation\") and \n",
    "4. A simple model for the mechanical warping (\"flexure\") of the telescope.\n",
    "\n",
    "This model is described in a classic paper by [P. T. Wallace & K. P. Tritton (1979; MNRAS)](http://articles.adsabs.harvard.edu/pdf/1979MNRAS.189..115W). It has been applied to other telescopes than the P48 since its publication: This model estimated that the UK 48-inch Schmidt telescope, a later version of the P48, could accurately point to locations on the sky to within 1/10 of a degree.\n",
    "\n",
    "### The model\n",
    "\n",
    "The Wallace & Tritton model maps a series of requested angles, $\\bf h$ and $\\bf \\delta$, to the expected errors on these angles. The equation is given below:\n",
    "\\begin{eqnarray}\n",
    "\t\t\\label{eq:dh}\n",
    "\t\\Delta h&=& \\tan(\\delta)\\big[{\\rm ME}\\sin(h)-{\\rm MA}\\cos(h)+{\\rm NP}\\big]+\n",
    "\t+ {\\rm CH}\\sec(\\delta) + {\\rm IH}\\\\\n",
    "\t\t\\label{eq:dd}\\cr\n",
    "\t\\Delta\\delta &=& \\cos(h)\\big[{\\rm ME}+{\\rm FO}\\big]+{\\rm MA}\\sin(h)+{\\rm ID}\n",
    "\\end{eqnarray}\n",
    "\n",
    "There are 7 parameters in this model: $\\rm ME$, $\\rm MA$, $\\rm NP$, $\\rm CH$, $\\rm FO$, $\\rm ID$, and $\\rm IH$ (these are described in much more detail in the appendix). Thus, we can construct a vector for $\\bf \\beta$:\n",
    "\n",
    " \\begin{equation*}\n",
    "  {\\bf\\beta}\\equiv\\begin{pmatrix} {\\rm ME}\\\\ {\\rm MA}\\\\ {\\rm NP}\\\\\n",
    "  {\\rm CH}\\\\ {\\rm FO}\\\\ {\\rm ID}\\\\ {\\rm IH} \\end{pmatrix}.\n",
    " \\end{equation*}\n",
    "\n",
    "Similarly, we are trying to predict the errors $\\Delta h$ and $\\Delta \\delta$ on each measurement. Thus, if we are taking $n$ measurements, we can (arbitrarily) construct $\\bf y$ as a $2n \\times 1$ vector like so:\n",
    "\n",
    " \\begin{equation*}\n",
    "  {\\bf y}\\equiv\\begin{pmatrix} \\Delta h_1\\\\ \\Delta\\delta_1\\\\ \\Delta\n",
    "  h_2\\\\ \\Delta\\delta_2\\\\ ...\n",
    " \\end{pmatrix}\n",
    "\\end{equation*} where the subscript is the index of the measurements,\n",
    "$i=1,2,...n_{meas}$. (This approach is not unique. For instance, we could\n",
    "have listed all of $\\Delta h$ first and followed it by $\\Delta\\delta$. Similarly, we could have constructed $\\beta$ differently.)\n",
    "\n",
    "Having specified ${\\bf y}$ and ${\\bf\\beta}$ we now have fully\n",
    "specified the rules for  constructing the response matrix, ${\\bf\n",
    "X}$.  For instance, consider a pair or rows of ${\\bf X}$  with row\n",
    "index  $K=2i-1$ and $ K^\\prime=K+1$:\n",
    " \\begin{eqnarray*}\n",
    "  {\\bf X}=\\begin{bmatrix}\n",
    "   .&.&.&.&.&.&.&\\\\\n",
    "    \\sin(h_K)\\tan(\\delta_K) & -\\cos(h_K)\\tan(\\delta_K) & \\tan(\\delta_K)&\n",
    "   \\sec(\\delta_K) &0 &0 &1\\\\ \\cos(h_{K^\\prime}) & \\sin(h_{K^\\prime})\n",
    "  & 0 & 0 & \\cos(h_{K^\\prime}) & 1 & 0\\\\\n",
    "   .&.&.&.&.&.&.&\n",
    " \\end{bmatrix}. \n",
    "\\end{eqnarray*}  \n",
    "The size of ${\\bf X}$ matrix is ($2n,7$) whereas that of ${\\bf y}$ is $(2n,1)$.\n",
    "\n",
    "With $\\bf y$, $\\bf \\beta$ and $\\bf X$ defined, we have completely specified the model. We now need to fit it via least squares regression.\n",
    "\n",
    "### Data\n",
    "\n",
    "In the \"data/\" folder, we placed files which yields offsets for a given night. Each field\n",
    "observed during a given night results in a data record: time,\n",
    "ra, dec, ha, raoff, decoff.  The collection of records for a given\n",
    "night constitute our basic and essential data.  Refined\n",
    "models would benefit from having pressure and temperature (top of\n",
    "dome, bottom of dome, ambient) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: IllegalSecondWarning: 'second' was found  to be '60', which is not in range [0,60). Treating as 0 sec, +1 min [astropy.coordinates.angle_utilities]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import Angle\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "INFILE='data/2021-02-04.csv'\n",
    "df = pd.read_csv(INFILE)\n",
    "t = Table.from_pandas(df)\n",
    "\n",
    "start_times, end_times = [], []\n",
    "ras, decs, has = [], [], []\n",
    "ra_offset, dec_offset = [], []\n",
    "for row in t:\n",
    "    start_times.append(Time(row[\"start_time\"], format=\"iso\"))\n",
    "    end_times.append(Time(row[\"end_time\"], format=\"iso\"))\n",
    "    ras.append(Angle(row[\"ra\"], unit=u.hour).deg)\n",
    "    decs.append(Angle(row[\"dec\"], unit=u.deg).deg)\n",
    "    has.append(Angle(row[\"ha\"], unit=u.hour).deg)\n",
    "t[\"start_time\"], t[\"end_time\"] = start_times, end_times\n",
    "t[\"ra\"], t[\"dec\"], t[\"ha\"] = ras, decs, has"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Form the X-array and y-array (in preparation for least-squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genX_tpoint(ha, dec):\n",
    "    sh=np.sin(ha*(2*np.pi/360))\n",
    "    ch=np.cos(ha*(2*np.pi/360))\n",
    "    td=np.tan(dec* (2*np.pi/360))\n",
    "    sd=1.0/np.cos(dec* (2*np.pi/360))\n",
    "\n",
    "    x = np.zeros((2,7))\n",
    "    # YOUR CODE HERE: See X equation\n",
    "    x[0,:]=[, , , , , , ]\n",
    "    x[1,:]=[, , , , , , ]\n",
    "    \n",
    "    return x\n",
    "\n",
    "n=len(t[\"ha\"])\n",
    "X=np.zeros((2*n,7))\n",
    "y=np.zeros((2*n,1))\n",
    "\n",
    "for j in range(n):\n",
    "    ind=2*j  \n",
    "    #convert raoff1 to haoff1 (see Wallace & Tritton 1976)\n",
    "    y[ind]=t[\"ra_offset\"][j]/np.cos(t[\"dec\"][j] * (2*np.pi/360))\n",
    "    y[ind+1]=t[\"dec_offset\"][j]\n",
    "\n",
    "    xhd = genX_tpoint(t[\"ha\"][j],t[\"dec\"][j])\n",
    "    X[ind,:]=xhd[0,:]\n",
    "    X[ind+1,:]=xhd[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Solve the least-squares problem\n",
    "\n",
    "Compute b_hat:\n",
    " \\begin{eqnarray*}\n",
    "  \\bf{\\hat{\\beta}} &=&({\\bf X}^T{\\bf X})^{-1}{\\bf X}^T{\\bf\n",
    "  y}.\n",
    " \\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "D=np.dot(X.T,X)\n",
    "b_hat = ...\n",
    "\n",
    "MODEL = {}\n",
    "MODEL[\"ME\"] = b_hat[0]\n",
    "MODEL[\"MA\"] = b_hat[1]\n",
    "MODEL[\"NP\"] = b_hat[2]\n",
    "MODEL[\"CH\"] = b_hat[3]\n",
    "MODEL[\"FO\"] = b_hat[4]\n",
    "MODEL[\"ID\"] = b_hat[5]\n",
    "MODEL[\"IH\"] = b_hat[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Plot the residuals as a function of HA and Declination\n",
    "\n",
    "What is the approximate size of the circle (in arcseconds) which contains most of the points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_offsets(MODEL, ha, dec):\n",
    "    ME = MODEL[\"ME\"]\n",
    "    MA = MODEL[\"MA\"]\n",
    "    NP = MODEL[\"NP\"]\n",
    "    CH = MODEL[\"CH\"]\n",
    "    FO = MODEL[\"FO\"]\n",
    "    ID = MODEL[\"ID\"]\n",
    "    IH = MODEL[\"IH\"]\n",
    "\n",
    "    m_raoff=((ME*np.sin(ha*(2*np.pi/360))-MA*np.cos(ha*(2*np.pi/360)))*np.tan(dec*(2*np.pi/360))+\\\n",
    "             NP*np.tan(dec*(2*np.pi/360)) + CH/np.cos(dec*(2*np.pi/360)) + IH)*np.cos(dec*(2*np.pi/360))\n",
    "    m_decoff=(ME+FO)*np.cos(ha*(2*np.pi/360)) + MA*np.sin(ha*(2*np.pi/360)) + ID\n",
    "\n",
    "    return m_raoff, m_decoff\n",
    "\n",
    "m_raoff, m_decoff = model_offsets(MODEL, t[\"ha\"], t[\"dec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Q4: Using a Gaussian Process to improve upon the estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, DotProduct, ConstantKernel, RationalQuadratic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As a reminder from class: for our data to be well interpolated by this Gaussian Process, it will need to be rescaled such that it has zero mean and unit variance. There are [standard methods for doing this](http://scikit-learn.org/stable/modules/preprocessing.html), but we'll do this rescaling here for transparency - and so we know what to add back in later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Rescale():\n",
    "    def __init__(self, y):\n",
    "        self.original_data = y\n",
    "        self.mean = np.mean(y)\n",
    "        self.std = np.std(y)\n",
    "        self.transform()\n",
    "        return\n",
    "    def transform(self):\n",
    "        self.y = (self.original_data - self.mean) / self.std\n",
    "        return()\n",
    "    def invert(self, scaled_y):\n",
    "        return (scaled_y * self.std + self.mean)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train_idx = np.random.choice(np.arange(len(t[\"ha\"])),int(len(t[\"ha\"])/3),replace=False)\n",
    "test_idx = np.setdiff1d(np.arange(len(t[\"ha\"])), train_idx)\n",
    "\n",
    "ha_rescaled = Rescale(t[\"ha\"])\n",
    "dec_rescaled = Rescale(t[\"dec\"])\n",
    "ra_offset_rescaled = Rescale(t[\"ra_offset\"])\n",
    "dec_offset_rescaled = Rescale(t[\"dec_offset\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Use the GaussianProcessRegressor with a RationalQuadratic kernel to predict the offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Use all of our datapoints:\n",
    "x_rescaled = np.vstack((ha_rescaled.y,dec_rescaled.y)).T\n",
    "rescaled_ra_y = ra_offset_rescaled.y.T\n",
    "rescaled_dec_y = dec_offset_rescaled.y.T\n",
    "\n",
    "# Instantiate a GP model, including observational errors:\n",
    "# YOUR CODE HERE\n",
    "kernel = RationalQuadratic(...\n",
    "\n",
    "gp_ra = GaussianProcessRegressor(...\n",
    "\n",
    "# Fit it on our training data\n",
    "gp_ra.fit(...\n",
    "\n",
    "# Now predict y(x) on our testing data\n",
    "rescaled_ygrid_ra, rescaled_ygrid_ra_err = gp_ra.predict(...\n",
    "\n",
    "# And undo scaling:\n",
    "ra_y = ra_offset_rescaled.invert(...\n",
    "\n",
    "gp_dec = GaussianProcessRegressor(...\n",
    "\n",
    "# Now predict y(x) on our testing data\n",
    "gp_dec.fit(...\n",
    "\n",
    "# Now predict y(x) on our testing data\n",
    "rescaled_ygrid_dec, rescaled_ygrid_dec_err = gp_dec.predict(...\n",
    "\n",
    "# And undo scaling:\n",
    "dec_y = dec_offset_rescaled.invert(..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Plot the residuals as a function of HA and Declination\n",
    "\n",
    "What is the approximate size of the circle (in arcseconds) which contains most of the points? Did your Gaussian Process improve over the linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: The Story of GW170817"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 2015, astronomers have detected roughly 20 confirmed signals from gravitational waves (GWs), with dozens more unconfirmed candidate signals. The science of GWs has been driven by three GW detectors: Two [LIGO detectors](https://www.ligo.caltech.edu/page/what-is-ligo) at Hanford, WA and Livingston, LA, plus the [Virgo detector](http://public.virgo-gw.eu/virgo-in-a-nutshell/) in Italy.\n",
    "\n",
    "Before Aug 17th, 2017, there were only 4 confirmed detections of gravitational waves: GW150914 (the first one), GW151226, GW170104, and GW170814 (plus LVT151012 as a tentative detection). The last one (GW170814) is the first detected by both LIGO and VIRGO, which joined the collaboration on Aug 1st, 2017. So, it was only a few days after that that they detected another very important event.\n",
    "\n",
    "On Aug 17th, 2017, at 12:41:04 UTC, a clear signal was detected by LIGO-Hanford (just at the end of the second LIGO cycle – 9 days later and LIGO would have have been off!). The raw data from LIGO-Livingston detector included a glitch. After reprocessing the data to remove this artifact there was a another clear signal. The VIRGO didn’t manage to show any significant signal but that was due to its antenna orientation and sensitivity (which is important to constrain the sky positions though). The duration of the signal was approximately 60 s. This was the longest and the strongest (at SNR~32.4) signal detected so far.\n",
    "\n",
    "<img src=\"figures/GW170817-bns_figure1.png\" alt=\"\" width=\"500\" height=\"695\">\n",
    "\n",
    "However, such a long signal is expected to be produced by the merging of neutron stars. And indeed the total mass estimate was 2.73–3.29 M☉ (where M☉ = the Sun's mass) with a mass ratio of 0.4–1.0 between the merging objects. This means that the individual masses of the sources that merged were 1.36–2.26 M☉ and 0.86–1.36 M☉, well within the limits of neutron star masses.\n",
    "\n",
    "<img src=\"figures/GW170817-milkyway-triangulation-small.png\" alt=\"\" width=\"500\" height=\"695\">\n",
    "\n",
    "We can pinpoint sources like GW170817 much more accurately now that we can triangulate the signal between Hanford, Livingston, and Virgo. Above, the rapid Hanford-Livingston localization is shown in blue, and the final Hanford-Livingston-Virgo localization is in green. The gray rings are one-sigma triangulation constraints from the three detector pairs.\n",
    "\n",
    "Almost at the same time (~2s after the GW detection) FERMI (and INTEGRAL) detected a short Gamma-Ray Burst (GRB170817A). The detection of such a contemporaneous signal triggered the community that something exceptional was going on. It is interesting to note that the detection of the GRB only (without any GW detection) wouldn’t be sufficient to mobilize a follow-up campaign, especially because the error of sky position from FERMI is huge. The localization obtained from the GW detection and the information that an electromagnetic (EM) counterpart may exist increased the significance of this source.\n",
    "\n",
    "<img src=\"figures/GW170817-data-mod.png\" alt=\"\" width=\"500\" height=\"695\">\n",
    "\n",
    "### Searching for the kilonova\n",
    "\n",
    "Apart from the gravitational waves, a neutron star merger would become visible in the electromagnetic (EM) spectrum as a **kilonova**. By 2017, several kilonovae had already been oberved, and it was known that they typically peaked in brightness for only a few days before fading.\n",
    "\n",
    "Very soon after the detection all collaborators of LIGO/VIRGO were informed about the possible EM counterpart. Around 70 teams around the world started using almost all available (both ground and space) telescopes to detect and study it. The collaboration quickly compiled a list of ~100 candidate galaxies according to the properties derived from the GW detection (see [Coulter et al. 2017](https://ui.adsabs.harvard.edu/abs/2017Sci...358.1556C/abstract) for more details), and aimed to find new light sources in these galaxies. The Swope telescope in Chile was the best-positioned for these observaitons, and on only the 9th image (and only 20 minutes into their observations) Swope discovered a new light source in the galaxy NGC 4993 -- a galaxy they had classified as the 12th most probable to host the GW source. (Impressively, its V magnitude was at 17.35 mag, which was bright enough to be visible by many amateur astronomers!)\n",
    "\n",
    "Luck was definitely on our side, as the position and the timings were marginal: the GRB was not exciting by itself, SSS17a was setting within one hour, the transient would have been hidden behind the Sun one month later, and only 9 days later LIGO would have been down. Despite these constraints, the astronomical community and the whole collaboration proved to be prepared enough not to lose this unique opportunity. The event mobilized almost half the astronomers around the globe (approximately 4000 people in a community of 10000). This led to a an impressive number of publications counting ~250 GCN circulars and ~80 papers during the “first wave” of its announcement only (with the most striking cases of the ApJ Letter of 60 pages containing all obtained observations; LIGO et al. 2017). The new era of multi-messenger astronomy is here and will routinely discover and study new events aftert the future upgrades of the GW detectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The kilonova lightcurve\n",
    "\n",
    "The image below shows the kilonova as it was observed on August 17, 2017:\n",
    "\n",
    "<img src=\"figures/GW170817-Coulter2017-F4.large_.jpg\" alt=\"\" width=\"500\" height=\"695\">\n",
    "\n",
    "Both the light curves and the spectra display fast changes in the temperature of the material expelled from the collision:\n",
    "\n",
    "<img src=\"figures/GW170817-Drout2017-F3.large_.jpg\" alt=\"\" width=\"500\" height=\"695\">\n",
    "\n",
    "Even within the first hour of observations the spectra show a drop of temperature from ~11000K to 9300K, which is indicative of a material expansion at ~0.3c.\n",
    "\n",
    "![GW170817 timelapse](figures/Time-lapse-sequence-of-kilonova.gif)\n",
    "\n",
    "In total, its evolution was remarkably fast, unlike anything else we have observed so far.\n",
    "\n",
    "This very fast expansion of the material and its cooling could be attributed to the formation of lanthanide elements through the [r-process](https://en.wikipedia.org/wiki/R-process). All elements up to Fe can be produced within the massive stars and some of the heavier elements during their supernovae explosions. Theory predicted that the majority of the heaviest elements (such as gold, platinum, uranium, etc) should be produced during the merging process of neutron stars, where a large number of neutrons are available within very short times. But we lacked observations up to now.\n",
    "\n",
    "The current models of kilonovae are only partly able to fit the our observed data on kilonovae, but help to derive important conclusions regarding the nature of these explosions. In particular, SSS17a could be described better by a two-component mass ejection, with each component being responsible mainly for the the early and later behavior. Estimates of the released material reach up to a few Earth masses for gold and platinum (and up to 16000 Earth masses for heavier elements in total).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Problem summary:** Predicting neutron star properties from the GW170817 lightcurve\n",
    "\n",
    "As explained in the intro, the astronomical community went to immense effort to obtain the lightcurve for the GW170817 kilonova. How can we analyze this lightcurve to obtain information about the neutron stars that merged? In this problem, we will use **PCA** and **Gaussian process modeling** to determine the a best-fit model for GW170817's lightcurve from a grid of modeled lightcurves.\n",
    "\n",
    "---\n",
    "\n",
    "**The model grid:** While kilonova observations are rare, astronomers have been able to model the lightcurve that would arise given a set of initial conditions. For this problem, we will use a grid of models from [Dietrich et al. 2020](https://arxiv.org/pdf/2002.11355.pdf) that predict kilonova lightcurves based on a small number of parameters that describe the merger. These models use four parameters ($M^{dyn}_{ej}$, $M^{wind}_{ej}$, $\\phi$ and $\\theta$), which are described more fully in the paper.\n",
    "\n",
    "(In short: $M^{dyn}_{ej}$ and $M^{wind}_{ej}$ measure the amount of mass ejected from the merger due to different processes, while $\\phi$ is related to the chemical composition of this ejected mass and $\\theta$ is the angle between the merger's plane of rotation and the observer.)\n",
    "\n",
    "**Fitting a model to GW170817's lightcurve:** Our goal for this problem is to to determine the best-fit model parameters for GW170817 based on its observed lightcurve. While this will be similar to model-fitting tasks on past homeworks, there are two major obstacles in our way this time:\n",
    "1. We don't have a continuous map between \"merger parameters\" and \"observed lightcurves\". Instead, we only know the observed lightcurves for the DISCRETE grid of parameters for which lightcurves were simulated. (Eg: we may know the lightcurves to expect for $m_{ejected} = m_1$ and $m_{ejected} = m_2$, but not for any masses between $m_1$ and $m_2$.)\n",
    "2. The lightcurve predicted by each set of parameters is **extremely high-dimensional**: It predicts the magnitude of the kilonova at MANY different times following the neutron star merger.\n",
    "\n",
    "Fortunately, we now have the tools to overcome these obstacles! The outline of this problem is as follows:\n",
    "- First, you will reduce the dimensionality of the lightcurve dataset by using PCA: Each lightcurve will be represented by a small number of \"eigenvalues\", rather than the full lightcurve. After performing PCA, you will have a discrete grid of models that relate merger parameters to a few **lightcurve eigenvalues** rather than the whole lightcurve.\n",
    "- Next, you will model this grid as a Gaussian process. This will allow you to form a **continuous map** from merger parameters to lightcurve eigenvalues.\n",
    "- Finally, you will calculate the eigenvalues of the GW170817 lightcurve itself. Using the map from above, you can convert these eigenvalues directly to the set of merger parameters that most likely resulted in this lightcurve!\n",
    "\n",
    "At the end of this problem, you will have predicted the **total mass ejected** from the GW170817 merger as well as some of its **chemical properties**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.interpolate import interpolate as interp\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import pickle\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, DotProduct, ConstantKernel, RationalQuadratic\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS\n",
    "\n",
    "def read_files(files, tt, filts):\n",
    "\n",
    "    names = []\n",
    "    mags = {}\n",
    "    for filename in files:\n",
    "        name = filename.replace(\".txt\",\"\").replace(\".dat\",\"\").split(\"/\")[-1]\n",
    "        mag_d = np.loadtxt(filename)\n",
    "\n",
    "        t = mag_d[:,0]\n",
    "        mags[name] = {}\n",
    "        mags[name][\"t\"] = mag_d[:,0]\n",
    "        mags[name][\"u\"] = mag_d[:,1]\n",
    "        mags[name][\"g\"] = mag_d[:,2]\n",
    "        mags[name][\"r\"] = mag_d[:,3]\n",
    "        mags[name][\"i\"] = mag_d[:,4]\n",
    "        mags[name][\"z\"] = mag_d[:,5]\n",
    "        mags[name][\"y\"] = mag_d[:,6]\n",
    "        mags[name][\"J\"] = mag_d[:,7]\n",
    "        mags[name][\"H\"] = mag_d[:,8]\n",
    "        mags[name][\"K\"] = mag_d[:,9]\n",
    "\n",
    "        names.append(name)\n",
    "\n",
    "    magkeys = mags.keys()    \n",
    "    for jj, key in enumerate(magkeys):\n",
    "        keySplit = key.split(\"_\")\n",
    "\n",
    "        if \"nsns\" in key:\n",
    "\n",
    "            mejdyn = float(keySplit[2].replace(\"mejdyn\",\"\"))\n",
    "            mejwind = float(keySplit[3].replace(\"mejwind\",\"\"))\n",
    "            phi0 = float(keySplit[4].replace(\"phi\",\"\"))\n",
    "            theta = float(keySplit[5])\n",
    "\n",
    "            mags[key][\"mej_dyn\"] = mejdyn\n",
    "            mags[key][\"mej_wind\"] = mejwind\n",
    "            mags[key][\"phi\"] = phi0\n",
    "            mags[key][\"theta\"] = theta\n",
    "\n",
    "        elif \"nsbh\" in key:\n",
    "\n",
    "            mej_dyn = float(keySplit[2].replace(\"mejdyn\",\"\"))\n",
    "            mej_wind = float(keySplit[3].replace(\"mejwind\",\"\"))\n",
    "            phi = float(keySplit[4].replace(\"phi\",\"\"))\n",
    "            theta = float(keySplit[5])\n",
    "\n",
    "            mags[key][\"mej_dyn\"] = mej_dyn\n",
    "            mags[key][\"mej_wind\"] = mej_wind\n",
    "            #mags[key][\"phi\"] = phi\n",
    "            mags[key][\"theta\"] = theta\n",
    "           \n",
    "        # Interpolate data onto grid\n",
    "        mags[key][\"data\"] = np.zeros((len(tt),len(filts)))\n",
    "        for jj,filt in enumerate(filts):\n",
    "            ii = np.where(np.isfinite(mags[key][filt]))[0]\n",
    "            f = interp.interp1d(mags[key][\"t\"][ii], mags[key][filt][ii], fill_value='extrapolate')\n",
    "            maginterp = f(tt)\n",
    "            mags[key][\"data\"][:,jj] = maginterp\n",
    "        mags[key][\"data_vector\"] = np.reshape(mags[key][\"data\"],(len(tt)*len(filts),1))\n",
    "            \n",
    "    return mags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Data\n",
    "\n",
    "First, we will load the kilonova lightcurve models and have a look at them.\n",
    "\n",
    "In the cell below, a few key variables are defined:\n",
    "- `models` is a dictionary mapping the \"name\" of each model to the associated parameters & lightcurves of those models.\n",
    "- `modelkeys` is a list of all available model names\n",
    "- `filts` lists the particular filter bands on which we'll focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS\n",
    "\n",
    "# The number of PCA components we'll use to represent each lightcurve\n",
    "n_coeff = 3 \n",
    "\n",
    "# The array of post-merger times we'll use to examine each lightcurve\n",
    "tini, tmax, dt = 0.1, 5.0, 0.2 \n",
    "tt = np.arange(tini,tmax+dt,dt) # \n",
    "\n",
    "# The filters we'll be focusing on\n",
    "filts = ['g','r']  # We will focus on these two bands; all available: [\"u\",\"g\",\"r\",\"i\",\"z\",\"y\",\"J\",\"H\",\"K\"]\n",
    "\n",
    "# The model type we'll be focusing on\n",
    "objtype = \"BNS\" # for \"binary neutron star\" -- can also choose \"NSBH\" for \"neutron star - black hole\"\n",
    "\n",
    "# Defines the files containing model data\n",
    "dataDir = \"data/%s\" % objtype\n",
    "filenames = glob.glob('%s/*.dat'%dataDir)\n",
    "\n",
    "# Loads the model data\n",
    "models = read_files(filenames, tt, filts)\n",
    "modelkeys = list(models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Plot the **modeled** lightcurve of a kilonova \n",
    "\n",
    "Below, plot one of the models from the `models` dictionary. Plot the modeled lightcurve (absolute magnitude vs. time in days) in the r-band and the g-band.\n",
    "\n",
    "(You're welcome to plot multiple if you wish -- just don't plot all 2,000+ models!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What did the GW170817 data look like?\n",
    "\n",
    "Below, we read in the actual photometry observed from the 2017 kilonova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS\n",
    "\n",
    "from astropy.time import Time\n",
    "\n",
    "def loadEvent(filename):\n",
    "    lines = [line.rstrip('\\n') for line in open(filename)]\n",
    "    lines = filter(None,lines)\n",
    "\n",
    "    data = {}\n",
    "    for line in lines:\n",
    "        lineSplit = line.split(\" \")\n",
    "        lineSplit = list(filter(None,lineSplit))\n",
    "        mjd = Time(lineSplit[0], format='isot').mjd\n",
    "        filt = lineSplit[1]\n",
    "        mag = float(lineSplit[2])\n",
    "        dmag = float(lineSplit[3])\n",
    "\n",
    "        if not filt in data:\n",
    "            data[filt] = np.empty((0,3), float)\n",
    "        data[filt] = np.append(data[filt],np.array([[mjd,mag,dmag]]),axis=0)\n",
    "\n",
    "    return data \n",
    "    \n",
    "filename = \"data/GW170817.dat\"\n",
    "T0 = 57982.5285236896 # Merger time\n",
    "distance = 40\n",
    "\n",
    "data_out = loadEvent(filename)\n",
    "\n",
    "for ii,key in enumerate(list(data_out.keys())):\n",
    "    if key == \"t\":\n",
    "        continue\n",
    "    else:\n",
    "        data_out[key][:,0] = data_out[key][:,0] - T0\n",
    "        data_out[key][:,1] = data_out[key][:,1] - 5*(np.log10(distance*1e6) - 1)\n",
    "\n",
    "for ii,key in enumerate(list(data_out.keys())):\n",
    "    if key == \"t\":\n",
    "        continue\n",
    "    else:\n",
    "        idxs = np.intersect1d(np.where(data_out[key][:,0]>=tini)[0],np.where(data_out[key][:,0]<=tmax)[0])\n",
    "        data_out[key] = data_out[key][idxs,:]\n",
    "\n",
    "for ii,key in enumerate(list(data_out.keys())):\n",
    "    idxs = np.where(~np.isnan(data_out[key][:,2]))[0]\n",
    "    if key == \"t\":\n",
    "        continue\n",
    "    else:\n",
    "        data_out[key] = data_out[key][idxs,:]\n",
    "\n",
    "for ii,key in enumerate(list(data_out.keys())):\n",
    "    if not key in filts:\n",
    "        del data_out[key]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Plot the GW170817 data\n",
    "\n",
    "Plot the photometric data for GW170817, separating lightcurves by band, and showing### Q2: Plot the GW170817 data\n",
    "\n",
    "**Plot the lightcurve for GW170817 for both the g- and r-bands.**\n",
    "\n",
    "In the cell above, we've defined the following variables:\n",
    "- `tini`, `tmax`: The minimum and maximum times we'll be examining the lightcurve over\n",
    "- `data_out`: A dictionary mapping \"filter band\" -> \"lightcurve data\"\n",
    "\n",
    "In `data_out`, each \"lightcurve data\" array contains 3 columns: [\"time (days)\", \"absolute magnitude\", and \"error on absolute magnitude\"]. You should use the data stored in these columns to plot the lightcurve (absolute magnitude vs. time) for each filter band between `tini` and `tmax`, showing the error bars on each point.\n",
    "\n",
    "Hints:\n",
    "- You'll need to remove NaNs and infinite values from your dataset.\n",
    "- The error bars will typically be small the errorbars. \n",
    "You'll note we need to remove NaNs and infinite values from your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Can you try find a model in the `models` dictionary that fits this data \"by eye\"?\n",
    "\n",
    "Try plotting a few model lightcurves against the GW170817 lightcurve. Can you find a model that's (roughly) close to the data? If so, what is its name?\n",
    "- There are over 2,000 models, so don't spend too long on this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Preparing the data - Normalize the model parameters and lightcurve data so that they range from 0-1\n",
    "\n",
    "Recall that Gaussian processes work best on data that is scaled the same way in every dimension. To ensure this is true for this dataset, we will ensure that our **model parameters** and **lightcurve magnitudes** are scaled so that they all range between 0-1.\n",
    "\n",
    "In the cell below, we take the parameters of each model in `models` and store them in an array, `param_array_postprocess`. You should normalize each column of this array so that it ranges from 0-1; this will prepare us to find the best-fit parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the relevant parameters into an array\n",
    "param_array = []\n",
    "for key in modelkeys:\n",
    "    if objtype == \"BNS\":\n",
    "        param_array.append([np.log10(models[key][\"mej_dyn\"]),np.log10(models[key][\"mej_wind\"]),models[key][\"phi\"],models[key][\"theta\"]])\n",
    "    elif objtype == \"NSBH\":\n",
    "        param_array.append([np.log10(models[key][\"mej_dyn\"]),np.log10(models[key][\"mej_wind\"]),models[key][\"theta\"]])\n",
    "param_array_postprocess = np.array(param_array)\n",
    "        \n",
    "# YOUR CODE HERE \n",
    "param_mins, param_maxs = np.min(param_array_postprocess,axis=0),np.max(param_array_postprocess,axis=0)\n",
    "for i in range(len(param_mins)):\n",
    "    param_array_postprocess[:,i] = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we do the same thing for the lightcurve magnitudes stored in the `models` array. These will be stored in an array called `mag_array_postprocess`; make sure the columns of this array are scaled from 0-1 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the relevant parameters into an array\n",
    "svd_model = {}\n",
    "# Loop through filters\n",
    "for jj,filt in enumerate(filts):\n",
    "    print('Normalizing mag filter %s...' % filt)\n",
    "    mag_array = []\n",
    "    for key in magkeys:\n",
    "        mag_array.append(models[key][\"data\"][:,jj])\n",
    "\n",
    "    mag_array_postprocess = np.array(mag_array)\n",
    "    mins,maxs = np.min(mag_array_postprocess,axis=0),np.max(mag_array_postprocess,axis=0)\n",
    "    for i in range(len(mins)):\n",
    "        mag_array_postprocess[:,i] = # YOUR CODE HERE\n",
    "    mag_array_postprocess[np.isnan(mag_array_postprocess)]=0.0\n",
    "    \n",
    "    svd_model[filt] = {}\n",
    "    svd_model[filt][\"param_array\"] = param_array\n",
    "    svd_model[filt][\"param_mins\"] = param_mins\n",
    "    svd_model[filt][\"param_maxs\"] = param_maxs\n",
    "    svd_model[filt][\"mins\"] = mins\n",
    "    svd_model[filt][\"maxs\"] = maxs\n",
    "    svd_model[filt][\"tt\"] = tt\n",
    "    svd_model[filt][\"mag_array_postprocess\"] = mag_array_postprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Performing PCA - Compute the \"singular value decomposition\" of the magnitude array\n",
    "\n",
    "In the cell below, we will reduce the dimensions of the modeled kilonova lightcurves by performing PCA on them and determining the \"most important\" (aka \"principal\") components. In particular, we will use an operation called the \"singular value decomposition\" to do this.\n",
    "\n",
    "Use [`np.linalg.svd`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html) to calculate the singular value decomposition. The components generated by this are stored in three arrays, called `UA`, `sA` and `VA` (for \n",
    "- For more on how singular value decomposition works (and how it's related to PCA): https://jonathan-hui.medium.com/machine-learning-singular-value-decomposition-svd-principal-component-analysis-pca-1d45e885e491\n",
    "\n",
    "Once this is done, we will take the `n_coeff` most important eigenvalues to represent each model lightcurve (stored in `VA_principal`). We will then generate two arrays: `cAmat`, which stores the model lighcurve eigenvalues, and `cAvar`, which stores their variance.\n",
    "\n",
    "Note: you can perform SVD on the covariance of the data OR the data itself. However, if you choose to perform SVD on the data, make sure it is normalized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through filters\n",
    "for jj,filt in enumerate(filts):\n",
    "    print('Computing PCA for filter %s...' % filt)\n",
    "\n",
    "    mag_array_postprocess = svd_model[filt][\"mag_array_postprocess\"] \n",
    "    UA, sA, VA = # compute the SVD\n",
    "    VA = VA.T\n",
    "\n",
    "    n, n = UA.shape\n",
    "    m, m = VA.shape\n",
    "\n",
    "    cAmat = np.zeros((n_coeff,n))\n",
    "    cAvar = np.zeros((n_coeff,n))\n",
    "    for i in range(n):\n",
    "        ErrorLevel = 1.0\n",
    "        cAmat[:,i] = # prepare the array of target values (hint: remember this is the dot product of your data with V)\n",
    "        errors = ErrorLevel*np.ones_like(mag_array_postprocess[i,:])\n",
    "        cAvar[:,i] = # calculate the variance in the target array (hint: remember this is V^T E^2 V)\n",
    "    cAstd = np.sqrt(cAvar)\n",
    "\n",
    "    svd_model[filt][\"n_coeff\"] = n_coeff\n",
    "    svd_model[filt][\"cAmat\"] = cAmat\n",
    "    svd_model[filt][\"cAstd\"] = cAstd\n",
    "    svd_model[filt][\"VA\"] = VA  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Compute the Gaussian Process to interpolate the eigenvalues\n",
    "\n",
    "Now, we will compute the Gaussian process models on the eigenvalues of the model lightcurves. We will use the `RationalQuadratic` kernel for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through filters\n",
    "for jj,filt in enumerate(filts):\n",
    "    print('Computing GP for filter %s...' % filt)\n",
    "\n",
    "    cAmat = svd_model[filt][\"cAmat\"]\n",
    "    cAstd = svd_model[filt][\"cAstd\"]\n",
    "    VA = svd_model[filt][\"VA\"]\n",
    "    \n",
    "    nsvds, nparams = param_array_postprocess.shape\n",
    "    \n",
    "    # Set of Gaussian Process\n",
    "    kernel = # Choose a kernel: I used RationalQuadratic\n",
    "    gps = []\n",
    "    for i in range(n_coeff):\n",
    "        if np.mod(i,1) == 0:\n",
    "            print('Coefficient %d/%d...' % (i+1, n_coeff))\n",
    "        \n",
    "        gp = # Run GaussianProcessRegressor with your chosen kernel\n",
    "        gp.fit( # fit your parameters to your computed PCA coefficients\n",
    "        gps.append(gp)\n",
    "        \n",
    "    svd_model[filt][\"gps\"] = gps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your dictionary to a pickle file for safe keeping\n",
    "As you notice, this is not a fast computation, so save the model in a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile = '%s.pkl' % objtype\n",
    "with open(modelfile, 'wb') as handle:\n",
    "    pickle.dump(svd_model, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Using your trained Gaussian process model, interpolate between the points in the model grid, and recover the merger parameters of GW170817\n",
    "\n",
    "The GP model you just trained allows us to interpolate between points on the \"merger parameter\" grid. Now, we can determine the lightcurve \n",
    "\n",
    "In the cells below, use your trained GP model to predict the parameters that give rise to the real GW170817 lightcurve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a set of parameters\n",
    "param_list = [np.log10(0.005), np.log10(0.01), 45, 30]\n",
    "\n",
    "with open(modelfile, 'rb') as handle:\n",
    "    svd_model = pickle.load(handle)\n",
    "\n",
    "mAB = np.zeros((len(filts),len(tt)))\n",
    "for jj,filt in enumerate(filts):\n",
    "    param_array = svd_model[filt][\"param_array\"]\n",
    "    cAmat = svd_model[filt][\"cAmat\"]\n",
    "    VA = svd_model[filt][\"VA\"]\n",
    "    param_mins = svd_model[filt][\"param_mins\"]\n",
    "    param_maxs = svd_model[filt][\"param_maxs\"]\n",
    "    mins = svd_model[filt][\"mins\"]\n",
    "    maxs = svd_model[filt][\"maxs\"]\n",
    "    gps = svd_model[filt][\"gps\"]\n",
    "    tt_interp = svd_model[filt][\"tt\"]\n",
    "\n",
    "    param_list_postprocess = np.array(param_list)\n",
    "    for i in range(len(param_mins)):\n",
    "        param_list_postprocess[i] = (param_list_postprocess[i]-param_mins[i])/(param_maxs[i]-param_mins[i])\n",
    "\n",
    "    cAproj = np.zeros((n_coeff,))\n",
    "    cAstd = np.zeros((n_coeff,))\n",
    "    for i in range(n_coeff):\n",
    "        gp = gps[i]\n",
    "        # YOUR CODE HERE\n",
    "        y_pred, sigma2_pred = # use gp.predict to extract the predicted PCA coefficients (gp.predict will need the return_std=True flag set)        \n",
    "        cAproj[i] = y_pred\n",
    "        cAstd[i] = sigma2_pred\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        coverrors = # compute the error bars (hint: V * E^2 * V^T)\n",
    "        errors = np.diag(coverrors)\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        mag_back = # compute the light curve from your predicted coefficients (hint: V * C)\n",
    " \n",
    "        # This line renormalizes.\n",
    "        mag_back = mag_back*(maxs-mins)+mins\n",
    "        #mag_back = scipy.signal.medfilt(mag_back,kernel_size=3)\n",
    "\n",
    "        ii = np.where(~np.isnan(mag_back))[0]\n",
    "        if len(ii) < 2:\n",
    "            maginterp = np.nan*np.ones(tt.shape)\n",
    "        else:\n",
    "            f = interp.interp1d(tt_interp[ii], mag_back[ii], fill_value='extrapolate')\n",
    "            maginterp = f(tt)\n",
    "        mAB[jj,:] = maginterp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorbudget = 1.0\n",
    "\n",
    "cnt = 0\n",
    "for ii, (filt, color) in enumerate(zip(filts,colors)):\n",
    "    cnt = cnt+1\n",
    "    if cnt == 1:\n",
    "        ax1 = plt.subplot(len(filts),1,cnt)\n",
    "    else:\n",
    "        ax2 = plt.subplot(len(filts),1,cnt,sharex=ax1,sharey=ax1)\n",
    "\n",
    "    if not filt in data_out: continue\n",
    "    samples = data_out[filt]\n",
    "    t, y, sigma_y = samples[:,0], samples[:,1], samples[:,2]\n",
    "    idx = np.where(~np.isnan(y))[0]\n",
    "    t, y, sigma_y = t[idx], y[idx], sigma_y[idx]\n",
    "    if len(t) == 0: continue\n",
    "\n",
    "    idx = np.where(np.isfinite(sigma_y))[0]\n",
    "    plt.errorbar(t[idx],y[idx],sigma_y[idx],fmt='o',c=color, markersize=16, label='%s-band'%filt, markeredgecolor='k')\n",
    "\n",
    "    idx = np.where(~np.isfinite(sigma_y))[0]\n",
    "    plt.errorbar(t[idx],y[idx],sigma_y[idx],fmt='v',c=color, markersize=16, markeredgecolor='k')\n",
    "\n",
    "    plt.xlim([0.0, 14.0])\n",
    "    plt.ylim([-17.0,-11.0])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.ylabel(r'$%s$'%filt,fontsize=20,rotation=0,labelpad=20)\n",
    "\n",
    "    f = interp.interp1d(tt, mAB[ii,:], fill_value='extrapolate')\n",
    "    maginterp = f(tt)\n",
    "    #plt.plot(tt,maginterp+zp_best,'--',c=color,linewidth=3)\n",
    "    #plt.fill_between(tt,maginterp+zp_best-errorbudget,maginterp+zp_best+errorbudget,facecolor=color,alpha=0.2)\n",
    "\n",
    "    plt.plot(tt,maginterp,'--',c='k',linewidth=3)\n",
    "    plt.fill_between(tt,maginterp-errorbudget,maginterp+errorbudget,facecolor='k',alpha=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** You have just recovered the light curve of the world's most famous kilonova!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Can you use `emcee` or a similar method to estimate the binary parameters?\n",
    "\n",
    "Another way to predict GW170817's best fit would be to build likelihood function that takes in merger parameters, predicts a model lightcurve from these parameters, and estimates the likelihood of GW170817's lightcurve given this model. Then, an MCMC walker (or other likelihood-maximization algorithm) can determine the set of parameters that maximizes this likelihood. As a bonus question, try to fit the lightcurve this way and compare the best fit to what you got from our original method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 (Extra Credit: 1 point): Please fill out the project survey (https://forms.gle/AGJGtuHYmP8ZrYCY8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit: Regression with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem we will use some simple regression models (provided by the Scikit-learn package) to predict **galaxy redshift** from **galaxy color**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intro: Scikit-learn**\n",
    "\n",
    "Scikit-learn models, like those used in class, have a fixed syntax so it is the same for a simple linear regression operation as it is for something much more complex such as random forest. The specific model is represented as a class with model parameters defined in the class constructor:\n",
    "\n",
    "```\n",
    "class sklearn.linear_model.LinearRegression(\n",
    "    fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)\n",
    "```\n",
    "\n",
    "The class will also have a <i>fit</i> method for fitting (training) the model which takes the data (X) as a Numpy array of shape [n_samples, n_features] and the response values (y) as a Numpy array of shape [n_samples, n_responses]:\n",
    "```\n",
    "def fit(X, y):\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Data\n",
    "\n",
    "For these exercises, we're going to use a data set of galaxies with known (\"spectroscopically confirmed\") redshifts and SDSS magnitudes. We're interested in determining the redshift of a galaxy from its colors. This estimate is known as **photometric redshift**; it's useful because it is far easier to estimate the color of a galaxy than to get its spectrum.\n",
    "\n",
    "In the cells below, we load and plot the galaxy dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "sns.set(style=\"ticks\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       u-g      g-r      r-i      i-z  redshift\n",
      "0  1.88235  0.95459  0.44631  0.32659  0.091214\n",
      "1  1.97871  0.95931  0.46358  0.32285  0.117409\n",
      "2  1.84007  0.92670  0.40268  0.32295  0.091852\n",
      "3  1.89717  1.09666  0.47545  0.34684  0.153276\n",
      "4  0.98144  0.38145  0.34404  0.04365  0.090731\n"
     ]
    }
   ],
   "source": [
    "# Loads the galaxy dataset and prints the first few rows\n",
    "\n",
    "sdss_gal_df = pd.read_csv('data/sdss_gal.csv', low_memory=False)\n",
    "\n",
    "print(sdss_gal_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plots a random subsample of the data\n",
    "\n",
    "sdss_gal_sample = sdss_gal_df.sample(n=1000, random_state=0)\n",
    "redshift = sdss_gal_sample['redshift'].values\n",
    "gr = sdss_gal_sample['g-r'].values\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.scatter(gr, redshift, color='gray', alpha=0.1)\n",
    "ax.set_xlabel('g-r')\n",
    "ax.set_ylabel('Redshift')\n",
    "ax.set_title('SDSS galaxy redshifts:\\n SDSS g-r color vs Redshift Scatter Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: modeling the data\n",
    "\n",
    "We're going to use train_test_split method to create our training and test data sets for a random subsample. We'll set the test set to be half the size of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_gal_sample = sdss_gal_df.sample(n=1000, random_state=0)\n",
    "\n",
    "y = sdss_gal_sample['redshift'].values\n",
    "X = sdss_gal_sample['g-r'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.reshape((len(X), 1)), y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define our basic linear regressor and fit it to the data.\n",
    "\n",
    "Confirm that the values of the slope and intercept are what you would expect from a MSE loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "regression = LinearRegression(...\n",
    "regression.fit(...\n",
    "\n",
    "regression_line = lambda x: regression.intercept_ + regression.coef_ * x\n",
    "print('The equation of the regression line is: {} + {} * x'.format(regression.intercept_, regression.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: plot the regression line over the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Train vs Test Error\n",
    "\n",
    "We would like to evaluate and interpret the modle. Let's have a bit more of a look at the linear model we've fitted.\n",
    "\n",
    "Compute the mean squared error (MSE) values for the training and the test data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: Residual Analysis\n",
    "\n",
    "In residual analysis we want to check that the residuals are uncorrelated and normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the residuals. Are they normally distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Extra Credit: Regression with multiple parameters\n",
    "\n",
    "Clearly redshift is not just a function of one color but of several. Here we will look at fitting a linear model with multiple parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_gal_sample = sdss_gal_df.sample(n=1000, random_state=0)\n",
    "#sdss_gal_sample['lpep_pickup_datetime'] = nyc_cab_sample['lpep_pickup_datetime'].apply(lambda dt: pd.to_datetime(dt).hour)\n",
    "#sdss_gal_sample['Lpep_dropoff_datetime'] = nyc_cab_sample['Lpep_dropoff_datetime'].apply(lambda dt: pd.to_datetime(dt).hour)\n",
    "msk = np.random.rand(len(sdss_gal_sample)) < 0.8\n",
    "train = sdss_gal_sample[msk]\n",
    "test = sdss_gal_sample[~msk]\n",
    "\n",
    "y_train = train['redshift'].values\n",
    "X_train = train[['g-r', 'r-i', 'i-z']].values\n",
    "\n",
    "y_test = test['redshift'].values\n",
    "X_test = test[['g-r', 'r-i', 'i-z']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Create the linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "multi_regression_model = LinearRegression(...\n",
    "multi_regression_model.fit(...\n",
    "\n",
    "print('The equation of the regression plane is: {} + {}^T . x'.format(multi_regression_model.intercept_, multi_regression_model.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Evaluating the Significance of Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tools import add_constant\n",
    "\n",
    "predictors_multiple = ['g-r', 'r-i', 'i-z']\n",
    "predictors_simple = ['g-r']\n",
    "\n",
    "X_train_multi = add_constant(train[predictors_multiple].values)\n",
    "X_test_multi = add_constant(test[predictors_multiple].values)\n",
    "\n",
    "X_train_simple = add_constant(train[predictors_simple].values)\n",
    "X_test_simple = add_constant(test[predictors_simple].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the number of predictors vs the model fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['u-g', 'g-r', 'r-i', 'i-z']\n",
    "train_R_sq = []\n",
    "test_R_sq = []\n",
    "for i in range(1, len(cols) + 1):\n",
    "    \n",
    "    predictors = cols[:i]\n",
    "    X_train = train[predictors].values\n",
    "    X_test = test[predictors].values\n",
    "    \n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Polynomial Regression\n",
    "What is the effect of Polynomial Degree on model performance? Can you improve the fits using a higher degree polynomial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['redshift'].values\n",
    "X_train = train[['g-r', 'r-i', 'i-z']].values\n",
    "\n",
    "y_test = test['redshift'].values\n",
    "X_test = test[['g-r', 'r-i', 'i-z']].values\n",
    "\n",
    "gen_poly_terms = PolynomialFeatures(degree=2, interaction_only=False)\n",
    "X_train_with_poly = gen_poly_terms.fit_transform(X_train)\n",
    "X_test_with_poly = gen_poly_terms.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the fit of the model vs. the number of polynomial degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train_R_sq = []\n",
    "test_R_sq = []\n",
    "max_deg = 10\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_test = min_max_scaler.fit_transform(X_test)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "for d in range(1, max_deg + 1):\n",
    "    gen_poly_terms = PolynomialFeatures(degree=d, interaction_only=False)\n",
    "    X_train_with_poly = gen_poly_terms.fit_transform(X_train)\n",
    "    X_test_with_poly = gen_poly_terms.fit_transform(X_test)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    poly_regression_model = LinearRegression(...\n",
    "    poly_regression_model.fit(...\n",
    "    \n",
    "    train_R_sq.append(...\n",
    "    test_R_sq.append(..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Appendix: Details of the telescope pointing error model\n",
    "\n",
    "Wallace & Tritton (1976) present a basic geometrical model for a telescope using HA and DEC angles. The model with seven parameters admits of three principal errors and allows for a rudimentary model for flexure error.\n",
    "\n",
    "#### **Error #1**: Misalignment of the polar axis.\n",
    "\n",
    "The polar axis of the telescope is defined by the mount (the giant yoke in the case of P200). The\n",
    "offset of the polar axis with respect to the rotation axis of the Earth has two components: in elevation (ME) and in azimuth (MA). You can raise or lower the pole of the mount to change the elevation angle or rotate the yoke to address the error in azimuth. The misalignment leads to errors in both HA and $\\delta$:\n",
    "\n",
    " \\begin{eqnarray}\n",
    "\t\\Delta h&=& \\tan(\\delta)({\\rm ME}\\sin(h)-{\\rm MA}\\cos(h))\\\\\n",
    "\t\\Delta\\delta &=& {\\rm ME}\\cos(h)+{\\rm MA}\\sin(h)\n",
    "\\end{eqnarray}\n",
    "\n",
    "#### **Error #2:** Non-perpendicularity of the RA and DEC axes.\n",
    "Ideally these two axes are supposed to be perpendicular to each other.  Let NP the angle by which the two axis  deviate from being perpendicular.\n",
    "\n",
    " \\begin{eqnarray}\n",
    "  \\Delta h&=& {\\rm NP}\\tan\\delta\n",
    " \\end{eqnarray}\n",
    "\n",
    "#### **Error #3:** Optical Collimation Error.\n",
    "So far we have two of errors associated with the mount of the telescope. However, the observations are made via telescope optics. As with polar-axis misalignment there are two components: CH and CE.\n",
    "\n",
    " \\begin{eqnarray} \n",
    "        \\Delta h&=& {\\rm CH}\\sec(\\delta)\\\\\n",
    "\t\\Delta\\delta &=& {\\rm CE}\n",
    " \\end{eqnarray}\n",
    "\n",
    "#### **Error #4:** Flexure.\n",
    "This can be complicated term, requiring understanding of the mechanical structure of the telescope.  Wallace\n",
    "advocates the following as a start.\n",
    " \\begin{equation}\n",
    "\t\t\\Delta\\delta={\\rm FO}\\cos(h)\n",
    " \\end{equation}\n",
    "with no error in $h$. Note that if the mount is asymmetrical in E-W then\n",
    "flexure could be a winding error that is not symmetrical in HA.\n",
    "\n",
    "#### Zero point errors. \n",
    "In modern telescopes there are no clock errors so IH=0. However there could be zero point offsets\n",
    "in the encoders (both axes). Next, the declination error of optical collimation error can be absorbed into the zero point error for declination, ID. Finally, the \"bore-sight\" errors are absorbed by\n",
    "IH and ID.\n",
    "\n",
    "Note that these errors are in hour angle and declination. In\n",
    "particular, while $\\Delta h$ is the error the angular error in RA\n",
    "is $\\Delta h\\cos(\\delta)$. Inversely, $\\Delta h$ and $\\Delta \\delta$\n",
    "should be used in fitting the observed {\\it angular offsets} to\n",
    "this model one should use $\\Delta h$ (and not $\\Delta\\alpha$) and\n",
    "$\\Delta\\delta$.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\t\t\\label{eq:dh}\n",
    "\t\\Delta h&=& \\tan(\\delta)\\big[{\\rm ME}\\sin(h)-{\\rm MA}\\cos(h)+{\\rm NP}\\big]+\n",
    "\t+ {\\rm CH}\\sec(\\delta) + {\\rm IH}\\\\\n",
    "\t\t\\label{eq:dd}\\cr\n",
    "\t\\Delta\\delta &=& \\cos(h)\\big[{\\rm ME}+{\\rm FO}\\big]+{\\rm MA}\\sin(h)+{\\rm ID}\n",
    "\\end{eqnarray}"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "name": "_merged"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
